{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d3c4f4-82f9-4132-84cc-55312da36d4e",
   "metadata": {},
   "source": [
    "### Gruppo 4 Text Analytics 2022/23\n",
    "- Simona Sette\n",
    "- Giulio Canapa\n",
    "- Sara Quattrone\n",
    "- Diego Borsetto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a743cf6-efb2-4e35-8cd9-458eda5e4bd2",
   "metadata": {},
   "source": [
    "# Text Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd08475-2b62-473c-ab97-4eba1890068f",
   "metadata": {},
   "source": [
    "Investigating the contents and nature of the newspaper paragraphs texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef876e-2e4c-4f74-90c2-dad70d8c25a6",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc633810-85d4-433c-818d-99f6336c8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import spacy\n",
    "from itertools import *\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import eng_spacysentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ce6eb-f026-49d8-a0a5-9c7a6e8c70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Multiclass_problem_7Classes.csv\" ,sep=',', header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa2451-5d7e-453a-a1b6-64c8834ff548",
   "metadata": {},
   "source": [
    "Generation of dataframes containing persuasion techniques (y) and paragraph textual content along with other context data (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "954506b0-cadc-4c9b-bec0-2667ac538cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total=df['Technique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5b53b29d-c2c4-4047-9bb8-d203dfd1f34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>3</td>\n",
       "      <td>Geneva - The World Health Organisation chief o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>13</td>\n",
       "      <td>But Tedros voiced alarm that \"plague in Madaga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111111</td>\n",
       "      <td>17</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111111</td>\n",
       "      <td>19</td>\n",
       "      <td>He praised the rapid response from WHO and Mad...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111111</td>\n",
       "      <td>25</td>\n",
       "      <td>That means that Madagascar could be affected m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>999001621</td>\n",
       "      <td>41</td>\n",
       "      <td>The story was completely false and the Guardia...</td>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>999001970</td>\n",
       "      <td>3</td>\n",
       "      <td>Andy Warhol was only half-right. In the future...</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>999001970</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday Night Live writer and comedian Nimesh...</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>999001970</td>\n",
       "      <td>6</td>\n",
       "      <td>That's what Columbia snowflakes thought was of...</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>999001970</td>\n",
       "      <td>13</td>\n",
       "      <td>I'm sure Patel felt very, like, accepted.</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1878 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph                                               Text  \\\n",
       "0     111111111          3  Geneva - The World Health Organisation chief o...   \n",
       "1     111111111         13  But Tedros voiced alarm that \"plague in Madaga...   \n",
       "2     111111111         17  He also pointed to the presence of the pneumon...   \n",
       "3     111111111         19  He praised the rapid response from WHO and Mad...   \n",
       "4     111111111         25  That means that Madagascar could be affected m...   \n",
       "...         ...        ...                                                ...   \n",
       "1873  999001621         41  The story was completely false and the Guardia...   \n",
       "1874  999001970          3  Andy Warhol was only half-right. In the future...   \n",
       "1875  999001970          5  Saturday Night Live writer and comedian Nimesh...   \n",
       "1876  999001970          6  That's what Columbia snowflakes thought was of...   \n",
       "1877  999001970         13          I'm sure Patel felt very, like, accepted.   \n",
       "\n",
       "        ID  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  \n",
       "...    ...  \n",
       "1873  1873  \n",
       "1874  1874  \n",
       "1875  1875  \n",
       "1876  1876  \n",
       "1877  1877  \n",
       "\n",
       "[1878 rows x 4 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select all columns except target classes\n",
    "X_total=df.loc[:, df.columns != 'Technique']\n",
    "X_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82acce-20db-4c23-ae89-b595da677d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert texts into lists \n",
    "X_total_lista = list()\n",
    "for x in df['Text']:\n",
    "    X_total_lista.append(str(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe2464-fa11-41ad-94ed-c9e91430e682",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4a680-cde3-43fb-939a-1a2191dd50c8",
   "metadata": {},
   "source": [
    "## Content Word Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9286c-6c26-4ccd-adf7-959ca43a798e",
   "metadata": {},
   "source": [
    "As part of our analysis we performed the count of the total content words within the paragraph, the total and percentage of unique content words, the total and percentage of names, verbs and adjectives (and unique ones) separately. \n",
    "\n",
    "This first section will focus on the extraction of these information regardless of the persuasion technique, while the following will consider each class separately (and will follow the same data preparation done for the general one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "42c0408c-5bef-4b00-a238-e8f64a0b2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3af6a223-5340-4008-8af3-774df75cbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  104659\n"
     ]
    }
   ],
   "source": [
    "total = \"\".join(X_total_lista)\n",
    "total_text = nlp(total)\n",
    "print(\"Total of tokens: \", len(total_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c58ddda2-126f-4bfc-9eaa-500105ac50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  34960\n",
      "Percentage of content words:  33.403720654697636\n",
      "Unique content word total:  6745\n",
      "Percentage of unique content words:  19.293478260869566\n",
      "\n",
      "NOUNS\n",
      "Noun total:  16940\n",
      "Percentage of nouns:  16.185898967121794\n",
      "Unique noun total:  3466\n",
      "Percentage of unique nouns:  20.460448642266822\n",
      "\n",
      "VERBS\n",
      "Verb total:  11234\n",
      "Percentage of verbs:  10.73390726072292\n",
      "Unique verb total:  1643\n",
      "Percentage of unique nouns:  14.62524479259391\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  6786\n",
      "Percentage of adjectives:  6.483914426852923\n",
      "Unique adjective total:  1636\n",
      "Percentage of unique adjectives:  24.10845859121721\n"
     ]
    }
   ],
   "source": [
    "# Counting the total of Content Words simultaneously and separately\n",
    "content_words_total = [(token.lemma_,token.pos_) for token in total_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total = [(token.lemma_,token.pos_) for token in total_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total = [(token.lemma_,token.pos_) for token in total_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total = [(token.lemma_,token.pos_) for token in total_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "# Printing the total, percentage and unique Content Words simultaneously and separately\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total))\n",
    "print(\"Percentage of content words: \", (len(content_words_total)/len(total_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total))/len(content_words_total)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total))\n",
    "print(\"Percentage of nouns: \", (len(noun_total)/len(total_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total))/len(noun_total)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total))\n",
    "print(\"Percentage of verbs: \", (len(verb_total)/len(total_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total))/len(verb_total)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total)/len(total_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total))/len(adj_total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fe370d52-0592-4ae0-a099-de62af3c651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 506), (('have', 'VERB'), 301), (('make', 'VERB'), 185), (('do', 'VERB'), 180), (('go', 'VERB'), 173), (('year', 'NOUN'), 170), (('take', 'VERB'), 161), (('people', 'NOUN'), 155), (('know', 'VERB'), 145), (('time', 'NOUN'), 138), (('tell', 'VERB'), 129), (('be', 'VERB'), 127), (('other', 'ADJ'), 125), (('come', 'VERB'), 120), (('man', 'NOUN'), 118), (('give', 'VERB'), 117), (('see', 'VERB'), 109), (('think', 'VERB'), 108), (('get', 'VERB'), 102), (('-', 'ADJ'), 101), (('case', 'NOUN'), 96), (('many', 'ADJ'), 95), (('report', 'NOUN'), 94), (('fact', 'NOUN'), 89), (('american', 'ADJ'), 88), (('former', 'ADJ'), 86), (('more', 'ADJ'), 83), (('call', 'VERB'), 82), (('’', 'VERB'), 82), (('include', 'VERB'), 82), (('write', 'VERB'), 81)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('year', 'NOUN'), 170), (('people', 'NOUN'), 155), (('time', 'NOUN'), 138), (('man', 'NOUN'), 118), (('case', 'NOUN'), 96), (('report', 'NOUN'), 94), (('fact', 'NOUN'), 89), (('law', 'NOUN'), 80), (('day', 'NOUN'), 77), (('investigation', 'NOUN'), 75), (('priest', 'NOUN'), 75), (('country', 'NOUN'), 73), (('evidence', 'NOUN'), 73), (('world', 'NOUN'), 71), (('government', 'NOUN'), 69), (('life', 'NOUN'), 66), (('medium', 'NOUN'), 66), (('way', 'NOUN'), 65), (('member', 'NOUN'), 65), (('thing', 'NOUN'), 65)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 506), (('have', 'VERB'), 301), (('make', 'VERB'), 185), (('do', 'VERB'), 180), (('go', 'VERB'), 173), (('take', 'VERB'), 161), (('know', 'VERB'), 145), (('tell', 'VERB'), 129), (('be', 'VERB'), 127), (('come', 'VERB'), 120), (('give', 'VERB'), 117), (('see', 'VERB'), 109), (('think', 'VERB'), 108), (('get', 'VERB'), 102), (('call', 'VERB'), 82), (('’', 'VERB'), 82), (('include', 'VERB'), 82), (('write', 'VERB'), 81), (('continue', 'VERB'), 80), (('find', 'VERB'), 78)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('other', 'ADJ'), 125), (('-', 'ADJ'), 101), (('many', 'ADJ'), 95), (('american', 'ADJ'), 88), (('former', 'ADJ'), 86), (('more', 'ADJ'), 83), (('new', 'ADJ'), 80), (('last', 'ADJ'), 76), (('public', 'ADJ'), 75), (('nuclear', 'ADJ'), 56), (('own', 'ADJ'), 54), (('sexual', 'ADJ'), 52), (('such', 'ADJ'), 51), (('anti', 'ADJ'), 50), (('good', 'ADJ'), 49), (('same', 'ADJ'), 49), (('first', 'ADJ'), 48), (('political', 'ADJ'), 44), (('clear', 'ADJ'), 43), (('true', 'ADJ'), 42), (('high', 'ADJ'), 39)]\n"
     ]
    }
   ],
   "source": [
    "# Counting and printing the most common Content Words simultaneously and separately\n",
    "count_content_words_total = Counter(content_words_total)\n",
    "count_noun_total = Counter(noun_total)\n",
    "count_verb_total = Counter(verb_total)\n",
    "count_adj_total = Counter(adj_total)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c97b9b35-6bae-45d7-8f57-5e6e0f9cc009",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85dcc2c8-70e1-4505-bf99-3ad6decb86f9",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94e8e796-7813-4954-ba7f-093ec556cf30",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b79cb27-f8e4-4ce0-a5c6-b424981aca06",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75247d-397c-4bdf-9c36-fab859c7743d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loaded_Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689160f0-f72a-4547-b73e-6690687a5b0a",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Loaded_Language class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ce41dd1c-b9d9-4de5-b77a-a60a4552bd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111111112</td>\n",
       "      <td>15</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>On both of their blogs the pair called their b...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111111112</td>\n",
       "      <td>30</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>A researcher with the organisation, Matthew Co...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111111113</td>\n",
       "      <td>10</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Lead attorney Matt Gonzalez has argued that th...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>111111115</td>\n",
       "      <td>9</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Leeann Tweeden, a radio news anchor, says Fran...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>111111115</td>\n",
       "      <td>13</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>A woman described as a \"former elected officia...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>999001619</td>\n",
       "      <td>8</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Nonetheless, this unverified allegation has be...</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>999001619</td>\n",
       "      <td>16</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>For the best part of a decade, any claims by A...</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>999001619</td>\n",
       "      <td>37</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Glenn Greenwald, who once had an influential c...</td>\n",
       "      <td>1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>999001621</td>\n",
       "      <td>16</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>The new sensational claim was immediately pick...</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>999001970</td>\n",
       "      <td>3</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>Andy Warhol was only half-right. In the future...</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph        Technique  \\\n",
       "5     111111112         15  Loaded_Language   \n",
       "9     111111112         30  Loaded_Language   \n",
       "10    111111113         10  Loaded_Language   \n",
       "13    111111115          9  Loaded_Language   \n",
       "14    111111115         13  Loaded_Language   \n",
       "...         ...        ...              ...   \n",
       "1845  999001619          8  Loaded_Language   \n",
       "1848  999001619         16  Loaded_Language   \n",
       "1857  999001619         37  Loaded_Language   \n",
       "1867  999001621         16  Loaded_Language   \n",
       "1874  999001970          3  Loaded_Language   \n",
       "\n",
       "                                                   Text    ID  \n",
       "5     On both of their blogs the pair called their b...     5  \n",
       "9     A researcher with the organisation, Matthew Co...     9  \n",
       "10    Lead attorney Matt Gonzalez has argued that th...    10  \n",
       "13    Leeann Tweeden, a radio news anchor, says Fran...    13  \n",
       "14    A woman described as a \"former elected officia...    14  \n",
       "...                                                 ...   ...  \n",
       "1845  Nonetheless, this unverified allegation has be...  1845  \n",
       "1848  For the best part of a decade, any claims by A...  1848  \n",
       "1857  Glenn Greenwald, who once had an influential c...  1857  \n",
       "1867  The new sensational claim was immediately pick...  1867  \n",
       "1874  Andy Warhol was only half-right. In the future...  1874  \n",
       "\n",
       "[806 rows x 5 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded_language = df.loc[(df['Technique'] == \"Loaded_Language\")]\n",
    "df_loaded_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "450f40be-39f0-420f-834e-43b4be2a92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loaded_language = list()\n",
    "for x in df_loaded_language['Text']:\n",
    "    X_loaded_language.append(str(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3e1d6cc6-2d9e-4f64-9aa8-554048f6c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loaded_language = list()\n",
    "for i in X_loaded_language:\n",
    "    doc_loaded_language.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "441e542e-eb39-44b8-896a-df76edf7c373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  46782\n"
     ]
    }
   ],
   "source": [
    "total_loaded = \"\".join(X_loaded_language)\n",
    "total_loaded_text = nlp(total_loaded)\n",
    "print(\"Total of tokens: \", len(total_loaded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a564b8cb-602e-4378-a5bc-80c2591b76fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  15701\n",
      "Percentage of content words:  33.5620537813689\n",
      "Unique content word total:  4661\n",
      "Percentage of unique content words:  29.686007260684033\n",
      "\n",
      "NOUNS\n",
      "Noun total:  7554\n",
      "Percentage of nouns:  16.147236116455048\n",
      "Unique noun total:  2325\n",
      "Percentage of unique nouns:  30.778395552025415\n",
      "\n",
      "VERBS\n",
      "Verb total:  4956\n",
      "Percentage of verbs:  10.593818135180197\n",
      "Unique verb total:  1213\n",
      "Percentage of unique nouns:  24.47538337368846\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  3191\n",
      "Percentage of adjectives:  6.820999529733658\n",
      "Unique adjective total:  1123\n",
      "Percentage of unique adjectives:  35.19272955186462\n"
     ]
    }
   ],
   "source": [
    "content_words_total_loaded = [(token.lemma_,token.pos_) for token in total_loaded_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_loaded = [(token.lemma_,token.pos_) for token in total_loaded_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_loaded = [(token.lemma_,token.pos_) for token in total_loaded_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_loaded = [(token.lemma_,token.pos_) for token in total_loaded_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_loaded))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_loaded)/len(total_loaded_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_loaded)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_loaded))/len(content_words_total_loaded)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_loaded))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_loaded)/len(total_loaded_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_loaded)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_loaded))/len(noun_total_loaded)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_loaded))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_loaded)/len(total_loaded_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_loaded)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_loaded))/len(verb_total_loaded)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_loaded))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_loaded)/len(total_loaded_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_loaded)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_loaded))/len(adj_total_loaded)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "176f35cc-dd56-443e-8548-2092f689aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 211), (('have', 'VERB'), 124), (('make', 'VERB'), 87), (('year', 'NOUN'), 76), (('time', 'NOUN'), 75), (('do', 'VERB'), 73), (('go', 'VERB'), 72), (('take', 'VERB'), 66), (('be', 'VERB'), 62), (('people', 'NOUN'), 61), (('other', 'ADJ'), 58), (('give', 'VERB'), 54), (('tell', 'VERB'), 54), (('know', 'VERB'), 53), (('come', 'VERB'), 53), (('man', 'NOUN'), 50), (('see', 'VERB'), 46), (('-', 'ADJ'), 45), (('law', 'NOUN'), 44), (('former', 'ADJ'), 43), (('fact', 'NOUN'), 43), (('public', 'ADJ'), 43), (('new', 'ADJ'), 41), (('continue', 'VERB'), 40), (('get', 'VERB'), 40), (('investigation', 'NOUN'), 40), (('abuse', 'NOUN'), 39), (('think', 'VERB'), 38), (('many', 'ADJ'), 38), (('part', 'NOUN'), 38), (('write', 'VERB'), 37)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('year', 'NOUN'), 76), (('time', 'NOUN'), 75), (('people', 'NOUN'), 61), (('man', 'NOUN'), 50), (('law', 'NOUN'), 44), (('fact', 'NOUN'), 43), (('investigation', 'NOUN'), 40), (('abuse', 'NOUN'), 39), (('part', 'NOUN'), 38), (('case', 'NOUN'), 37), (('report', 'NOUN'), 36), (('priest', 'NOUN'), 34), (('way', 'NOUN'), 33), (('story', 'NOUN'), 32), (('bishop', 'NOUN'), 32), (('country', 'NOUN'), 31), (('month', 'NOUN'), 29), (('day', 'NOUN'), 29), (('thing', 'NOUN'), 29), (('member', 'NOUN'), 29)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 211), (('have', 'VERB'), 124), (('make', 'VERB'), 87), (('do', 'VERB'), 73), (('go', 'VERB'), 72), (('take', 'VERB'), 66), (('be', 'VERB'), 62), (('give', 'VERB'), 54), (('tell', 'VERB'), 54), (('know', 'VERB'), 53), (('come', 'VERB'), 53), (('see', 'VERB'), 46), (('continue', 'VERB'), 40), (('get', 'VERB'), 40), (('think', 'VERB'), 38), (('write', 'VERB'), 37), (('include', 'VERB'), 33), (('’', 'VERB'), 33), (('ask', 'VERB'), 33), (('find', 'VERB'), 32)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('other', 'ADJ'), 58), (('-', 'ADJ'), 45), (('former', 'ADJ'), 43), (('public', 'ADJ'), 43), (('new', 'ADJ'), 41), (('many', 'ADJ'), 38), (('more', 'ADJ'), 37), (('last', 'ADJ'), 34), (('such', 'ADJ'), 28), (('first', 'ADJ'), 27), (('same', 'ADJ'), 27), (('political', 'ADJ'), 26), (('american', 'ADJ'), 26), (('sexual', 'ADJ'), 26), (('nuclear', 'ADJ'), 24), (('clear', 'ADJ'), 22), (('anti', 'ADJ'), 22), (('own', 'ADJ'), 22), (('religious', 'ADJ'), 20), (('least', 'ADJ'), 19), (('catholic', 'ADJ'), 19)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_loaded = Counter(content_words_total_loaded)\n",
    "count_noun_total_loaded = Counter(noun_total_loaded)\n",
    "count_verb_total_loaded = Counter(verb_total_loaded)\n",
    "count_adj_total_loaded = Counter(adj_total_loaded)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_loaded.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_loaded.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_loaded.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_loaded.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be078e1d-a2db-4b75-9dc4-be2a92999280",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_loaded)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6af92a-fbdb-4c49-9e3e-03ad14514a02",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_loaded)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_loaded)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_loaded)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c79c46f0-f2a6-4e69-baca-d000bf63731e",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_loaded))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b31e5d0a-f8ef-4a5b-8913-fb306b57d831",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_loaded))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_loaded))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25ee3c-b8c8-4758-a07e-bbf5fd5e07e3",
   "metadata": {},
   "source": [
    "### Name_Calling-Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446c29b-5411-4e7e-b47d-8bf2e1ca4f02",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Name_Calling-Labeling class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d87964c5-4a69-45c5-bec3-5ea07ee88bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111111112</td>\n",
       "      <td>23</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>It's embarrassing for this so-called land of d...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111111112</td>\n",
       "      <td>25</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>How many hate preachers are living in this cou...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>111111113</td>\n",
       "      <td>19</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>San Francisco prosecutors, who had long ago de...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>111111122</td>\n",
       "      <td>31</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>Some have speculated that Kavanaugh would be e...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111111124</td>\n",
       "      <td>5</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>The documents Trump ordered declassified invol...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>999001619</td>\n",
       "      <td>57</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>That clear partisanship should be no surprise,...</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>999001619</td>\n",
       "      <td>62</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>UPDATE: Excellent background from investigativ...</td>\n",
       "      <td>1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>999001621</td>\n",
       "      <td>34</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>In a series of tweets WikiLeaks said Assange a...</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>999001621</td>\n",
       "      <td>40</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>A day after the Guardian smear piece the Washi...</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>999001970</td>\n",
       "      <td>6</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>That's what Columbia snowflakes thought was of...</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph              Technique  \\\n",
       "7     111111112         23  Name_Calling-Labeling   \n",
       "8     111111112         25  Name_Calling-Labeling   \n",
       "11    111111113         19  Name_Calling-Labeling   \n",
       "20    111111122         31  Name_Calling-Labeling   \n",
       "24    111111124          5  Name_Calling-Labeling   \n",
       "...         ...        ...                    ...   \n",
       "1862  999001619         57  Name_Calling-Labeling   \n",
       "1863  999001619         62  Name_Calling-Labeling   \n",
       "1871  999001621         34  Name_Calling-Labeling   \n",
       "1872  999001621         40  Name_Calling-Labeling   \n",
       "1876  999001970          6  Name_Calling-Labeling   \n",
       "\n",
       "                                                   Text    ID  \n",
       "7     It's embarrassing for this so-called land of d...     7  \n",
       "8     How many hate preachers are living in this cou...     8  \n",
       "11    San Francisco prosecutors, who had long ago de...    11  \n",
       "20    Some have speculated that Kavanaugh would be e...    20  \n",
       "24    The documents Trump ordered declassified invol...    24  \n",
       "...                                                 ...   ...  \n",
       "1862  That clear partisanship should be no surprise,...  1862  \n",
       "1863  UPDATE: Excellent background from investigativ...  1863  \n",
       "1871  In a series of tweets WikiLeaks said Assange a...  1871  \n",
       "1872  A day after the Guardian smear piece the Washi...  1872  \n",
       "1876  That's what Columbia snowflakes thought was of...  1876  \n",
       "\n",
       "[318 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_name_calling = df.loc[(df['Technique'] == \"Name_Calling-Labeling\")]\n",
    "df_name_calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6b919941-7866-4a58-95ce-68442ddc7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_name_calling = list()\n",
    "for x in df_name_calling['Text']:\n",
    "    X_name_calling.append(str(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2402fb32-5652-4231-a20e-8924fde91793",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name_calling = list()\n",
    "for i in X_name_calling:\n",
    "    doc_name_calling.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "07556b6b-a754-40d0-b9f2-5fe5a29797f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  15846\n"
     ]
    }
   ],
   "source": [
    "total_calling = \"\".join(X_name_calling)\n",
    "total_calling_text = nlp(total_calling)\n",
    "print(\"Total of tokens: \", len(total_calling_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c86e7c7d-38ee-4735-905c-112769b8e9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  5165\n",
      "Percentage of content words:  32.59497665025874\n",
      "Unique content word total:  2251\n",
      "Percentage of unique content words:  43.58180058083253\n",
      "\n",
      "NOUNS\n",
      "Noun total:  2504\n",
      "Percentage of nouns:  15.802095165972485\n",
      "Unique noun total:  1141\n",
      "Percentage of unique nouns:  45.56709265175719\n",
      "\n",
      "VERBS\n",
      "Verb total:  1637\n",
      "Percentage of verbs:  10.330682822163322\n",
      "Unique verb total:  612\n",
      "Percentage of unique nouns:  37.38546120952962\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  1024\n",
      "Percentage of adjectives:  6.462198662122934\n",
      "Unique adjective total:  498\n",
      "Percentage of unique adjectives:  48.6328125\n"
     ]
    }
   ],
   "source": [
    "content_words_total_calling = [(token.lemma_,token.pos_) for token in total_calling_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_calling = [(token.lemma_,token.pos_) for token in total_calling_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_calling = [(token.lemma_,token.pos_) for token in total_calling_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_calling = [(token.lemma_,token.pos_) for token in total_calling_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_calling))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_calling)/len(total_calling_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_calling)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_calling))/len(content_words_total_calling)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_calling))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_calling)/len(total_calling_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_calling)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_calling))/len(noun_total_calling)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_calling))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_calling)/len(total_calling_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_calling)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_calling))/len(verb_total_calling)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_calling))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_calling)/len(total_calling_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_calling)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_calling))/len(adj_total_calling)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "68efb430-bb6a-4808-b963-1bde0e2784fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 54), (('have', 'VERB'), 36), (('year', 'NOUN'), 30), (('-', 'ADJ'), 27), (('make', 'VERB'), 26), (('do', 'VERB'), 25), (('former', 'ADJ'), 24), (('man', 'NOUN'), 23), (('take', 'VERB'), 23), (('think', 'VERB'), 21), (('other', 'ADJ'), 20), (('go', 'VERB'), 20), (('call', 'VERB'), 18), (('know', 'VERB'), 18), (('member', 'NOUN'), 18), (('priest', 'NOUN'), 18), (('time', 'NOUN'), 17), (('document', 'NOUN'), 16), (('tell', 'VERB'), 16), (('authority', 'NOUN'), 15), (('come', 'VERB'), 15), (('sexual', 'ADJ'), 15), (('find', 'VERB'), 15), (('child', 'NOUN'), 15), (('message', 'NOUN'), 14), (('give', 'VERB'), 14), (('medium', 'NOUN'), 14), (('try', 'VERB'), 14), (('president', 'NOUN'), 13), (('believe', 'VERB'), 13), (('include', 'VERB'), 13)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('year', 'NOUN'), 30), (('man', 'NOUN'), 23), (('member', 'NOUN'), 18), (('priest', 'NOUN'), 18), (('time', 'NOUN'), 17), (('document', 'NOUN'), 16), (('authority', 'NOUN'), 15), (('child', 'NOUN'), 15), (('message', 'NOUN'), 14), (('medium', 'NOUN'), 14), (('president', 'NOUN'), 13), (('government', 'NOUN'), 13), (('report', 'NOUN'), 13), (('day', 'NOUN'), 12), (('-', 'NOUN'), 12), (('person', 'NOUN'), 12), (('world', 'NOUN'), 12), (('compound', 'NOUN'), 12), (('case', 'NOUN'), 11), (('investigation', 'NOUN'), 11)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 54), (('have', 'VERB'), 36), (('make', 'VERB'), 26), (('do', 'VERB'), 25), (('take', 'VERB'), 23), (('think', 'VERB'), 21), (('go', 'VERB'), 20), (('call', 'VERB'), 18), (('know', 'VERB'), 18), (('tell', 'VERB'), 16), (('come', 'VERB'), 15), (('find', 'VERB'), 15), (('give', 'VERB'), 14), (('try', 'VERB'), 14), (('believe', 'VERB'), 13), (('include', 'VERB'), 13), (('write', 'VERB'), 13), (('claim', 'VERB'), 12), (('get', 'VERB'), 12), (('release', 'VERB'), 11)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('-', 'ADJ'), 27), (('former', 'ADJ'), 24), (('other', 'ADJ'), 20), (('sexual', 'ADJ'), 15), (('anti', 'ADJ'), 13), (('many', 'ADJ'), 12), (('own', 'ADJ'), 12), (('old', 'ADJ'), 10), (('good', 'ADJ'), 10), (('last', 'ADJ'), 10), (('more', 'ADJ'), 9), (('new', 'ADJ'), 8), (('great', 'ADJ'), 8), (('corrupt', 'ADJ'), 8), (('few', 'ADJ'), 7), (('nuclear', 'ADJ'), 7), (('muslim', 'ADJ'), 7), (('early', 'ADJ'), 7), (('progressive', 'ADJ'), 7), (('islamic', 'ADJ'), 7), (('legal', 'ADJ'), 6)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_calling = Counter(content_words_total_calling)\n",
    "count_noun_total_calling = Counter(noun_total_calling)\n",
    "count_verb_total_calling = Counter(verb_total_calling)\n",
    "count_adj_total_calling = Counter(adj_total_calling)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_calling.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_calling.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_calling.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_calling.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fb633e4-6eb4-4b7f-bd87-59834f558728",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_calling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8de7f929-52b5-4af5-a444-d5580c0e1d0d",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_calling)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_calling)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_calling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2986832e-9057-43cb-99ac-558620175e44",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_calling))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d90b42a-c666-42be-b4fb-62d0db270b71",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_calling))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_calling))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_calling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0636d5-d8e1-49b0-bf4f-7307eeae8783",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d237f83-efdf-46c4-a2a1-6cede4d86a11",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Repetition class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "321eea96-fdef-45be-bb47-8f6151e3a4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>13</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>But Tedros voiced alarm that \"plague in Madaga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>111111131</td>\n",
       "      <td>26</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>He is very talented, Trump said, citing Kim's ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>111111131</td>\n",
       "      <td>27</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>Kim assumed power after his father Kim Jong Il...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>111111131</td>\n",
       "      <td>42</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>Kim was cheered by onlookers who caught sight ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>111111134</td>\n",
       "      <td>11</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>“I have never met Julian Assange or anyone con...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>999001280</td>\n",
       "      <td>16</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>Every media outlet from the Associated Press t...</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>999001280</td>\n",
       "      <td>17</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>But it's more than that, self-proclaimed \"fact...</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>999001290</td>\n",
       "      <td>21</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>In speaking about the rules and regulations th...</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>999001297</td>\n",
       "      <td>13</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>The first group of the migrant caravan arrived...</td>\n",
       "      <td>1834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>999001621</td>\n",
       "      <td>24</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>“I have never met Julian Assange or anyone con...</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph   Technique  \\\n",
       "1     111111111         13  Repetition   \n",
       "39    111111131         26  Repetition   \n",
       "40    111111131         27  Repetition   \n",
       "43    111111131         42  Repetition   \n",
       "61    111111134         11  Repetition   \n",
       "...         ...        ...         ...   \n",
       "1813  999001280         16  Repetition   \n",
       "1814  999001280         17  Repetition   \n",
       "1825  999001290         21  Repetition   \n",
       "1834  999001297         13  Repetition   \n",
       "1869  999001621         24  Repetition   \n",
       "\n",
       "                                                   Text    ID  \n",
       "1     But Tedros voiced alarm that \"plague in Madaga...     1  \n",
       "39    He is very talented, Trump said, citing Kim's ...    39  \n",
       "40    Kim assumed power after his father Kim Jong Il...    40  \n",
       "43    Kim was cheered by onlookers who caught sight ...    43  \n",
       "61    “I have never met Julian Assange or anyone con...    61  \n",
       "...                                                 ...   ...  \n",
       "1813  Every media outlet from the Associated Press t...  1813  \n",
       "1814  But it's more than that, self-proclaimed \"fact...  1814  \n",
       "1825  In speaking about the rules and regulations th...  1825  \n",
       "1834  The first group of the migrant caravan arrived...  1834  \n",
       "1869  “I have never met Julian Assange or anyone con...  1869  \n",
       "\n",
       "[218 rows x 5 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repetition = df.loc[(df['Technique'] == \"Repetition\")]\n",
    "df_repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "262d0ffc-6c90-4413-9f9c-07a88d30137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_repetition = list()\n",
    "for x in df_repetition['Text']:\n",
    "    X_repetition.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1ca164b2-a4c3-43f6-be94-31d19f9609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_repetition = list()\n",
    "for i in X_repetition:\n",
    "    doc_repetition.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dab7146b-f29a-4cc5-8368-4959e375f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  12820\n"
     ]
    }
   ],
   "source": [
    "total_repetition = \"\".join(X_repetition)\n",
    "total_repetition_text = nlp(total_repetition)\n",
    "print(\"Total of tokens: \", len(total_repetition_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f2336d0e-bf99-4c97-9f10-e5ddc9036860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  4336\n",
      "Percentage of content words:  33.82215288611544\n",
      "Unique content word total:  1811\n",
      "Percentage of unique content words:  41.76660516605166\n",
      "\n",
      "NOUNS\n",
      "Noun total:  2148\n",
      "Percentage of nouns:  16.755070202808113\n",
      "Unique noun total:  936\n",
      "Percentage of unique nouns:  43.575418994413404\n",
      "\n",
      "VERBS\n",
      "Verb total:  1352\n",
      "Percentage of verbs:  10.546021840873635\n",
      "Unique verb total:  482\n",
      "Percentage of unique nouns:  35.650887573964496\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  836\n",
      "Percentage of adjectives:  6.521060842433697\n",
      "Unique adjective total:  393\n",
      "Percentage of unique adjectives:  47.00956937799043\n"
     ]
    }
   ],
   "source": [
    "content_words_total_repetition = [(token.lemma_,token.pos_) for token in total_repetition_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_repetition = [(token.lemma_,token.pos_) for token in total_repetition_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_repetition = [(token.lemma_,token.pos_) for token in total_repetition_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_repetition = [(token.lemma_,token.pos_) for token in total_repetition_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_repetition))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_repetition)/len(total_repetition_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_repetition)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_repetition))/len(content_words_total_repetition)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_repetition))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_repetition)/len(total_repetition_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_repetition)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_repetition))/len(noun_total_repetition)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_repetition))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_repetition)/len(total_repetition_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_repetition)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_repetition))/len(verb_total_repetition)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_repetition))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_repetition)/len(total_repetition_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_repetition)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_repetition))/len(adj_total_repetition)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f0609032-bdf9-4512-a857-783089b7af4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 68), (('have', 'VERB'), 45), (('year', 'NOUN'), 27), (('do', 'VERB'), 25), (('people', 'NOUN'), 24), (('go', 'VERB'), 24), (('make', 'VERB'), 23), (('know', 'VERB'), 23), (('be', 'VERB'), 21), (('other', 'ADJ'), 21), (('autonomy', 'NOUN'), 21), (('think', 'VERB'), 20), (('man', 'NOUN'), 19), (('school', 'NOUN'), 19), (('monastery', 'NOUN'), 19), (('life', 'NOUN'), 18), (('parent', 'NOUN'), 18), (('take', 'VERB'), 17), (('come', 'VERB'), 17), (('get', 'VERB'), 16), (('case', 'NOUN'), 16), (('see', 'VERB'), 16), (('illegal', 'ADJ'), 16), (('alien', 'NOUN'), 16), (('give', 'VERB'), 16), (('priest', 'NOUN'), 16), (('-', 'ADJ'), 15), (('tell', 'VERB'), 15), (('last', 'ADJ'), 14), (('fact', 'NOUN'), 14), (('evidence', 'NOUN'), 14)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('year', 'NOUN'), 27), (('people', 'NOUN'), 24), (('autonomy', 'NOUN'), 21), (('man', 'NOUN'), 19), (('school', 'NOUN'), 19), (('monastery', 'NOUN'), 19), (('life', 'NOUN'), 18), (('parent', 'NOUN'), 18), (('case', 'NOUN'), 16), (('alien', 'NOUN'), 16), (('priest', 'NOUN'), 16), (('fact', 'NOUN'), 14), (('evidence', 'NOUN'), 14), (('child', 'NOUN'), 14), (('document', 'NOUN'), 12), (('thing', 'NOUN'), 12), (('curriculum', 'NOUN'), 12), (('affidavit', 'NOUN'), 12), (('gun', 'NOUN'), 11), (('time', 'NOUN'), 11)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 68), (('have', 'VERB'), 45), (('do', 'VERB'), 25), (('go', 'VERB'), 24), (('make', 'VERB'), 23), (('know', 'VERB'), 23), (('be', 'VERB'), 21), (('think', 'VERB'), 20), (('take', 'VERB'), 17), (('come', 'VERB'), 17), (('get', 'VERB'), 16), (('see', 'VERB'), 16), (('give', 'VERB'), 16), (('tell', 'VERB'), 15), (('’', 'VERB'), 12), (('seem', 'VERB'), 12), (('include', 'VERB'), 11), (('kill', 'VERB'), 11), (('allow', 'VERB'), 11), (('ask', 'VERB'), 11)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('other', 'ADJ'), 21), (('illegal', 'ADJ'), 16), (('-', 'ADJ'), 15), (('last', 'ADJ'), 14), (('new', 'ADJ'), 14), (('more', 'ADJ'), 12), (('public', 'ADJ'), 12), (('many', 'ADJ'), 11), (('young', 'ADJ'), 10), (('nuclear', 'ADJ'), 9), (('russian', 'ADJ'), 8), (('potential', 'ADJ'), 8), (('autonomous', 'ADJ'), 8), (('clear', 'ADJ'), 7), (('same', 'ADJ'), 7), (('wrong', 'ADJ'), 7), (('innocent', 'ADJ'), 7), (('anti', 'ADJ'), 6), (('least', 'ADJ'), 6), (('global', 'ADJ'), 6), (('legal', 'ADJ'), 6)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_repetition = Counter(content_words_total_repetition)\n",
    "count_noun_total_repetition = Counter(noun_total_repetition)\n",
    "count_verb_total_repetition = Counter(verb_total_repetition)\n",
    "count_adj_total_repetition = Counter(adj_total_repetition)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_repetition.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_repetition.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_repetition.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_repetition.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "781f2b89-a12f-47e2-89ea-2d710dc09a16",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_repetition)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d2b63b5-bc47-4809-9aa5-4f9ccd6e3409",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_repetition)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_repetition)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_repetition)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a30d627-7eb5-4ea4-8040-e1735b72f5f7",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_repetition))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db90c133-516c-430a-9c54-575a0deb3ebb",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_repetition))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_repetition))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_repetition))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb3650-fc41-48c4-9dfb-559a86110091",
   "metadata": {},
   "source": [
    "### Doubt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f740e7c-92ad-42b7-bea6-33468e8395d6",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Doubt class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "99535a1e-522f-4653-a665-2b9190778823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>3</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>Geneva - The World Health Organisation chief o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>111111122</td>\n",
       "      <td>21</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>It’s also the case that the more negative info...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>111111135</td>\n",
       "      <td>28</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>Why were Tamika Mallory and Danny Davis reluct...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>694356862</td>\n",
       "      <td>11</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>Whether the Trump administration follows throu...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>694811415</td>\n",
       "      <td>1</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>“It’s gotta be a set-up”: Neighbor of Las Vega...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>999001619</td>\n",
       "      <td>47</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>Similarly, the Guardian worked tirelessly to p...</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>999001621</td>\n",
       "      <td>1</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
       "      <td>1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>999001621</td>\n",
       "      <td>4</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>This Guardian Fake News Story Proves That The ...</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>999001621</td>\n",
       "      <td>18</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>The story was weakly sourced and included some...</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>999001621</td>\n",
       "      <td>41</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>The story was completely false and the Guardia...</td>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph Technique  \\\n",
       "0     111111111          3     Doubt   \n",
       "18    111111122         21     Doubt   \n",
       "66    111111135         28     Doubt   \n",
       "87    694356862         11     Doubt   \n",
       "88    694811415          1     Doubt   \n",
       "...         ...        ...       ...   \n",
       "1861  999001619         47     Doubt   \n",
       "1864  999001621          1     Doubt   \n",
       "1865  999001621          4     Doubt   \n",
       "1868  999001621         18     Doubt   \n",
       "1873  999001621         41     Doubt   \n",
       "\n",
       "                                                   Text    ID  \n",
       "0     Geneva - The World Health Organisation chief o...     0  \n",
       "18    It’s also the case that the more negative info...    18  \n",
       "66    Why were Tamika Mallory and Danny Davis reluct...    66  \n",
       "87    Whether the Trump administration follows throu...    87  \n",
       "88    “It’s gotta be a set-up”: Neighbor of Las Vega...    88  \n",
       "...                                                 ...   ...  \n",
       "1861  Similarly, the Guardian worked tirelessly to p...  1861  \n",
       "1864  This Guardian Fake News Story Proves That The ...  1864  \n",
       "1865  This Guardian Fake News Story Proves That The ...  1865  \n",
       "1868  The story was weakly sourced and included some...  1868  \n",
       "1873  The story was completely false and the Guardia...  1873  \n",
       "\n",
       "[210 rows x 5 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doubt = df.loc[(df['Technique'] == \"Doubt\")]\n",
    "df_doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4e62aa87-111b-4c4e-bbdc-a93e9e91536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doubt = list()\n",
    "for x in df_doubt['Text']:\n",
    "    X_doubt.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "170ad953-d11e-48cc-ad44-bfa8ab63fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_doubt = list()\n",
    "for i in X_doubt:\n",
    "    doc_doubt.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cc31ba41-998a-4223-82e8-0e9c00146f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  11722\n"
     ]
    }
   ],
   "source": [
    "total_doubt = \"\".join(X_doubt)\n",
    "total_doubt_text = nlp(total_doubt)\n",
    "print(\"Total of tokens: \", len(total_doubt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5338392b-050e-4b9c-b934-b1d02065645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  3929\n",
      "Percentage of content words:  33.51817096058693\n",
      "Unique content word total:  1601\n",
      "Percentage of unique content words:  40.74828200559939\n",
      "\n",
      "NOUNS\n",
      "Noun total:  1933\n",
      "Percentage of nouns:  16.490360006824776\n",
      "Unique noun total:  799\n",
      "Percentage of unique nouns:  41.3347128815313\n",
      "\n",
      "VERBS\n",
      "Verb total:  1376\n",
      "Percentage of verbs:  11.738611158505375\n",
      "Unique verb total:  475\n",
      "Percentage of unique nouns:  34.520348837209305\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  620\n",
      "Percentage of adjectives:  5.289199795256782\n",
      "Unique adjective total:  327\n",
      "Percentage of unique adjectives:  52.741935483870975\n"
     ]
    }
   ],
   "source": [
    "content_words_total_doubt = [(token.lemma_,token.pos_) for token in total_doubt_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_doubt = [(token.lemma_,token.pos_) for token in total_doubt_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_doubt = [(token.lemma_,token.pos_) for token in total_doubt_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_doubt = [(token.lemma_,token.pos_) for token in total_doubt_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_doubt))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_doubt)/len(total_doubt_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_doubt)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_doubt))/len(content_words_total_doubt)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_doubt))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_doubt)/len(total_doubt_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_doubt)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_doubt))/len(noun_total_doubt)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_doubt))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_doubt)/len(total_doubt_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_doubt)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_doubt))/len(verb_total_doubt)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_doubt))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_doubt)/len(total_doubt_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_doubt)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_doubt))/len(adj_total_doubt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e15d4692-fe26-497b-8fb0-e3110f079b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 76), (('have', 'VERB'), 41), (('police', 'NOUN'), 28), (('know', 'VERB'), 27), (('report', 'NOUN'), 25), (('do', 'VERB'), 22), (('shooting', 'NOUN'), 22), (('tell', 'VERB'), 22), (('take', 'VERB'), 21), (('go', 'VERB'), 18), (('see', 'VERB'), 17), (('question', 'NOUN'), 17), (('p.m.', 'NOUN'), 17), (('time', 'NOUN'), 17), (('case', 'NOUN'), 16), (('make', 'VERB'), 16), (('give', 'VERB'), 16), (('fail', 'VERB'), 15), (('guard', 'NOUN'), 15), (('be', 'VERB'), 15), (('ask', 'VERB'), 15), (('’', 'VERB'), 14), (('information', 'NOUN'), 14), (('day', 'NOUN'), 14), (('investigation', 'NOUN'), 14), (('evidence', 'NOUN'), 14), (('hotel', 'NOUN'), 14), (('security', 'NOUN'), 14), (('provide', 'VERB'), 14), (('get', 'VERB'), 14), (('medium', 'NOUN'), 13)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('police', 'NOUN'), 28), (('report', 'NOUN'), 25), (('shooting', 'NOUN'), 22), (('question', 'NOUN'), 17), (('p.m.', 'NOUN'), 17), (('time', 'NOUN'), 17), (('case', 'NOUN'), 16), (('guard', 'NOUN'), 15), (('information', 'NOUN'), 14), (('day', 'NOUN'), 14), (('investigation', 'NOUN'), 14), (('evidence', 'NOUN'), 14), (('hotel', 'NOUN'), 14), (('security', 'NOUN'), 14), (('medium', 'NOUN'), 13), (('officer', 'NOUN'), 13), (('people', 'NOUN'), 13), (('man', 'NOUN'), 13), (('room', 'NOUN'), 12), (('floor', 'NOUN'), 12)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 76), (('have', 'VERB'), 41), (('know', 'VERB'), 27), (('do', 'VERB'), 22), (('tell', 'VERB'), 22), (('take', 'VERB'), 21), (('go', 'VERB'), 18), (('see', 'VERB'), 17), (('make', 'VERB'), 16), (('give', 'VERB'), 16), (('fail', 'VERB'), 15), (('be', 'VERB'), 15), (('ask', 'VERB'), 15), (('’', 'VERB'), 14), (('provide', 'VERB'), 14), (('get', 'VERB'), 14), (('come', 'VERB'), 12), (('find', 'VERB'), 12), (('accord', 'VERB'), 12), (('fire', 'VERB'), 12)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('many', 'ADJ'), 13), (('other', 'ADJ'), 11), (('more', 'ADJ'), 10), (('own', 'ADJ'), 9), (('32nd', 'ADJ'), 9), (('such', 'ADJ'), 8), (('federal', 'ADJ'), 8), (('last', 'ADJ'), 7), (('entire', 'ADJ'), 7), (('new', 'ADJ'), 7), (('true', 'ADJ'), 7), (('few', 'ADJ'), 6), (('serious', 'ADJ'), 6), (('same', 'ADJ'), 6), (('important', 'ADJ'), 6), (('several', 'ADJ'), 6), (('-', 'ADJ'), 6), (('first', 'ADJ'), 6), (('former', 'ADJ'), 6), (('democratic', 'ADJ'), 6), (('right', 'ADJ'), 5)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_doubt = Counter(content_words_total_doubt)\n",
    "count_noun_total_doubt = Counter(noun_total_doubt)\n",
    "count_verb_total_doubt = Counter(verb_total_doubt)\n",
    "count_adj_total_doubt = Counter(adj_total_doubt)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_doubt.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_doubt.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_doubt.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_doubt.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7fdb786-7ca2-4706-80f2-8d3e9c44d293",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_doubt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d6df69c-e664-4305-b0d4-8136a6a9def0",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_doubt)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_doubt)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_doubt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90948e2a-b566-42e5-ba7e-60cbbe30d332",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_doubt))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6334dff-9d68-440e-b953-1f7d5c57dac5",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_doubt))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_doubt))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_doubt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706460ab-319a-4e14-a87f-8bbe9a548a96",
   "metadata": {},
   "source": [
    "### Appeal_to_Fear-Prejudice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd44aa-2b37-4910-a70a-253baa5e2246",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Appeal_to_Fear-Prejudice class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f133195a-5a67-496c-b510-32b5516347da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111111</td>\n",
       "      <td>17</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111111</td>\n",
       "      <td>19</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>He praised the rapid response from WHO and Mad...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111111</td>\n",
       "      <td>25</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>That means that Madagascar could be affected m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>111111114</td>\n",
       "      <td>25</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Members of the group and advocates say they fe...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>694327499</td>\n",
       "      <td>37</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>In a sense, what Bergoglio is doing is worse t...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>999000159</td>\n",
       "      <td>12</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>So it is crucial that you and your pro-gun fri...</td>\n",
       "      <td>1730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>999000565</td>\n",
       "      <td>6</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>Watch this leftist loon pour her beverage on F...</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>999000565</td>\n",
       "      <td>7</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>WATCH: Angry leftist pours her beverage on FSU...</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>999000874</td>\n",
       "      <td>15</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>“If left unchallenged, the actions of the Whit...</td>\n",
       "      <td>1767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>999001293</td>\n",
       "      <td>12</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>This massive Democrat voter fraud could be the...</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph                 Technique  \\\n",
       "2     111111111         17  Appeal_to_Fear-Prejudice   \n",
       "3     111111111         19  Appeal_to_Fear-Prejudice   \n",
       "4     111111111         25  Appeal_to_Fear-Prejudice   \n",
       "12    111111114         25  Appeal_to_Fear-Prejudice   \n",
       "82    694327499         37  Appeal_to_Fear-Prejudice   \n",
       "...         ...        ...                       ...   \n",
       "1730  999000159         12  Appeal_to_Fear-Prejudice   \n",
       "1738  999000565          6  Appeal_to_Fear-Prejudice   \n",
       "1739  999000565          7  Appeal_to_Fear-Prejudice   \n",
       "1767  999000874         15  Appeal_to_Fear-Prejudice   \n",
       "1830  999001293         12  Appeal_to_Fear-Prejudice   \n",
       "\n",
       "                                                   Text    ID  \n",
       "2     He also pointed to the presence of the pneumon...     2  \n",
       "3     He praised the rapid response from WHO and Mad...     3  \n",
       "4     That means that Madagascar could be affected m...     4  \n",
       "12    Members of the group and advocates say they fe...    12  \n",
       "82    In a sense, what Bergoglio is doing is worse t...    82  \n",
       "...                                                 ...   ...  \n",
       "1730  So it is crucial that you and your pro-gun fri...  1730  \n",
       "1738  Watch this leftist loon pour her beverage on F...  1738  \n",
       "1739  WATCH: Angry leftist pours her beverage on FSU...  1739  \n",
       "1767  “If left unchallenged, the actions of the Whit...  1767  \n",
       "1830  This massive Democrat voter fraud could be the...  1830  \n",
       "\n",
       "[122 rows x 5 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prejudice = df.loc[(df['Technique'] == \"Appeal_to_Fear-Prejudice\")]\n",
    "df_prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b457b690-f6d4-4bcf-9032-97df4385cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prejudice = list()\n",
    "for x in df_prejudice['Text']:\n",
    "    X_prejudice.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ad56f1ed-8742-487d-803a-3b17d0f56a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_prejudice = list()\n",
    "for i in X_prejudice:\n",
    "    doc_prejudice.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "abacdcbe-f6fa-4a1a-b898-53852e777add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  6748\n"
     ]
    }
   ],
   "source": [
    "total_prejudice = \"\".join(X_prejudice)\n",
    "total_prejudice_text = nlp(total_prejudice)\n",
    "print(\"Total of tokens: \", len(total_prejudice_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c07901d1-9100-4391-b2c8-aecf24b8e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  2231\n",
      "Percentage of content words:  33.06164789567279\n",
      "Unique content word total:  1171\n",
      "Percentage of unique content words:  52.48767368892872\n",
      "\n",
      "NOUNS\n",
      "Noun total:  1043\n",
      "Percentage of nouns:  15.45643153526971\n",
      "Unique noun total:  597\n",
      "Percentage of unique nouns:  57.238734419942475\n",
      "\n",
      "VERBS\n",
      "Verb total:  749\n",
      "Percentage of verbs:  11.099585062240664\n",
      "Unique verb total:  341\n",
      "Percentage of unique nouns:  45.52736982643525\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  439\n",
      "Percentage of adjectives:  6.505631298162419\n",
      "Unique adjective total:  233\n",
      "Percentage of unique adjectives:  53.075170842824605\n"
     ]
    }
   ],
   "source": [
    "content_words_total_prejudice = [(token.lemma_,token.pos_) for token in total_prejudice_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_prejudice = [(token.lemma_,token.pos_) for token in total_prejudice_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_prejudice = [(token.lemma_,token.pos_) for token in total_prejudice_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_prejudice = [(token.lemma_,token.pos_) for token in total_prejudice_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_prejudice))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_prejudice)/len(total_prejudice_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_prejudice)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_prejudice))/len(content_words_total_prejudice)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_prejudice))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_prejudice)/len(total_prejudice_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_prejudice)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_prejudice))/len(noun_total_prejudice)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_prejudice))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_prejudice)/len(total_prejudice_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_prejudice)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_prejudice))/len(verb_total_prejudice)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_prejudice))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_prejudice)/len(total_prejudice_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_prejudice)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_prejudice))/len(adj_total_prejudice)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ab05ccef-4a4a-4737-8c9f-9fad21285367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 36), (('have', 'VERB'), 19), (('do', 'VERB'), 18), (('go', 'VERB'), 18), (('many', 'ADJ'), 15), (('disease', 'NOUN'), 13), (('spread', 'VERB'), 12), (('country', 'NOUN'), 12), (('world', 'NOUN'), 11), (('ally', 'NOUN'), 11), (('take', 'VERB'), 11), (('people', 'NOUN'), 11), (('get', 'VERB'), 10), (('nuclear', 'ADJ'), 10), (('year', 'NOUN'), 10), (('continue', 'VERB'), 9), (('be', 'VERB'), 9), (('know', 'VERB'), 9), (('kill', 'VERB'), 9), (('enter', 'VERB'), 9), (('want', 'VERB'), 8), (('write', 'VERB'), 8), (('outbreak', 'NOUN'), 7), (('large', 'ADJ'), 7), (('deal', 'NOUN'), 7), (('military', 'ADJ'), 7), (('case', 'NOUN'), 7), (('warn', 'VERB'), 6), (('heresy', 'NOUN'), 6), (('call', 'VERB'), 6), (('issue', 'VERB'), 6)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('disease', 'NOUN'), 13), (('country', 'NOUN'), 12), (('world', 'NOUN'), 11), (('ally', 'NOUN'), 11), (('people', 'NOUN'), 11), (('year', 'NOUN'), 10), (('outbreak', 'NOUN'), 7), (('deal', 'NOUN'), 7), (('case', 'NOUN'), 7), (('heresy', 'NOUN'), 6), (('health', 'NOUN'), 6), (('plague', 'NOUN'), 6), (('war', 'NOUN'), 6), (('risk', 'NOUN'), 6), (('faith', 'NOUN'), 6), (('virus', 'NOUN'), 6), (('presence', 'NOUN'), 5), (('threat', 'NOUN'), 5), (('term', 'NOUN'), 5), (('point', 'NOUN'), 5)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 36), (('have', 'VERB'), 19), (('do', 'VERB'), 18), (('go', 'VERB'), 18), (('spread', 'VERB'), 12), (('take', 'VERB'), 11), (('get', 'VERB'), 10), (('continue', 'VERB'), 9), (('be', 'VERB'), 9), (('know', 'VERB'), 9), (('kill', 'VERB'), 9), (('enter', 'VERB'), 9), (('want', 'VERB'), 8), (('write', 'VERB'), 8), (('warn', 'VERB'), 6), (('call', 'VERB'), 6), (('issue', 'VERB'), 6), (('include', 'VERB'), 6), (('make', 'VERB'), 6), (('believe', 'VERB'), 6)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('many', 'ADJ'), 15), (('nuclear', 'ADJ'), 10), (('large', 'ADJ'), 7), (('military', 'ADJ'), 7), (('senior', 'ADJ'), 6), (('other', 'ADJ'), 6), (('muslim', 'ADJ'), 5), (('bad', 'ADJ'), 5), (('such', 'ADJ'), 5), (('own', 'ADJ'), 5), (('impossible', 'ADJ'), 5), (('more', 'ADJ'), 5), (('serious', 'ADJ'), 5), (('true', 'ADJ'), 5), (('right', 'ADJ'), 5), (('iranian', 'ADJ'), 4), (('last', 'ADJ'), 4), (('major', 'ADJ'), 4), (('syrian', 'ADJ'), 4), (('terrorist', 'ADJ'), 4), (('former', 'ADJ'), 4)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_prejudice = Counter(content_words_total_prejudice)\n",
    "count_noun_total_prejudice = Counter(noun_total_prejudice)\n",
    "count_verb_total_prejudice = Counter(verb_total_prejudice)\n",
    "count_adj_total_prejudice = Counter(adj_total_prejudice)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_prejudice.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_prejudice.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_prejudice.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_prejudice.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d370d225-6707-4d9c-a288-6a1aae82e06e",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_prejudice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d5907b6-9d8e-45a0-b3a6-dd17a26e9fad",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_prejudice)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_prejudice)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_prejudice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "433eb939-6f98-4a3f-ab2f-32472627de6c",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_prejudice))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac9708d8-6dc3-4389-8bf5-7c50dbea9211",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_prejudice))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_prejudice))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_prejudice))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ad7c6-a1a8-4d2f-8cc0-e67cdc025405",
   "metadata": {},
   "source": [
    "### Exaggeration-Minimisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c0460-2a53-45a4-80d7-90608534a48f",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Exaggeration-Minimisation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "42159db0-b669-4d7f-9402-f542e52149a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Technique</th>\n",
       "      <th>Text</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111111122</td>\n",
       "      <td>19</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>For one thing, the president has made this an ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>111111124</td>\n",
       "      <td>24</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>The source added that the Justice Department i...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>111111134</td>\n",
       "      <td>15</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>And WikiLeaks said on Twitter that it was “wil...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>111111135</td>\n",
       "      <td>48</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>Representative Davis, who was interviewed by T...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>111111137</td>\n",
       "      <td>3</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>New gun control measures for Florida have pass...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>999001290</td>\n",
       "      <td>27</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>Well, I can't wait to see the next press confe...</td>\n",
       "      <td>1828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>999001621</td>\n",
       "      <td>13</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>Manafort held secret talks with Assange in Ecu...</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>999001621</td>\n",
       "      <td>32</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>Manafort, 69, denies involvement in the hack a...</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>999001970</td>\n",
       "      <td>5</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>Saturday Night Live writer and comedian Nimesh...</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>999001970</td>\n",
       "      <td>13</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>I'm sure Patel felt very, like, accepted.</td>\n",
       "      <td>1877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Article  Paragraph                  Technique  \\\n",
       "17    111111122         19  Exaggeration-Minimisation   \n",
       "27    111111124         24  Exaggeration-Minimisation   \n",
       "62    111111134         15  Exaggeration-Minimisation   \n",
       "69    111111135         48  Exaggeration-Minimisation   \n",
       "73    111111137          3  Exaggeration-Minimisation   \n",
       "...         ...        ...                        ...   \n",
       "1828  999001290         27  Exaggeration-Minimisation   \n",
       "1866  999001621         13  Exaggeration-Minimisation   \n",
       "1870  999001621         32  Exaggeration-Minimisation   \n",
       "1875  999001970          5  Exaggeration-Minimisation   \n",
       "1877  999001970         13  Exaggeration-Minimisation   \n",
       "\n",
       "                                                   Text    ID  \n",
       "17    For one thing, the president has made this an ...    17  \n",
       "27    The source added that the Justice Department i...    27  \n",
       "62    And WikiLeaks said on Twitter that it was “wil...    62  \n",
       "69    Representative Davis, who was interviewed by T...    69  \n",
       "73    New gun control measures for Florida have pass...    73  \n",
       "...                                                 ...   ...  \n",
       "1828  Well, I can't wait to see the next press confe...  1828  \n",
       "1866  Manafort held secret talks with Assange in Ecu...  1866  \n",
       "1870  Manafort, 69, denies involvement in the hack a...  1870  \n",
       "1875  Saturday Night Live writer and comedian Nimesh...  1875  \n",
       "1877          I'm sure Patel felt very, like, accepted.  1877  \n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ex_min = df.loc[(df['Technique'] == \"Exaggeration-Minimisation\")]\n",
    "df_ex_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "662972ae-2222-48ad-bb15-0c4e38d9d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex_min = list()\n",
    "for x in df_ex_min['Text']:\n",
    "    X_ex_min.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1b4b3402-eb22-4ca8-8b12-6bc091436fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ex_min = list()\n",
    "for i in X_ex_min:\n",
    "    doc_ex_min.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9947343e-d8cb-49a0-9dc0-24dd5e3abad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  5613\n"
     ]
    }
   ],
   "source": [
    "total_ex_min = \"\".join(X_ex_min)\n",
    "total_ex_min_text = nlp(total_ex_min)\n",
    "print(\"Total of tokens: \", len(total_ex_min_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d8e0940f-7d8b-44f4-ad97-9bba7f4d243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  1888\n",
      "Percentage of content words:  33.63620167468377\n",
      "Unique content word total:  1044\n",
      "Percentage of unique content words:  55.29661016949152\n",
      "\n",
      "NOUNS\n",
      "Noun total:  907\n",
      "Percentage of nouns:  16.158916800285052\n",
      "Unique noun total:  524\n",
      "Percentage of unique nouns:  57.7728776185226\n",
      "\n",
      "VERBS\n",
      "Verb total:  598\n",
      "Percentage of verbs:  10.653839301621236\n",
      "Unique verb total:  294\n",
      "Percentage of unique nouns:  49.163879598662206\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  383\n",
      "Percentage of adjectives:  6.823445572777481\n",
      "Unique adjective total:  226\n",
      "Percentage of unique adjectives:  59.00783289817232\n"
     ]
    }
   ],
   "source": [
    "content_words_total_ex_min = [(token.lemma_,token.pos_) for token in total_ex_min_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_ex_min = [(token.lemma_,token.pos_) for token in total_ex_min_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_ex_min = [(token.lemma_,token.pos_) for token in total_ex_min_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_ex_min = [(token.lemma_,token.pos_) for token in total_ex_min_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_ex_min))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_ex_min)/len(total_ex_min_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_ex_min)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_ex_min))/len(content_words_total_ex_min)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_ex_min))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_ex_min)/len(total_ex_min_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_ex_min)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_ex_min))/len(noun_total_ex_min)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_ex_min))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_ex_min)/len(total_ex_min_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_ex_min)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_ex_min))/len(verb_total_ex_min)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_ex_min))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_ex_min)/len(total_ex_min_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_ex_min)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_ex_min))/len(adj_total_ex_min)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5f39dd7d-a3fc-4f36-85c6-cfc1e44144f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('say', 'VERB'), 30), (('make', 'VERB'), 16), (('go', 'VERB'), 14), (('come', 'VERB'), 11), (('have', 'VERB'), 10), (('history', 'NOUN'), 10), (('tell', 'VERB'), 10), (('do', 'VERB'), 10), (('take', 'VERB'), 9), (('government', 'NOUN'), 9), (('evidence', 'NOUN'), 9), (('give', 'VERB'), 9), (('man', 'NOUN'), 9), (('world', 'NOUN'), 9), (('see', 'VERB'), 9), (('gun', 'NOUN'), 8), (('year', 'NOUN'), 8), (('official', 'NOUN'), 8), (('life', 'NOUN'), 8), (('thing', 'NOUN'), 7), (('happen', 'VERB'), 7), (('time', 'NOUN'), 7), (('be', 'VERB'), 7), (('case', 'NOUN'), 7), (('month', 'NOUN'), 7), (('think', 'VERB'), 7), (('gay', 'ADJ'), 7), (('president', 'NOUN'), 6), (('high', 'ADJ'), 6), (('other', 'ADJ'), 6), (('know', 'VERB'), 6)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('history', 'NOUN'), 10), (('government', 'NOUN'), 9), (('evidence', 'NOUN'), 9), (('man', 'NOUN'), 9), (('world', 'NOUN'), 9), (('gun', 'NOUN'), 8), (('year', 'NOUN'), 8), (('official', 'NOUN'), 8), (('life', 'NOUN'), 8), (('thing', 'NOUN'), 7), (('time', 'NOUN'), 7), (('case', 'NOUN'), 7), (('month', 'NOUN'), 7), (('president', 'NOUN'), 6), (('source', 'NOUN'), 6), (('question', 'NOUN'), 6), (('school', 'NOUN'), 6), (('communist', 'NOUN'), 6), (('member', 'NOUN'), 6), (('medium', 'NOUN'), 6)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 30), (('make', 'VERB'), 16), (('go', 'VERB'), 14), (('come', 'VERB'), 11), (('have', 'VERB'), 10), (('tell', 'VERB'), 10), (('do', 'VERB'), 10), (('take', 'VERB'), 9), (('give', 'VERB'), 9), (('see', 'VERB'), 9), (('happen', 'VERB'), 7), (('be', 'VERB'), 7), (('think', 'VERB'), 7), (('know', 'VERB'), 6), (('continue', 'VERB'), 6), (('believe', 'VERB'), 6), (('find', 'VERB'), 5), (('add', 'VERB'), 5), (('’', 'VERB'), 5), (('hold', 'VERB'), 5)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('gay', 'ADJ'), 7), (('high', 'ADJ'), 6), (('other', 'ADJ'), 6), (('likely', 'ADJ'), 6), (('american', 'ADJ'), 6), (('former', 'ADJ'), 6), (('black', 'ADJ'), 6), (('more', 'ADJ'), 5), (('false', 'ADJ'), 5), (('great', 'ADJ'), 5), (('religious', 'ADJ'), 5), (('most', 'ADJ'), 5), (('human', 'ADJ'), 4), (('bad', 'ADJ'), 4), (('illegal', 'ADJ'), 4), (('-', 'ADJ'), 4), (('sexual', 'ADJ'), 4), (('clear', 'ADJ'), 4), (('anti', 'ADJ'), 4), (('nuclear', 'ADJ'), 4), (('last', 'ADJ'), 4)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_ex_min = Counter(content_words_total_ex_min)\n",
    "count_noun_total_ex_min = Counter(noun_total_ex_min)\n",
    "count_verb_total_ex_min = Counter(verb_total_ex_min)\n",
    "count_adj_total_ex_min = Counter(adj_total_ex_min)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_ex_min.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_ex_min.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_ex_min.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_ex_min.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34f9d60e-4a61-412b-9c59-de8a31234a03",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_ex_min)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9c5fff3-7eaf-4202-82db-aa402fd70221",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_ex_min)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_ex_min)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_ex_min)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "053fa57a-a4d0-4eeb-ae38-e1b75df9b7d2",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_ex_min))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a603c97-bf08-482a-bc9d-ac8431ec3c5e",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_ex_min))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_ex_min))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_ex_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d812f35-41f6-4db7-bdfc-3219510d86c7",
   "metadata": {},
   "source": [
    "### Flag_Waving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc64b24-a0a0-4fe0-92ec-d2d106a8fcfb",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Flag_Waving class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d9987-f0f0-4503-859c-10444a9b132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flag_waving = df.loc[(df['Technique'] == \"Flag_Waving\")]\n",
    "df_flag_waving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "29365d01-47e3-4c3e-baa2-4580e00bc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flag_waving = list()\n",
    "for x in df_flag_waving['Text']:\n",
    "    X_flag_waving.append(str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "859134c1-19d9-4014-b759-3b9cabff6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_flag_waving = list()\n",
    "for i in X_flag_waving:\n",
    "    doc_flag_waving.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "17f2a011-62e0-43b7-906b-808ac344b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of tokens:  5133\n"
     ]
    }
   ],
   "source": [
    "total_waving = \"\".join(X_flag_waving)\n",
    "total_waving_text = nlp(total_waving)\n",
    "print(\"Total of tokens: \", len(total_waving_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6b8cdedc-f848-4ead-9d91-e4e7ab482470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CONTENT WORDS\n",
      "Content word total:  1699\n",
      "Percentage of content words:  33.099551918955775\n",
      "Unique content word total:  892\n",
      "Percentage of unique content words:  52.501471453796356\n",
      "\n",
      "NOUNS\n",
      "Noun total:  827\n",
      "Percentage of nouns:  16.111435807519968\n",
      "Unique noun total:  456\n",
      "Percentage of unique nouns:  55.139056831922616\n",
      "\n",
      "VERBS\n",
      "Verb total:  574\n",
      "Percentage of verbs:  11.18254432105981\n",
      "Unique verb total:  274\n",
      "Percentage of unique nouns:  47.73519163763066\n",
      "\n",
      "ADJECTIVES\n",
      "Adjective total:  298\n",
      "Percentage of adjectives:  5.805571790375998\n",
      "Unique adjective total:  162\n",
      "Percentage of unique adjectives:  54.36241610738255\n"
     ]
    }
   ],
   "source": [
    "content_words_total_waving = [(token.lemma_,token.pos_) for token in total_waving_text if token.pos_ in [\"VERB\",\"ADJ\",\"NOUN\"]]\n",
    "noun_total_waving = [(token.lemma_,token.pos_) for token in total_waving_text if token.pos_ in [\"NOUN\"]]\n",
    "verb_total_waving = [(token.lemma_,token.pos_) for token in total_waving_text if token.pos_ in [\"VERB\"]]\n",
    "adj_total_waving = [(token.lemma_,token.pos_) for token in total_waving_text if token.pos_ in [\"ADJ\"]]\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(\"Content word total: \", len(content_words_total_waving))\n",
    "print(\"Percentage of content words: \", (len(content_words_total_waving)/len(total_waving_text)*100))\n",
    "print(\"Unique content word total: \", len(set(content_words_total_waving)))\n",
    "print(\"Percentage of unique content words: \", len(set(content_words_total_waving))/len(content_words_total_waving)*100)\n",
    "print(\"\\nNOUNS\")\n",
    "print(\"Noun total: \", len(noun_total_waving))\n",
    "print(\"Percentage of nouns: \", (len(noun_total_waving)/len(total_waving_text)*100))\n",
    "print(\"Unique noun total: \", len(set(noun_total_waving)))\n",
    "print(\"Percentage of unique nouns: \", len(set(noun_total_waving))/len(noun_total_waving)*100)\n",
    "print(\"\\nVERBS\")\n",
    "print(\"Verb total: \", len(verb_total_waving))\n",
    "print(\"Percentage of verbs: \", (len(verb_total_waving)/len(total_waving_text)*100))\n",
    "print(\"Unique verb total: \", len(set(verb_total_waving)))\n",
    "print(\"Percentage of unique nouns: \", len(set(verb_total_waving))/len(verb_total_waving)*100)\n",
    "print(\"\\nADJECTIVES\")\n",
    "print(\"Adjective total: \", len(adj_total_waving))\n",
    "print(\"Percentage of adjectives: \", (len(adj_total_waving)/len(total_waving_text)*100))\n",
    "print(\"Unique adjective total: \", len(set(adj_total_waving)))\n",
    "print(\"Percentage of unique adjectives: \", len(set(adj_total_waving))/len(adj_total_waving)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "df1f4fd8-d7c7-4dcb-979c-92716367912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CONTENT WORDS\n",
      "[(('american', 'ADJ'), 45), (('people', 'NOUN'), 32), (('say', 'VERB'), 30), (('have', 'VERB'), 26), (('take', 'VERB'), 13), (('make', 'VERB'), 11), (('call', 'VERB'), 10), (('year', 'NOUN'), 10), (('know', 'VERB'), 10), (('keep', 'VERB'), 9), (('time', 'NOUN'), 9), (('day', 'NOUN'), 9), (('power', 'NOUN'), 8), (('important', 'ADJ'), 8), (('right', 'NOUN'), 8), (('tell', 'VERB'), 8), (('officer', 'NOUN'), 8), (('report', 'NOUN'), 8), (('election', 'NOUN'), 8), (('country', 'NOUN'), 7), (('do', 'VERB'), 7), (('war', 'NOUN'), 7), (('assassination', 'NOUN'), 7), (('go', 'VERB'), 7), (('nation', 'NOUN'), 7), (('want', 'VERB'), 7), (('see', 'VERB'), 7), (('home', 'NOUN'), 6), (('fight', 'VERB'), 6), (('way', 'NOUN'), 6), (('support', 'VERB'), 6)]\n",
      "\n",
      "MOST COMMON NOUNS\n",
      "[(('people', 'NOUN'), 32), (('year', 'NOUN'), 10), (('time', 'NOUN'), 9), (('day', 'NOUN'), 9), (('power', 'NOUN'), 8), (('right', 'NOUN'), 8), (('officer', 'NOUN'), 8), (('report', 'NOUN'), 8), (('election', 'NOUN'), 8), (('country', 'NOUN'), 7), (('war', 'NOUN'), 7), (('assassination', 'NOUN'), 7), (('nation', 'NOUN'), 7), (('home', 'NOUN'), 6), (('way', 'NOUN'), 6), (('leader', 'NOUN'), 6), (('world', 'NOUN'), 6), (('culture', 'NOUN'), 6), (('force', 'NOUN'), 5), (('press', 'NOUN'), 5)]\n",
      "\n",
      "MOST COMMON VERBS\n",
      "[(('say', 'VERB'), 30), (('have', 'VERB'), 26), (('take', 'VERB'), 13), (('make', 'VERB'), 11), (('call', 'VERB'), 10), (('know', 'VERB'), 10), (('keep', 'VERB'), 9), (('tell', 'VERB'), 8), (('do', 'VERB'), 7), (('go', 'VERB'), 7), (('want', 'VERB'), 7), (('see', 'VERB'), 7), (('fight', 'VERB'), 6), (('support', 'VERB'), 6), (('give', 'VERB'), 6), (('come', 'VERB'), 6), (('put', 'VERB'), 6), (('think', 'VERB'), 6), (('pay', 'VERB'), 5), (('include', 'VERB'), 5)]\n",
      "\n",
      "MOST COMMON ADJECTIVES\n",
      "[(('american', 'ADJ'), 45), (('important', 'ADJ'), 8), (('secret', 'ADJ'), 6), (('good', 'ADJ'), 6), (('more', 'ADJ'), 5), (('christian', 'ADJ'), 5), (('full', 'ADJ'), 5), (('right', 'ADJ'), 4), (('islamic', 'ADJ'), 4), (('russian', 'ADJ'), 4), (('new', 'ADJ'), 3), (('many', 'ADJ'), 3), (('-', 'ADJ'), 3), (('other', 'ADJ'), 3), (('federal', 'ADJ'), 3), (('muslim', 'ADJ'), 3), (('national', 'ADJ'), 3), (('domestic', 'ADJ'), 3), (('true', 'ADJ'), 3), (('immigrant', 'ADJ'), 3), (('last', 'ADJ'), 3)]\n"
     ]
    }
   ],
   "source": [
    "count_content_words_total_waving = Counter(content_words_total_waving)\n",
    "count_noun_total_waving = Counter(noun_total_waving)\n",
    "count_verb_total_waving = Counter(verb_total_waving)\n",
    "count_adj_total_waving = Counter(adj_total_waving)\n",
    "\n",
    "print(\"MOST COMMON CONTENT WORDS\")\n",
    "print(count_content_words_total_waving.most_common(31))\n",
    "print(\"\\nMOST COMMON NOUNS\")\n",
    "print(count_noun_total_waving.most_common(20))\n",
    "print(\"\\nMOST COMMON VERBS\")\n",
    "print(count_verb_total_waving.most_common(20))\n",
    "print(\"\\nMOST COMMON ADJECTIVES\")\n",
    "print(count_adj_total_waving.most_common(21))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8231dba6-7225-4d8e-92ef-9312a2edb269",
   "metadata": {},
   "source": [
    "#run as code cell to see all the content words extracted\n",
    "\n",
    "print(\"ALL CONTENT WORDS\")\n",
    "print(content_words_total_waving)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59567c06-7efc-47e2-a8d6-1f7c9adf9731",
   "metadata": {},
   "source": [
    "print(\"ALL NOUNS\")\n",
    "print(noun_total_waving)\n",
    "print(\"\\nALL VERBS\")\n",
    "print(verb_total_waving)\n",
    "print(\"\\nALL ADJECTIVES\")\n",
    "print(adj_total_waving)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8697e2d9-95e4-4264-ab2c-28fbe98d4468",
   "metadata": {},
   "source": [
    "#run as code cell to see all the unique content words extracted\n",
    "\n",
    "print(\"ALL UNIQUE CONTENT WORDS\")\n",
    "print(set(content_words_total_waving))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18f42d6d-32c4-4bfa-a29c-30004355aa05",
   "metadata": {},
   "source": [
    "print(\"ALL UNIQUE NOUNS\")\n",
    "print(set(noun_total_waving))\n",
    "print(\"\\nALL UNIQUE VERBS\")\n",
    "print(set(verb_total_waving))\n",
    "print(\"\\nALL UNIQUE ADJECTIVES\")\n",
    "print(set(adj_total_waving))total = \"\".join(X_total_lista)\n",
    "total_text = nlp(total)\n",
    "print(\"Total of tokens: \", len(total_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9a6d7-127a-47f5-b789-20b643475eaf",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7bceb-499e-49bb-a4b9-b87485c0df81",
   "metadata": {},
   "source": [
    "# Named Entity Recogniton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49519c9f-2e0d-468e-a9ec-64c511cdb0f5",
   "metadata": {},
   "source": [
    "From every paragraph, different kind of entities and information about them have been extracted. \n",
    "\n",
    "As done in the previous section, this first part will focus on the extraction of these information regardless of the persuasion technique, while the following will consider each class separately (and will follow the same data preparation done for the general one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "03c9d2f2-c890-411b-a157-d802e3f2ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  18\n",
      "Total number of entities:  8078\n",
      "\n",
      "ALL UNIQUE ENTITIES\n",
      "Total number of unique entities:  3390\n",
      "Percentage of unique entities:  41.965833127011635\n"
     ]
    }
   ],
   "source": [
    "#Extracting named entities and printing the total of NE and type of NE categories extracted\n",
    "total_entities_dict = {key: list(g) for key, g in groupby(sorted(total_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict))\n",
    "\n",
    "total_entities_value_list = list()\n",
    "for i in total_entities_dict.values():\n",
    "    total_entities_value_list.append(i)\n",
    "    \n",
    "total_entities= len(sum(total_entities_value_list, []))\n",
    "print(\"Total number of entities: \", total_entities)\n",
    "\n",
    "#Printing total and percentage of unique named entities\n",
    "print(\"\\nALL UNIQUE ENTITIES\")\n",
    "unique_entities_dict = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list = list()\n",
    "for i in unique_entities_dict.values():\n",
    "    unique_entities_value_list.append(i)\n",
    "    \n",
    "unique_entities= len(sum(unique_entities_value_list, []))\n",
    "print(\"Total number of unique entities: \", unique_entities)\n",
    "print(\"Percentage of unique entities: \", (unique_entities/total_entities)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ecf6ebea-b462-44e4-a104-4d6a9fcfaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal = len(total_entities_dict['CARDINAL'])\n",
    "total_date = len(total_entities_dict['DATE'])\n",
    "total_event = len(total_entities_dict['EVENT'])\n",
    "total_fac = len(total_entities_dict['FAC'])\n",
    "total_gpe = len(total_entities_dict['GPE'])\n",
    "total_language = len(total_entities_dict['LANGUAGE'])\n",
    "total_law = len(total_entities_dict['LAW'])\n",
    "total_loc = len(total_entities_dict['LOC'])\n",
    "total_money = len(total_entities_dict['MONEY'])\n",
    "total_norp = len(total_entities_dict['NORP'])\n",
    "total_ordinal = len(total_entities_dict['ORDINAL'])\n",
    "total_org = len(total_entities_dict['ORG'])\n",
    "total_percent = len(total_entities_dict['PERCENT'])\n",
    "total_person = len(total_entities_dict['PERSON'])\n",
    "total_product = len(total_entities_dict['PRODUCT'])\n",
    "total_quantity = len(total_entities_dict['QUANTITY'])\n",
    "total_time = len(total_entities_dict['TIME'])\n",
    "total_woa = len(total_entities_dict['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "da2b52d8-1ef8-4fa0-9a34-bf9319386898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal = len(unique_entities_dict['CARDINAL'])\n",
    "unique_date = len(unique_entities_dict['DATE'])\n",
    "unique_event = len(unique_entities_dict['EVENT'])\n",
    "unique_fac = len(unique_entities_dict['FAC'])\n",
    "unique_gpe = len(unique_entities_dict['GPE'])\n",
    "unique_language = len(unique_entities_dict['LANGUAGE'])\n",
    "unique_law = len(unique_entities_dict['LAW'])\n",
    "unique_loc = len(unique_entities_dict['LOC'])\n",
    "unique_money = len(unique_entities_dict['MONEY'])\n",
    "unique_norp = len(unique_entities_dict['NORP'])\n",
    "unique_ordinal = len(unique_entities_dict['ORDINAL'])\n",
    "unique_org = len(unique_entities_dict['ORG'])\n",
    "unique_percent = len(unique_entities_dict['PERCENT'])\n",
    "unique_person = len(unique_entities_dict['PERSON'])\n",
    "unique_product = len(unique_entities_dict['PRODUCT'])\n",
    "unique_quantity = len(unique_entities_dict['QUANTITY'])\n",
    "unique_time = len(unique_entities_dict['TIME'])\n",
    "unique_woa = len(unique_entities_dict['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ac71c90c-dce7-47c0-8c1f-b2a82e4b2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  457\n",
      "Percentage of extracted cardinal numbers:  5.657340925971775\n",
      "Total of unique cardinal numbers:  185\n",
      "Percentage of unique cardinal numbers:  40.48140043763676\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  907\n",
      "Percentage of extracted dates:  11.228026739291904\n",
      "Total of unique dates:  504\n",
      "Percentage of unique dates:  55.567805953693494\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  38\n",
      "Percentage of extracted events:  0.4704134686803664\n",
      "Total of unique events:  29\n",
      "Percentage of unique events:  76.31578947368422\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  61\n",
      "Percentage of extracted facilities:  0.7551374102500619\n",
      "Total of unique facilities:  22\n",
      "Percentage of unique facilities:  36.0655737704918\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  1263\n",
      "Percentage of extracted countries or cities:  15.635058182718495\n",
      "Total of unique countries or cities:  318\n",
      "Percentage of unique countries or cities:  25.17814726840855\n",
      "\n",
      "LANGUAGE\n",
      "Total of extracted languages:  9\n",
      "Percentage of extracted languages:  0.11141371626640258\n",
      "Total of unique languages:  2\n",
      "Percentage of unique languages:  22.22222222222222\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  38\n",
      "Percentage of extracted laws:  0.4704134686803664\n",
      "Total of unique laws:  27\n",
      "Percentage of unique laws:  71.05263157894737\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  114\n",
      "Percentage of extracted generic locations:  1.4112404060410992\n",
      "Total of unique generic locations:  46\n",
      "Percentage of unique generic locations:  40.35087719298245\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  39\n",
      "Percentage of extracted money values:  0.4827927704877445\n",
      "Total of unique money values:  34\n",
      "Percentage of unique money values:  87.17948717948718\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  826\n",
      "Percentage of extracted nationalities, religious or political groups:  10.22530329289428\n",
      "Total of unique nationalities, religious or political groups:  175\n",
      "Percentage of unique nationalities, religious or political groups:  21.1864406779661\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  100\n",
      "Percentage extracted ordinal numbers:  1.2379301807378065\n",
      "Total of unique ordinal numbers:  15\n",
      "Percentage of unique ordinal numbers:  15.0\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  1978\n",
      "Percentage extracted companies or organizations:  24.48625897499381\n",
      "Total of unique companies or organizations:  904\n",
      "Percentage of unique companies or organizations:  45.70273003033367\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  51\n",
      "Percentage extracted percentages:  0.6313443921762812\n",
      "Total of unique percentages:  45\n",
      "Percentage of unique percentages:  88.23529411764706\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  1941\n",
      "Percentage extracted people:  24.02822480812082\n",
      "Total of unique people:  886\n",
      "Percentage of unique people:  45.64657393096342\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  51\n",
      "Percentage extracted products:  0.6313443921762812\n",
      "Total of unique products:  32\n",
      "Percentage of unique products:  62.745098039215684\n",
      "\n",
      "QUANTITY\n",
      "Total of extracted measurements:  7\n",
      "Percentage extracted measurements:  0.08665511265164644\n",
      "Total of unique measurements:  7\n",
      "Percentage of unique measurements:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  96\n",
      "Percentage of extracted times:  1.188412973508294\n",
      "Total of unique times:  69\n",
      "Percentage of unique times:  71.875\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  102\n",
      "Percentage of extracted works of art:  1.2626887843525625\n",
      "Total of unique works of art:  90\n",
      "Percentage of unique works of art:  88.23529411764706\n"
     ]
    }
   ],
   "source": [
    "# Printing total, percentage, unique entities for each persuasion technique\n",
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal/total_entities)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal/total_cardinal)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date)\n",
    "print(\"Percentage of extracted dates: \", (total_date/total_entities)*100)\n",
    "print(\"Total of unique dates: \", unique_date)\n",
    "print(\"Percentage of unique dates: \", (unique_date/total_date)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event)\n",
    "print(\"Percentage of extracted events: \", (total_event/total_entities)*100)\n",
    "print(\"Total of unique events: \", unique_event)\n",
    "print(\"Percentage of unique events: \", (unique_event/total_event)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac/total_entities)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac/total_fac)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe/total_entities)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe/total_gpe)*100)\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(\"Total of extracted languages: \", total_language)\n",
    "print(\"Percentage of extracted languages: \", (total_language/total_entities)*100)\n",
    "print(\"Total of unique languages: \", unique_language)\n",
    "print(\"Percentage of unique languages: \", (unique_language/total_language)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law)\n",
    "print(\"Percentage of extracted laws: \", (total_law/total_entities)*100)\n",
    "print(\"Total of unique laws: \", unique_law)\n",
    "print(\"Percentage of unique laws: \", (unique_law/total_law)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc/total_entities)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc/total_loc)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money)\n",
    "print(\"Percentage of extracted money values: \", (total_money/total_entities)*100)\n",
    "print(\"Total of unique money values: \", unique_money)\n",
    "print(\"Percentage of unique money values: \", (unique_money/total_money)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp/total_entities)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp/total_norp)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal/total_entities)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal/total_ordinal)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org/total_entities)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org/total_org)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent)\n",
    "print(\"Percentage extracted percentages: \", (total_percent/total_entities)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent/total_percent)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person)\n",
    "print(\"Percentage extracted people: \", (total_person/total_entities)*100)\n",
    "print(\"Total of unique people: \", unique_person)\n",
    "print(\"Percentage of unique people: \", (unique_person/total_person)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product)\n",
    "print(\"Percentage extracted products: \", (total_product/total_entities)*100)\n",
    "print(\"Total of unique products: \", unique_product)\n",
    "print(\"Percentage of unique products: \", (unique_product/total_product)*100)\n",
    "print(\"\\nQUANTITY\")\n",
    "print(\"Total of extracted measurements: \", total_quantity)\n",
    "print(\"Percentage extracted measurements: \", (total_quantity/total_entities)*100)\n",
    "print(\"Total of unique measurements: \", unique_quantity)\n",
    "print(\"Percentage of unique measurements: \", (unique_quantity/total_quantity)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time)\n",
    "print(\"Percentage of extracted times: \", (total_time/total_entities)*100)\n",
    "print(\"Total of unique times: \", unique_time)\n",
    "print(\"Percentage of unique times: \", (unique_time/total_time)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa/total_entities)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa/total_woa)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d2d7bd72-5c97-4832-8ccf-b3c96833f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "116\tGPE: Iran\n",
      "104\tORG: Trump\n",
      "99\tORG: Church\n",
      "85\tCARDINAL: one\n",
      "84\tORG: FBI\n",
      "82\tGPE: US\n",
      "77\tNORP: American\n",
      "72\tPERSON: Trump\n",
      "72\tPERSON: Francis\n",
      "67\tGPE: U.S.\n",
      "59\tCARDINAL: two\n",
      "56\tORDINAL: first\n",
      "45\tGPE: Syria\n",
      "43\tGPE: the United States\n",
      "40\tNORP: Democrats\n",
      "39\tNORP: Muslim\n",
      "39\tGPE: Russia\n",
      "38\tPERSON: Pope\n",
      "37\tORG: CIA\n",
      "37\tNORP: Islamic\n",
      "36\tGPE: America\n",
      "33\tPERSON: Clinton\n",
      "33\tNORP: Catholic\n",
      "33\tDATE: today\n",
      "31\tORG: Guardian\n",
      "31\tNORP: Russian\n",
      "31\tPERSON: McCarrick\n",
      "28\tORG: Assange\n",
      "28\tPERSON: Benedict\n",
      "27\tPERSON: Donald Trump\n"
     ]
    }
   ],
   "source": [
    "# Printing the 30 most common entities in the total of texts\n",
    "total_ents_count = Counter()\n",
    "\n",
    "for ent in total_text.ents:\n",
    "    total_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in total_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "97b1e70e-0ab5-4d8c-aa3c-4e9a1219733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting each occurrences of NE for each different categories\n",
    "total_cardinal_count = Counter()\n",
    "total_date_count = Counter()\n",
    "total_event_count = Counter()\n",
    "total_fac_count = Counter()\n",
    "total_gpe_count = Counter()\n",
    "total_language_count = Counter()\n",
    "total_law_count = Counter()\n",
    "total_loc_count = Counter()\n",
    "total_money_count = Counter()\n",
    "total_norp_count = Counter()\n",
    "total_ordinal_count = Counter()\n",
    "total_org_count = Counter()\n",
    "total_percent_count = Counter()\n",
    "total_person_count = Counter()\n",
    "total_product_count = Counter()\n",
    "total_quantity_count = Counter()\n",
    "total_time_count = Counter()\n",
    "total_woa_count = Counter()\n",
    "\n",
    "for ent in total_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        total_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        total_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        total_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        total_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        total_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LANGUAGE\"):\n",
    "        total_language_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        total_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        total_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        total_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        total_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        total_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        total_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        total_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        total_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        total_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"QUANTITY\"):\n",
    "        total_quantity_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        total_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        total_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7223aa8a-9e90-4c34-b4fd-1b2f73849bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "85\tCARDINAL: one\n",
      "59\tCARDINAL: two\n",
      "23\tCARDINAL: One\n",
      "19\tCARDINAL: three\n",
      "10\tCARDINAL: 11\n",
      "9\tCARDINAL: millions\n",
      "9\tCARDINAL: four\n",
      "6\tCARDINAL: five\n",
      "6\tCARDINAL: thousands\n",
      "4\tCARDINAL: Two\n",
      "\n",
      "MOST COMMON DATES\n",
      "33\tDATE: today\n",
      "26\tDATE: Friday\n",
      "20\tDATE: Thursday\n",
      "18\tDATE: Tuesday\n",
      "15\tDATE: Monday\n",
      "15\tDATE: 2015\n",
      "13\tDATE: Wednesday\n",
      "13\tDATE: 2016\n",
      "12\tDATE: 2009\n",
      "11\tDATE: Sunday\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "4\tEVENT: the Second Amendment\n",
      "4\tEVENT: the Cold War\n",
      "3\tEVENT: Holocaust\n",
      "2\tEVENT: the Third Secret\n",
      "1\tEVENT: Geneva -\n",
      "1\tEVENT: the New Mass\n",
      "1\tEVENT: Hurricane Maria’s\n",
      "1\tEVENT: Occupation\n",
      "1\tEVENT: the Green Revolution\n",
      "1\tEVENT: WWII\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "26\tFAC: Vatican\n",
      "9\tFAC: Vatican II\n",
      "3\tFAC: Metro\n",
      "2\tFAC: Route 91 Harvest\n",
      "2\tFAC: the Oval Office\n",
      "2\tFAC: the White House\n",
      "2\tFAC: the Fourth Amendment\n",
      "1\tFAC: Alexandria’s\n",
      "1\tFAC: St. Cyr\n",
      "1\tFAC: Route 91\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "116\tGPE: Iran\n",
      "82\tGPE: US\n",
      "67\tGPE: U.S.\n",
      "45\tGPE: Syria\n",
      "43\tGPE: the United States\n",
      "39\tGPE: Russia\n",
      "36\tGPE: America\n",
      "24\tGPE: Israel\n",
      "22\tGPE: Obama\n",
      "19\tGPE: Iraq\n",
      "19\tGPE: Las Vegas\n",
      "19\tGPE: Rome\n",
      "16\tGPE: Chile\n",
      "15\tGPE: Washington\n",
      "15\tGPE: Georgia\n",
      "\n",
      "MOST COMMON LANGUAGES\n",
      "6\tLANGUAGE: English\n",
      "3\tLANGUAGE: Arabic\n",
      "\n",
      "MOST COMMON LAWS\n",
      "10\tLAW: Constitution\n",
      "2\tLAW: First Amendment\n",
      "2\tLAW: Jean’s\n",
      "1\tLAW: the Southern Poverty Law Center\n",
      "1\tLAW: Chapter 8\n",
      "1\tLAW: the Mystical Body\n",
      "1\tLAW: Canon 915\n",
      "1\tLAW: Chapter 8 of AL\n",
      "1\tLAW: the Real Presence in the Mass - in the Sacrifice of the Mass\n",
      "1\tLAW: the Foreign Corrupt Practices Act\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "26\tLOC: Europe\n",
      "10\tLOC: Mandalay Bay\n",
      "6\tLOC: Africa\n",
      "6\tLOC: Earth\n",
      "6\tLOC: Barros\n",
      "5\tLOC: the Middle East\n",
      "4\tLOC: the Gulf of Tonkin\n",
      "3\tLOC: the Arabian Gulf\n",
      "3\tLOC: West\n",
      "3\tLOC: Western Europe\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "3\tMONEY: 6.00\n",
      "2\tMONEY: billions of dollars\n",
      "2\tMONEY: 45,000\n",
      "2\tMONEY: tens of billions of dollars\n",
      "1\tMONEY: 15 million dollars\n",
      "1\tMONEY: #KateSteinle #KatesLaw\n",
      "1\tMONEY: #BuildtheWall #\n",
      "1\tMONEY: $94.4 billion\n",
      "1\tMONEY: $45 billion\n",
      "1\tMONEY: $46 billion\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "77\tNORP: American\n",
      "40\tNORP: Democrats\n",
      "39\tNORP: Muslim\n",
      "37\tNORP: Islamic\n",
      "33\tNORP: Catholic\n",
      "31\tNORP: Russian\n",
      "23\tNORP: Iranian\n",
      "22\tNORP: Republican\n",
      "22\tNORP: Muslims\n",
      "21\tNORP: Catholics\n",
      "21\tNORP: Democratic\n",
      "20\tNORP: Republicans\n",
      "19\tNORP: Americans\n",
      "19\tNORP: Jewish\n",
      "18\tNORP: Christian\n",
      "18\tNORP: Christians\n",
      "17\tNORP: Democrat\n",
      "15\tNORP: Jews\n",
      "12\tNORP: Russians\n",
      "12\tNORP: Syrian\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "56\tORDINAL: first\n",
      "13\tORDINAL: second\n",
      "8\tORDINAL: third\n",
      "6\tORDINAL: First\n",
      "5\tORDINAL: fourth\n",
      "2\tORDINAL: Second\n",
      "2\tORDINAL: Third\n",
      "1\tORDINAL: 10th\n",
      "1\tORDINAL: 59th\n",
      "1\tORDINAL: 5th\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "104\tORG: Trump\n",
      "99\tORG: Church\n",
      "84\tORG: FBI\n",
      "37\tORG: CIA\n",
      "31\tORG: Guardian\n",
      "28\tORG: Assange\n",
      "27\tORG: Congress\n",
      "26\tORG: CNN\n",
      "25\tORG: Islam\n",
      "24\tORG: Ford\n",
      "22\tORG: Acosta\n",
      "21\tORG: White House\n",
      "21\tORG: House\n",
      "20\tORG: Kavanaugh\n",
      "20\tORG: Council\n",
      "18\tORG: ISIS\n",
      "16\tORG: Senate\n",
      "14\tORG: the White House\n",
      "14\tORG: Google\n",
      "14\tORG: the Supreme Court\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "3\tPERCENT: 0.63%\n",
      "3\tPERCENT: 100%\n",
      "2\tPERCENT: Ninety-two percent\n",
      "2\tPERCENT: 0.30%\n",
      "1\tPERCENT: nearly 500.David Hickey\n",
      "1\tPERCENT: 20%\n",
      "1\tPERCENT: 45 percent\n",
      "1\tPERCENT: almost 90%\n",
      "1\tPERCENT: 100 %\n",
      "1\tPERCENT: 20 percent\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "72\tPERSON: Trump\n",
      "72\tPERSON: Francis\n",
      "38\tPERSON: Pope\n",
      "33\tPERSON: Clinton\n",
      "31\tPERSON: McCarrick\n",
      "28\tPERSON: Benedict\n",
      "27\tPERSON: Donald Trump\n",
      "25\tPERSON: Obama\n",
      "23\tPERSON: Ford\n",
      "21\tPERSON: Hillary Clinton\n",
      "19\tPERSON: Campos\n",
      "19\tPERSON: Muhammad\n",
      "14\tPERSON: Haig\n",
      "12\tPERSON: Comey\n",
      "12\tPERSON: Kim\n",
      "12\tPERSON: Barack Obama\n",
      "12\tPERSON: Putin\n",
      "12\tPERSON: Bush\n",
      "11\tPERSON: Farrakhan\n",
      "11\tPERSON: Paddock\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "13\tPRODUCT: Twitter\n",
      "3\tPRODUCT: Cardinal McCarrick\n",
      "2\tPRODUCT: Corker\n",
      "2\tPRODUCT: Khweis\n",
      "2\tPRODUCT: MS-13\n",
      "2\tPRODUCT: Facebook\n",
      "2\tPRODUCT: Avenatti\n",
      "1\tPRODUCT: Canon 751\n",
      "1\tPRODUCT: JVP\n",
      "1\tPRODUCT: Twitterverse\n",
      "\n",
      "MOST COMMON QUANTITIES\n",
      "1\tQUANTITY: about 3 miles\n",
      "1\tQUANTITY: 6.5 million miles\n",
      "1\tQUANTITY: 600 to 150 yards\n",
      "1\tQUANTITY: 3.79 billion miles\n",
      "1\tQUANTITY: one billion miles\n",
      "1\tQUANTITY: a few feet\n",
      "1\tQUANTITY: a mile\n",
      "\n",
      "MOST COMMON TIMES\n",
      "6\tTIME: night\n",
      "4\tTIME: 9:59 p.m.\n",
      "4\tTIME: hours\n",
      "4\tTIME: morning\n",
      "3\tTIME: 10:05 p.m.\n",
      "3\tTIME: 6 minutes\n",
      "3\tTIME: last-minute\n",
      "3\tTIME: afternoon\n",
      "2\tTIME: six minutes\n",
      "2\tTIME: earlier this morning\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "7\tWORK_OF_ART: Bible\n",
      "2\tWORK_OF_ART: PhD\n",
      "2\tWORK_OF_ART: FCPA\n",
      "2\tWORK_OF_ART: The History of Jihad From Muhammad\n",
      "2\tWORK_OF_ART: Allahu Akbar\n",
      "2\tWORK_OF_ART: Speaker Pelosi\n",
      "2\tWORK_OF_ART: sources”\n",
      "1\tWORK_OF_ART: the Bible\n",
      "1\tWORK_OF_ART: The Jewish Question\n",
      "1\tWORK_OF_ART: Honorius\n"
     ]
    }
   ],
   "source": [
    "# Printing the most common named entities for each types\n",
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in total_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in total_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in total_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in total_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in total_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LANGUAGES\")        \n",
    "for key, val in total_language_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in total_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in total_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in total_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in total_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in total_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in total_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in total_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in total_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in total_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON QUANTITIES\")        \n",
    "for key, val in total_quantity_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in total_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in total_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5d3c266-00d6-45d7-8a75-2a60efef52dc",
   "metadata": {},
   "source": [
    "#run as code to see all the entities extracted\n",
    "\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71252817-96d3-4c70-8422-a26d9092b644",
   "metadata": {},
   "source": [
    "#run as code to see all the entities extracted for each category\n",
    "\n",
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(total_entities_dict['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(total_entities_dict['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8702037a-02ce-400b-ba25-bd74ca649f5d",
   "metadata": {},
   "source": [
    "#run as code to see all unique entities\n",
    "\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91b314ef-5344-48e3-8f0d-6847513126bd",
   "metadata": {},
   "source": [
    "#run as code to see all unique entities for each categories\n",
    "\n",
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(unique_entities_dict['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(unique_entities_dict['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab2c2bcf-d8f3-49b7-88e2-61deaf493f06",
   "metadata": {},
   "source": [
    "#run as code to display the text with all of the recognized entities\n",
    "\n",
    "displacy.render(total_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20fc109-e8e6-4fe1-bce5-7d50b9f0c96b",
   "metadata": {},
   "source": [
    "### Loaded_Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc60c78-832f-44c2-9c79-92ae8285ba8e",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Loaded_Language class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0726f578-283d-41f2-91f2-2091b649441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  18\n",
      "Total number of entities:  3644\n",
      "\n",
      "UNIQUE ENTITIES\n",
      "Total number of unique entities:  1785\n",
      "Percentage of unique entities:  48.98463227222832\n"
     ]
    }
   ],
   "source": [
    "# Extracting and counting each NE extracted and the total of NE categories\n",
    "total_entities_dict_loaded = {key: list(g) for key, g in groupby(sorted(total_loaded_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_loaded.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_loaded))\n",
    "\n",
    "total_entities_value_list_loaded = list()\n",
    "for i in total_entities_dict_loaded.values():\n",
    "    total_entities_value_list_loaded.append(i)\n",
    "    \n",
    "total_entities_loaded= len(sum(total_entities_value_list_loaded, []))\n",
    "print(\"Total number of entities: \", total_entities_loaded)\n",
    "\n",
    "# Counting and printing total and percentage of each unique entities\n",
    "unique_entities_dict_loaded = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_loaded_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"\\nUNIQUE ENTITIES\")\n",
    "\n",
    "unique_entities_value_list_loaded = list()\n",
    "for i in unique_entities_dict_loaded.values():\n",
    "    unique_entities_value_list_loaded.append(i)\n",
    "    \n",
    "unique_entities_loaded= len(sum(unique_entities_value_list_loaded, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_loaded)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_loaded/total_entities_loaded)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e5cb9bcd-4138-44f9-9b93-b7b0524b0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_loaded = len(total_entities_dict_loaded['CARDINAL'])\n",
    "total_date_loaded = len(total_entities_dict_loaded['DATE'])\n",
    "total_event_loaded = len(total_entities_dict_loaded['EVENT'])\n",
    "total_fac_loaded = len(total_entities_dict_loaded['FAC'])\n",
    "total_gpe_loaded = len(total_entities_dict_loaded['GPE'])\n",
    "total_language_loaded = len(total_entities_dict_loaded['LANGUAGE'])\n",
    "total_law_loaded = len(total_entities_dict_loaded['LAW'])\n",
    "total_loc_loaded = len(total_entities_dict_loaded['LOC'])\n",
    "total_money_loaded = len(total_entities_dict_loaded['MONEY'])\n",
    "total_norp_loaded = len(total_entities_dict_loaded['NORP'])\n",
    "total_ordinal_loaded = len(total_entities_dict_loaded['ORDINAL'])\n",
    "total_org_loaded = len(total_entities_dict_loaded['ORG'])\n",
    "total_percent_loaded = len(total_entities_dict_loaded['PERCENT'])\n",
    "total_person_loaded = len(total_entities_dict_loaded['PERSON'])\n",
    "total_product_loaded = len(total_entities_dict_loaded['PRODUCT'])\n",
    "total_quantity_loaded = len(total_entities_dict_loaded['QUANTITY'])\n",
    "total_time_loaded = len(total_entities_dict_loaded['TIME'])\n",
    "total_woa_loaded = len(total_entities_dict_loaded['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "beeb08f7-df07-4fd5-b3af-1802bedde75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_loaded = len(unique_entities_dict_loaded['CARDINAL'])\n",
    "unique_date_loaded = len(unique_entities_dict_loaded['DATE'])\n",
    "unique_event_loaded = len(unique_entities_dict_loaded['EVENT'])\n",
    "unique_fac_loaded = len(unique_entities_dict_loaded['FAC'])\n",
    "unique_gpe_loaded = len(unique_entities_dict_loaded['GPE'])\n",
    "unique_language_loaded = len(unique_entities_dict_loaded['LANGUAGE'])\n",
    "unique_law_loaded = len(unique_entities_dict_loaded['LAW'])\n",
    "unique_loc_loaded = len(unique_entities_dict_loaded['LOC'])\n",
    "unique_money_loaded = len(unique_entities_dict_loaded['MONEY'])\n",
    "unique_norp_loaded = len(unique_entities_dict_loaded['NORP'])\n",
    "unique_ordinal_loaded = len(unique_entities_dict_loaded['ORDINAL'])\n",
    "unique_org_loaded = len(unique_entities_dict_loaded['ORG'])\n",
    "unique_percent_loaded = len(unique_entities_dict_loaded['PERCENT'])\n",
    "unique_person_loaded = len(unique_entities_dict_loaded['PERSON'])\n",
    "unique_product_loaded = len(unique_entities_dict_loaded['PRODUCT'])\n",
    "unique_quantity_loaded = len(unique_entities_dict_loaded['QUANTITY'])\n",
    "unique_time_loaded = len(unique_entities_dict_loaded['TIME'])\n",
    "unique_woa_loaded = len(unique_entities_dict_loaded['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b64326bc-0120-47bc-ae6c-bcbad449f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  214\n",
      "Percentage of extracted cardinal numbers:  5.872667398463227\n",
      "Total of unique cardinal numbers:  107\n",
      "Percentage of unique cardinal numbers:  50.0\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  408\n",
      "Percentage of extracted dates:  11.19648737650933\n",
      "Total of unique dates:  259\n",
      "Percentage of unique dates:  63.48039215686274\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  19\n",
      "Percentage of extracted events:  0.5214050493962679\n",
      "Total of unique events:  15\n",
      "Percentage of unique events:  78.94736842105263\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  30\n",
      "Percentage of extracted facilities:  0.823271130625686\n",
      "Total of unique facilities:  11\n",
      "Percentage of unique facilities:  36.666666666666664\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  512\n",
      "Percentage of extracted countries or cities:  14.050493962678376\n",
      "Total of unique countries or cities:  184\n",
      "Percentage of unique countries or cities:  35.9375\n",
      "\n",
      "LANGUAGE\n",
      "Total of extracted languages:  5\n",
      "Percentage of extracted languages:  0.13721185510428102\n",
      "Total of unique languages:  2\n",
      "Percentage of unique languages:  40.0\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  17\n",
      "Percentage of extracted laws:  0.4665203073545554\n",
      "Total of unique laws:  13\n",
      "Percentage of unique laws:  76.47058823529412\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  38\n",
      "Percentage of extracted generic locations:  1.0428100987925357\n",
      "Total of unique generic locations:  23\n",
      "Percentage of unique generic locations:  60.526315789473685\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  24\n",
      "Percentage of extracted money values:  0.6586169045005488\n",
      "Total of unique money values:  23\n",
      "Percentage of unique money values:  95.83333333333334\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  347\n",
      "Percentage of extracted nationalities, religious or political groups:  9.522502744237102\n",
      "Total of unique nationalities, religious or political groups:  101\n",
      "Percentage of unique nationalities, religious or political groups:  29.106628242074926\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  44\n",
      "Percentage extracted ordinal numbers:  1.2074643249176729\n",
      "Total of unique ordinal numbers:  8\n",
      "Percentage of unique ordinal numbers:  18.181818181818183\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  913\n",
      "Percentage extracted companies or organizations:  25.05488474204171\n",
      "Total of unique companies or organizations:  461\n",
      "Percentage of unique companies or organizations:  50.492880613362544\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  28\n",
      "Percentage extracted percentages:  0.7683863885839737\n",
      "Total of unique percentages:  28\n",
      "Percentage of unique percentages:  100.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  947\n",
      "Percentage extracted people:  25.987925356750825\n",
      "Total of unique people:  464\n",
      "Percentage of unique people:  48.99683210137275\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  24\n",
      "Percentage extracted products:  0.6586169045005488\n",
      "Total of unique products:  22\n",
      "Percentage of unique products:  91.66666666666666\n",
      "\n",
      "QUANTITY\n",
      "Total of extracted measurements:  4\n",
      "Percentage extracted measurements:  0.10976948408342481\n",
      "Total of unique measurements:  4\n",
      "Percentage of unique measurements:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  28\n",
      "Percentage of extracted times:  0.7683863885839737\n",
      "Total of unique times:  23\n",
      "Percentage of unique times:  82.14285714285714\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  42\n",
      "Percentage of extracted works of art:  1.1525795828759604\n",
      "Total of unique works of art:  37\n",
      "Percentage of unique works of art:  88.09523809523809\n"
     ]
    }
   ],
   "source": [
    "# Printing total, percentage and unique entities extracted of each categories\n",
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_loaded)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_loaded)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_loaded/total_cardinal_loaded)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_loaded)\n",
    "print(\"Percentage of extracted dates: \", (total_date_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique dates: \", unique_date_loaded)\n",
    "print(\"Percentage of unique dates: \", (unique_date_loaded/total_date_loaded)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_loaded)\n",
    "print(\"Percentage of extracted events: \", (total_event_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique events: \", unique_event_loaded)\n",
    "print(\"Percentage of unique events: \", (unique_event_loaded/total_event_loaded)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_loaded)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_loaded)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_loaded/total_fac_loaded)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_loaded)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_loaded)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_loaded/total_gpe_loaded)*100)\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(\"Total of extracted languages: \", total_language_loaded)\n",
    "print(\"Percentage of extracted languages: \", (total_language_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique languages: \", unique_language_loaded)\n",
    "print(\"Percentage of unique languages: \", (unique_language_loaded/total_language_loaded)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_loaded)\n",
    "print(\"Percentage of extracted laws: \", (total_law_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique laws: \", unique_law_loaded)\n",
    "print(\"Percentage of unique laws: \", (unique_law_loaded/total_law_loaded)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_loaded)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_loaded)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_loaded/total_loc_loaded)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money_loaded)\n",
    "print(\"Percentage of extracted money values: \", (total_money_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique money values: \", unique_money_loaded)\n",
    "print(\"Percentage of unique money values: \", (unique_money_loaded/total_money_loaded)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_loaded)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_loaded)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_loaded/total_norp_loaded)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_loaded)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_loaded)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_loaded/total_ordinal_loaded)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_loaded)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_loaded)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_loaded/total_org_loaded)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_loaded)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_loaded)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_loaded/total_percent_loaded)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_loaded)\n",
    "print(\"Percentage extracted people: \", (total_person_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique people: \", unique_person_loaded)\n",
    "print(\"Percentage of unique people: \", (unique_person_loaded/total_person_loaded)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_loaded)\n",
    "print(\"Percentage extracted products: \", (total_product_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique products: \", unique_product_loaded)\n",
    "print(\"Percentage of unique products: \", (unique_product_loaded/total_product_loaded)*100)\n",
    "print(\"\\nQUANTITY\")\n",
    "print(\"Total of extracted measurements: \", total_quantity_loaded)\n",
    "print(\"Percentage extracted measurements: \", (total_quantity_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique measurements: \", unique_quantity_loaded)\n",
    "print(\"Percentage of unique measurements: \", (unique_quantity_loaded/total_quantity_loaded)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_loaded)\n",
    "print(\"Percentage of extracted times: \", (total_time_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique times: \", unique_time_loaded)\n",
    "print(\"Percentage of unique times: \", (unique_time_loaded/total_time_loaded)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_loaded)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_loaded/total_entities_loaded)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_loaded)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_loaded/total_woa_loaded)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2fc5d3d2-fb3e-4d28-9ddc-aecba12fbf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "66\tORG: Church\n",
      "48\tORG: Trump\n",
      "46\tPERSON: Francis\n",
      "44\tGPE: Iran\n",
      "42\tORG: FBI\n",
      "39\tPERSON: Trump\n",
      "34\tGPE: US\n",
      "34\tCARDINAL: one\n",
      "30\tCARDINAL: two\n",
      "29\tORDINAL: first\n",
      "25\tNORP: Democrats\n",
      "25\tPERSON: McCarrick\n",
      "24\tPERSON: Pope\n",
      "22\tNORP: Catholic\n",
      "21\tNORP: American\n",
      "21\tPERSON: Clinton\n",
      "19\tPERSON: Muhammad\n",
      "18\tGPE: U.S.\n",
      "17\tGPE: America\n",
      "17\tNORP: Islamic\n",
      "16\tGPE: the United States\n",
      "15\tGPE: Obama\n",
      "15\tORG: CIA\n",
      "14\tORG: CNN\n",
      "14\tPERSON: Obama\n",
      "14\tORG: House\n",
      "14\tFAC: Vatican\n",
      "14\tNORP: Iranian\n",
      "14\tDATE: today\n",
      "14\tCARDINAL: One\n"
     ]
    }
   ],
   "source": [
    "# Printing the 30 most common entities in the texts\n",
    "loaded_ents_count = Counter()\n",
    "\n",
    "for ent in total_loaded_text.ents:\n",
    "    loaded_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in loaded_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "45977072-86f7-4722-9a1d-29dd16bb70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrencies of each NE for each categories\n",
    "loaded_cardinal_count = Counter()\n",
    "loaded_date_count = Counter()\n",
    "loaded_event_count = Counter()\n",
    "loaded_fac_count = Counter()\n",
    "loaded_gpe_count = Counter()\n",
    "loaded_language_count = Counter()\n",
    "loaded_law_count = Counter()\n",
    "loaded_loc_count = Counter()\n",
    "loaded_money_count = Counter()\n",
    "loaded_norp_count = Counter()\n",
    "loaded_ordinal_count = Counter()\n",
    "loaded_org_count = Counter()\n",
    "loaded_percent_count = Counter()\n",
    "loaded_person_count = Counter()\n",
    "loaded_product_count = Counter()\n",
    "loaded_quantity_count = Counter()\n",
    "loaded_time_count = Counter()\n",
    "loaded_woa_count = Counter()\n",
    "\n",
    "for ent in total_loaded_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        loaded_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        loaded_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        loaded_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        loaded_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        loaded_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LANGUAGE\"):\n",
    "        loaded_language_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        loaded_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        loaded_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        loaded_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        loaded_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        loaded_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        loaded_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        loaded_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        loaded_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        loaded_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"QUANTITY\"):\n",
    "        loaded_quantity_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        loaded_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        loaded_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9de31be9-081b-4b4b-b5e7-1aa8d26d2fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "34\tCARDINAL: one\n",
      "30\tCARDINAL: two\n",
      "14\tCARDINAL: One\n",
      "9\tCARDINAL: three\n",
      "5\tCARDINAL: millions\n",
      "5\tCARDINAL: four\n",
      "4\tCARDINAL: thousands\n",
      "3\tCARDINAL: five\n",
      "2\tCARDINAL: 12\n",
      "2\tCARDINAL: Two\n",
      "\n",
      "MOST COMMON DATES\n",
      "14\tDATE: today\n",
      "11\tDATE: Friday\n",
      "9\tDATE: Tuesday\n",
      "9\tDATE: Thursday\n",
      "7\tDATE: 2009\n",
      "7\tDATE: Wednesday\n",
      "6\tDATE: Monday\n",
      "6\tDATE: 2015\n",
      "5\tDATE: March\n",
      "5\tDATE: Today\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "3\tEVENT: the Second Amendment\n",
      "3\tEVENT: the Cold War\n",
      "1\tEVENT: the New Mass\n",
      "1\tEVENT: Hurricane Maria’s\n",
      "1\tEVENT: the Green Revolution\n",
      "1\tEVENT: the Congressional Medal of Honor\n",
      "1\tEVENT: the Vicar of Christ\n",
      "1\tEVENT: Hurricane Irma\n",
      "1\tEVENT: the Middle Ages\n",
      "1\tEVENT: the Great Recession\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "14\tFAC: Vatican\n",
      "6\tFAC: Vatican II\n",
      "2\tFAC: the Oval Office\n",
      "1\tFAC: Route 91\n",
      "1\tFAC: Garcia Zarate\n",
      "1\tFAC: Cardinal Sandri\n",
      "1\tFAC: the Vatican Curia\n",
      "1\tFAC: Faith\n",
      "1\tFAC: the Fourth Amendment\n",
      "1\tFAC: the Clinton Global Initiative\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "44\tGPE: Iran\n",
      "34\tGPE: US\n",
      "18\tGPE: U.S.\n",
      "17\tGPE: America\n",
      "16\tGPE: the United States\n",
      "15\tGPE: Obama\n",
      "12\tGPE: Syria\n",
      "11\tGPE: Russia\n",
      "11\tGPE: Israel\n",
      "9\tGPE: Chile\n",
      "9\tGPE: Iraq\n",
      "9\tGPE: Washington\n",
      "7\tGPE: North Korea\n",
      "7\tGPE: Faggioli\n",
      "7\tGPE: Libya\n",
      "\n",
      "MOST COMMON LANGUAGES\n",
      "3\tLANGUAGE: English\n",
      "2\tLANGUAGE: Arabic\n",
      "\n",
      "MOST COMMON LAWS\n",
      "4\tLAW: Constitution\n",
      "2\tLAW: Jean’s\n",
      "1\tLAW: the Southern Poverty Law Center\n",
      "1\tLAW: the Mystical Body\n",
      "1\tLAW: Canon 915\n",
      "1\tLAW: Chapter 8 of AL\n",
      "1\tLAW: Article 23 states\n",
      "1\tLAW: the “Federations of Discalced Carmelite Nuns of Europe & the Holy Land\n",
      "1\tLAW: the Franciscan Friars of the Immaculate\n",
      "1\tLAW: ABM\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "5\tLOC: Europe\n",
      "4\tLOC: Barros\n",
      "3\tLOC: the Arabian Gulf\n",
      "3\tLOC: Earth\n",
      "2\tLOC: Gulf\n",
      "2\tLOC: Jupiter\n",
      "2\tLOC: the Middle East\n",
      "2\tLOC: Central America\n",
      "1\tLOC: the bay\n",
      "1\tLOC: New England\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "2\tMONEY: 6.00\n",
      "1\tMONEY: #BuildtheWall #\n",
      "1\tMONEY: $94.4 billion\n",
      "1\tMONEY: $45 billion\n",
      "1\tMONEY: almost $1,000\n",
      "1\tMONEY: $1.5 billion\n",
      "1\tMONEY: 45,000\n",
      "1\tMONEY: 40 per cent\n",
      "1\tMONEY: 2.60\n",
      "1\tMONEY: 24.57\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "25\tNORP: Democrats\n",
      "22\tNORP: Catholic\n",
      "21\tNORP: American\n",
      "17\tNORP: Islamic\n",
      "14\tNORP: Iranian\n",
      "13\tNORP: Democratic\n",
      "12\tNORP: Muslim\n",
      "12\tNORP: Catholics\n",
      "11\tNORP: Jews\n",
      "10\tNORP: Republican\n",
      "9\tNORP: Republicans\n",
      "9\tNORP: Jewish\n",
      "9\tNORP: Democrat\n",
      "8\tNORP: Russian\n",
      "8\tNORP: Muslims\n",
      "7\tNORP: Americans\n",
      "7\tNORP: Christian\n",
      "6\tNORP: Christians\n",
      "5\tNORP: anti-Semitic\n",
      "5\tNORP: German\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "29\tORDINAL: first\n",
      "8\tORDINAL: second\n",
      "2\tORDINAL: First\n",
      "1\tORDINAL: 10th\n",
      "1\tORDINAL: 59th\n",
      "1\tORDINAL: 5th\n",
      "1\tORDINAL: seventh\n",
      "1\tORDINAL: Second\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "66\tORG: Church\n",
      "48\tORG: Trump\n",
      "42\tORG: FBI\n",
      "15\tORG: CIA\n",
      "14\tORG: CNN\n",
      "14\tORG: House\n",
      "13\tORG: White House\n",
      "13\tORG: Ford\n",
      "13\tORG: Acosta\n",
      "12\tORG: Islam\n",
      "10\tORG: Kavanaugh\n",
      "9\tORG: Trump’s\n",
      "8\tORG: Council\n",
      "8\tORG: the Supreme Court\n",
      "7\tORG: State\n",
      "7\tORG: Congress\n",
      "7\tORG: Fox News\n",
      "6\tORG: the White House\n",
      "6\tORG: the Catholic Church\n",
      "6\tORG: Obama’s\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "1\tPERCENT: 20%\n",
      "1\tPERCENT: 80 to 90 percent\n",
      "1\tPERCENT: 43.5 percent\n",
      "1\tPERCENT: 0.63%\n",
      "1\tPERCENT: 0.30%\n",
      "1\tPERCENT: 57%\n",
      "1\tPERCENT: 1.27%\n",
      "1\tPERCENT: 0.81%\n",
      "1\tPERCENT: 65.3%\n",
      "1\tPERCENT: 61.9%\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "46\tPERSON: Francis\n",
      "39\tPERSON: Trump\n",
      "25\tPERSON: McCarrick\n",
      "24\tPERSON: Pope\n",
      "21\tPERSON: Clinton\n",
      "19\tPERSON: Muhammad\n",
      "14\tPERSON: Obama\n",
      "14\tPERSON: Benedict\n",
      "14\tPERSON: Ford\n",
      "13\tPERSON: Hillary Clinton\n",
      "11\tPERSON: Donald Trump\n",
      "10\tPERSON: Brett Kavanaugh\n",
      "8\tPERSON: Comey\n",
      "8\tPERSON: Fr\n",
      "7\tPERSON: Kim\n",
      "7\tPERSON: Farrakhan\n",
      "7\tPERSON: Barack Obama\n",
      "7\tPERSON: Haig\n",
      "7\tPERSON: Ellison\n",
      "7\tPERSON: McMaster\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "3\tPRODUCT: Twitter\n",
      "1\tPRODUCT: Canon 751\n",
      "1\tPRODUCT: Corker\n",
      "1\tPRODUCT: Twitterverse\n",
      "1\tPRODUCT: GoFundMe\n",
      "1\tPRODUCT: Manbij\n",
      "1\tPRODUCT: ADL\n",
      "1\tPRODUCT: AR-15\n",
      "1\tPRODUCT: MS-13\n",
      "1\tPRODUCT: B-52\n",
      "\n",
      "MOST COMMON QUANTITIES\n",
      "1\tQUANTITY: 600 to 150 yards\n",
      "1\tQUANTITY: 3.79 billion miles\n",
      "1\tQUANTITY: a few feet\n",
      "1\tQUANTITY: a mile\n",
      "\n",
      "MOST COMMON TIMES\n",
      "3\tTIME: last-minute\n",
      "2\tTIME: evening\n",
      "2\tTIME: hours\n",
      "2\tTIME: morning\n",
      "1\tTIME: Nearly five hours\n",
      "1\tTIME: Minutes\n",
      "1\tTIME: the hour\n",
      "1\tTIME: earlier this morning\n",
      "1\tTIME: 12-24 hours\n",
      "1\tTIME: every hour\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "6\tWORK_OF_ART: Bible\n",
      "1\tWORK_OF_ART: the Bible\n",
      "1\tWORK_OF_ART: “The Blast\n",
      "1\tWORK_OF_ART: Confidential Source 1\n",
      "1\tWORK_OF_ART: Oh Muslim\n",
      "1\tWORK_OF_ART: Great Clarifier\n",
      "1\tWORK_OF_ART: “Tantalizing Mystery of JFK Assassination Files Solved\n",
      "1\tWORK_OF_ART: Doubtful Works of Saint Francis\n",
      "1\tWORK_OF_ART: Saturday Night Live\n",
      "1\tWORK_OF_ART: SNL\n"
     ]
    }
   ],
   "source": [
    "# Printing the most common entities for each categories\n",
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in loaded_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in loaded_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in loaded_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in loaded_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in loaded_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LANGUAGES\")        \n",
    "for key, val in loaded_language_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in loaded_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in loaded_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in loaded_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in loaded_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in loaded_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in loaded_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in loaded_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in loaded_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in loaded_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON QUANTITIES\")        \n",
    "for key, val in loaded_quantity_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in loaded_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in loaded_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "22b017e6-39ca-421c-a971-1563213a078c",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_loaded)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2822e21c-3318-4e07-88c3-6ae098a4cb22",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_loaded['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_loaded['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_loaded['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_loaded['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_loaded['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(total_entities_dict_loaded['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_loaded['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_loaded['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict_loaded['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_loaded['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_loaded['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_loaded['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_loaded['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_loaded['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_loaded['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(total_entities_dict_loaded['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_loaded['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_loaded['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef7d9b1-2c23-43af-ab63-6759959572ee",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_loaded)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5846dc7-2606-4c0f-bf32-440941278257",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES FOR EACH CATEGORY\n",
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_loaded['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_loaded['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_loaded['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_loaded['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_loaded['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(unique_entities_dict_loaded['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_loaded['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_loaded['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict_loaded['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_loaded['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_loaded['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_loaded['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_loaded['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_loaded['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_loaded['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(unique_entities_dict_loaded['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_loaded['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_loaded['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4e970b9-7414-4b0c-989e-958537cc6931",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_loaded_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab1be9-fa6c-4e29-bd00-c33320b21d84",
   "metadata": {},
   "source": [
    "### Name-Calling-Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb6ce3-cefb-4974-83a9-f0f9a5226454",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Name_Calling-Labeling class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "af55ed0f-1eb6-41a2-b2e4-a2e503c646aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  17\n",
      "Total number of entities:  1325\n",
      "Total number of unique entities:  846\n",
      "Percentage of unique entities:  63.849056603773576\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_calling = {key: list(g) for key, g in groupby(sorted(total_calling_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_calling.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_calling))\n",
    "\n",
    "total_entities_value_list_calling = list()\n",
    "for i in total_entities_dict_calling.values():\n",
    "    total_entities_value_list_calling.append(i)\n",
    "    \n",
    "total_entities_calling= len(sum(total_entities_value_list_calling, []))\n",
    "print(\"Total number of entities: \", total_entities_calling)\n",
    "\n",
    "unique_entities_dict_calling = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_calling_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_calling = list()\n",
    "for i in unique_entities_dict_calling.values():\n",
    "    unique_entities_value_list_calling.append(i)\n",
    "    \n",
    "unique_entities_calling= len(sum(unique_entities_value_list_calling, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_calling)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_calling/total_entities_calling)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "70d49fed-0a37-418b-a0b6-2ff90add0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_calling = len(total_entities_dict_calling['CARDINAL'])\n",
    "total_date_calling = len(total_entities_dict_calling['DATE'])\n",
    "total_event_calling = len(total_entities_dict_calling['EVENT'])\n",
    "total_fac_calling = len(total_entities_dict_calling['FAC'])\n",
    "total_gpe_calling = len(total_entities_dict_calling['GPE'])\n",
    "total_language_calling = len(total_entities_dict_calling['LANGUAGE'])\n",
    "total_law_calling = len(total_entities_dict_calling['LAW'])\n",
    "total_loc_calling = len(total_entities_dict_calling['LOC'])\n",
    "total_money_calling = len(total_entities_dict_calling['MONEY'])\n",
    "total_norp_calling = len(total_entities_dict_calling['NORP'])\n",
    "total_ordinal_calling = len(total_entities_dict_calling['ORDINAL'])\n",
    "total_org_calling = len(total_entities_dict_calling['ORG'])\n",
    "total_percent_calling = len(total_entities_dict_calling['PERCENT'])\n",
    "total_person_calling = len(total_entities_dict_calling['PERSON'])\n",
    "total_product_calling = len(total_entities_dict_calling['PRODUCT'])\n",
    "total_time_calling = len(total_entities_dict_calling['TIME'])\n",
    "total_woa_calling = len(total_entities_dict_calling['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ddbaae7a-2e3a-497b-8dc8-d80e1ef7afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_calling = len(unique_entities_dict_calling['CARDINAL'])\n",
    "unique_date_calling = len(unique_entities_dict_calling['DATE'])\n",
    "unique_event_calling = len(unique_entities_dict_calling['EVENT'])\n",
    "unique_fac_calling = len(unique_entities_dict_calling['FAC'])\n",
    "unique_gpe_calling = len(unique_entities_dict_calling['GPE'])\n",
    "unique_language_calling = len(unique_entities_dict_calling['LANGUAGE'])\n",
    "unique_law_calling = len(unique_entities_dict_calling['LAW'])\n",
    "unique_loc_calling = len(unique_entities_dict_calling['LOC'])\n",
    "unique_money_calling = len(unique_entities_dict_calling['MONEY'])\n",
    "unique_norp_calling = len(unique_entities_dict_calling['NORP'])\n",
    "unique_ordinal_calling = len(unique_entities_dict_calling['ORDINAL'])\n",
    "unique_org_calling = len(unique_entities_dict_calling['ORG'])\n",
    "unique_percent_calling = len(unique_entities_dict_calling['PERCENT'])\n",
    "unique_person_calling = len(unique_entities_dict_calling['PERSON'])\n",
    "unique_product_calling = len(unique_entities_dict_calling['PRODUCT'])\n",
    "unique_time_calling = len(unique_entities_dict_calling['TIME'])\n",
    "unique_woa_calling = len(unique_entities_dict_calling['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b02cd8b2-4a4b-4a25-84f6-b8c47dd064ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  62\n",
      "Percentage of extracted cardinal numbers:  4.679245283018868\n",
      "Total of unique cardinal numbers:  30\n",
      "Percentage of unique cardinal numbers:  48.38709677419355\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  149\n",
      "Percentage of extracted dates:  11.245283018867925\n",
      "Total of unique dates:  111\n",
      "Percentage of unique dates:  74.49664429530202\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  7\n",
      "Percentage of extracted events:  0.5283018867924528\n",
      "Total of unique events:  5\n",
      "Percentage of unique events:  71.42857142857143\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  8\n",
      "Percentage of extracted facilities:  0.6037735849056604\n",
      "Total of unique facilities:  4\n",
      "Percentage of unique facilities:  50.0\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  165\n",
      "Percentage of extracted countries or cities:  12.452830188679245\n",
      "Total of unique countries or cities:  85\n",
      "Percentage of unique countries or cities:  51.515151515151516\n",
      "\n",
      "LANGUAGE\n",
      "Total of extracted languages:  3\n",
      "Percentage of extracted languages:  0.22641509433962265\n",
      "Total of unique languages:  2\n",
      "Percentage of unique languages:  66.66666666666666\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  4\n",
      "Percentage of extracted laws:  0.3018867924528302\n",
      "Total of unique laws:  4\n",
      "Percentage of unique laws:  100.0\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  9\n",
      "Percentage of extracted generic locations:  0.6792452830188679\n",
      "Total of unique generic locations:  8\n",
      "Percentage of unique generic locations:  88.88888888888889\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  8\n",
      "Percentage of extracted money values:  0.6037735849056604\n",
      "Total of unique money values:  8\n",
      "Percentage of unique money values:  100.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  133\n",
      "Percentage of extracted nationalities, religious or political groups:  10.037735849056602\n",
      "Total of unique nationalities, religious or political groups:  53\n",
      "Percentage of unique nationalities, religious or political groups:  39.849624060150376\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  15\n",
      "Percentage extracted ordinal numbers:  3.3207547169811322\n",
      "Total of unique ordinal numbers:  7\n",
      "Percentage of unique ordinal numbers:  46.666666666666664\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  350\n",
      "Percentage extracted companies or organizations:  26.41509433962264\n",
      "Total of unique companies or organizations:  227\n",
      "Percentage of unique companies or organizations:  64.85714285714286\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  4\n",
      "Percentage extracted percentages:  0.3018867924528302\n",
      "Total of unique percentages:  4\n",
      "Percentage of unique percentages:  100.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  363\n",
      "Percentage extracted people:  27.39622641509434\n",
      "Total of unique people:  258\n",
      "Percentage of unique people:  71.07438016528926\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  10\n",
      "Percentage extracted products:  0.7547169811320755\n",
      "Total of unique products:  6\n",
      "Percentage of unique products:  60.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  13\n",
      "Percentage of extracted times:  0.9811320754716981\n",
      "Total of unique times:  12\n",
      "Percentage of unique times:  92.3076923076923\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  22\n",
      "Percentage of extracted works of art:  1.6603773584905661\n",
      "Total of unique works of art:  22\n",
      "Percentage of unique works of art:  100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_calling)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_calling)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_calling/total_cardinal_calling)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_calling)\n",
    "print(\"Percentage of extracted dates: \", (total_date_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique dates: \", unique_date_calling)\n",
    "print(\"Percentage of unique dates: \", (unique_date_calling/total_date_calling)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_calling)\n",
    "print(\"Percentage of extracted events: \", (total_event_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique events: \", unique_event_calling)\n",
    "print(\"Percentage of unique events: \", (unique_event_calling/total_event_calling)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_calling)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_calling)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_calling/total_fac_calling)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_calling)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_calling)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_calling/total_gpe_calling)*100)\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(\"Total of extracted languages: \", total_language_calling)\n",
    "print(\"Percentage of extracted languages: \", (total_language_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique languages: \", unique_language_calling)\n",
    "print(\"Percentage of unique languages: \", (unique_language_calling/total_language_calling)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_calling)\n",
    "print(\"Percentage of extracted laws: \", (total_law_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique laws: \", unique_law_calling)\n",
    "print(\"Percentage of unique laws: \", (unique_law_calling/total_law_calling)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_calling)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_calling)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_calling/total_loc_calling)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money_calling)\n",
    "print(\"Percentage of extracted money values: \", (total_money_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique money values: \", unique_money_calling)\n",
    "print(\"Percentage of unique money values: \", (unique_money_calling/total_money_calling)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_calling)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_calling)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_calling/total_norp_calling)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_calling)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_loaded/total_entities_calling)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_calling)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_calling/total_ordinal_calling)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_calling)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_calling)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_calling/total_org_calling)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_calling)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_calling)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_calling/total_percent_calling)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_calling)\n",
    "print(\"Percentage extracted people: \", (total_person_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique people: \", unique_person_calling)\n",
    "print(\"Percentage of unique people: \", (unique_person_calling/total_person_calling)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_calling)\n",
    "print(\"Percentage extracted products: \", (total_product_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique products: \", unique_product_calling)\n",
    "print(\"Percentage of unique products: \", (unique_product_calling/total_product_calling)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_calling)\n",
    "print(\"Percentage of extracted times: \", (total_time_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique times: \", unique_time_calling)\n",
    "print(\"Percentage of unique times: \", (unique_time_calling/total_time_calling)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_calling)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_calling/total_entities_calling)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_calling)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_calling/total_woa_calling)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0cd8821e-87d7-4ba4-8e07-945cfa221d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "21\tORG: Trump\n",
      "15\tORG: FBI\n",
      "15\tCARDINAL: one\n",
      "12\tGPE: Iran\n",
      "12\tPERSON: Francis\n",
      "10\tGPE: US\n",
      "10\tORG: Church\n",
      "10\tORG: Assange\n",
      "9\tORG: Guardian\n",
      "9\tNORP: Muslim\n",
      "9\tNORP: Islamic\n",
      "8\tPERSON: Benedict\n",
      "7\tPERSON: Trump\n",
      "7\tDATE: today\n",
      "7\tORG: Google\n",
      "6\tPERSON: Peter Strzok\n",
      "6\tPERSON: Pope\n",
      "6\tNORP: Catholic\n",
      "6\tGPE: Russia\n",
      "5\tCARDINAL: two\n",
      "5\tORG: Kavanaugh\n",
      "5\tPERSON: Lisa Page\n",
      "5\tNORP: Republican\n",
      "5\tNORP: Russian\n",
      "5\tPERSON: Clinton\n",
      "5\tGPE: Syria\n",
      "5\tORG: CIA\n",
      "5\tNORP: Catholics\n",
      "5\tORDINAL: third\n",
      "5\tFAC: Vatican\n"
     ]
    }
   ],
   "source": [
    "calling_ents_count = Counter()\n",
    "\n",
    "for ent in total_calling_text.ents:\n",
    "    calling_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in calling_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "880546df-c7b4-4579-a851-e9bbd22ae873",
   "metadata": {},
   "outputs": [],
   "source": [
    "calling_cardinal_count = Counter()\n",
    "calling_date_count = Counter()\n",
    "calling_event_count = Counter()\n",
    "calling_fac_count = Counter()\n",
    "calling_gpe_count = Counter()\n",
    "calling_language_count = Counter()\n",
    "calling_law_count = Counter()\n",
    "calling_loc_count = Counter()\n",
    "calling_money_count = Counter()\n",
    "calling_norp_count = Counter()\n",
    "calling_ordinal_count = Counter()\n",
    "calling_org_count = Counter()\n",
    "calling_percent_count = Counter()\n",
    "calling_person_count = Counter()\n",
    "calling_product_count = Counter()\n",
    "calling_time_count = Counter()\n",
    "calling_woa_count = Counter()\n",
    "\n",
    "for ent in total_calling_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        calling_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        calling_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        calling_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        calling_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        calling_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LANGUAGE\"):\n",
    "        calling_language_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        calling_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        calling_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        calling_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        calling_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        calling_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        calling_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        calling_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        calling_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        calling_product_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        calling_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        calling_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "89f1aa40-0122-4680-be1a-47eb9aaf69b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "15\tCARDINAL: one\n",
      "5\tCARDINAL: two\n",
      "5\tCARDINAL: 11\n",
      "3\tCARDINAL: three\n",
      "2\tCARDINAL: at least one\n",
      "2\tCARDINAL: Two\n",
      "2\tCARDINAL: One\n",
      "2\tCARDINAL: Eleven\n",
      "2\tCARDINAL: 24:31\n",
      "2\tCARDINAL: 33:59\n",
      "\n",
      "MOST COMMON DATES\n",
      "7\tDATE: today\n",
      "4\tDATE: yesterday\n",
      "4\tDATE: Friday\n",
      "4\tDATE: 2015\n",
      "4\tDATE: Thursday\n",
      "3\tDATE: Sunday\n",
      "3\tDATE: Monday\n",
      "2\tDATE: February 2016\n",
      "2\tDATE: decades\n",
      "2\tDATE: this year\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "3\tEVENT: Holocaust\n",
      "1\tEVENT: WWII\n",
      "1\tEVENT: World Over\n",
      "1\tEVENT: World War\n",
      "1\tEVENT: the “World Meeting of Families\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "5\tFAC: Vatican\n",
      "1\tFAC: La Stampa\n",
      "1\tFAC: the White House\n",
      "1\tFAC: the Fourth Amendment\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "12\tGPE: Iran\n",
      "10\tGPE: US\n",
      "6\tGPE: Russia\n",
      "5\tGPE: Syria\n",
      "5\tGPE: Rome\n",
      "5\tGPE: Georgia\n",
      "4\tGPE: Israel\n",
      "4\tGPE: U.S.\n",
      "4\tGPE: the United States\n",
      "4\tGPE: America\n",
      "4\tGPE: Chile\n",
      "4\tGPE: Dallas\n",
      "3\tGPE: Barros\n",
      "3\tGPE: Orbán\n",
      "3\tGPE: Newark\n",
      "\n",
      "MOST COMMON LANGUAGES\n",
      "2\tLANGUAGE: English\n",
      "1\tLANGUAGE: Arabic\n",
      "\n",
      "MOST COMMON LAWS\n",
      "1\tLAW: Chapter 8\n",
      "1\tLAW: Trump’s\n",
      "1\tLAW: First Amendment\n",
      "1\tLAW: Constitution\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "2\tLOC: Europe\n",
      "1\tLOC: Marina Bay Sands\n",
      "1\tLOC: Bay Area\n",
      "1\tLOC: South Florida\n",
      "1\tLOC: Beltway\n",
      "1\tLOC: North America\n",
      "1\tLOC: the Southern District\n",
      "1\tLOC: Botham Jean\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "1\tMONEY: 15 million dollars\n",
      "1\tMONEY: $46 billion\n",
      "1\tMONEY: 45,000\n",
      "1\tMONEY: 8.00\n",
      "1\tMONEY: 8.51\n",
      "1\tMONEY: 7.55\n",
      "1\tMONEY: 6.00\n",
      "1\tMONEY: over $400,000\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "9\tNORP: Muslim\n",
      "9\tNORP: Islamic\n",
      "6\tNORP: Catholic\n",
      "5\tNORP: Republican\n",
      "5\tNORP: Russian\n",
      "5\tNORP: Catholics\n",
      "5\tNORP: Democrat\n",
      "5\tNORP: Christians\n",
      "5\tNORP: Dem\n",
      "4\tNORP: American\n",
      "4\tNORP: Christian\n",
      "4\tNORP: Jews\n",
      "4\tNORP: Russians\n",
      "4\tNORP: Indonesian\n",
      "4\tNORP: Jewish\n",
      "4\tNORP: Republicans\n",
      "3\tNORP: Democrats\n",
      "3\tNORP: Dems\n",
      "3\tNORP: Roman\n",
      "2\tNORP: Trump\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "5\tORDINAL: third\n",
      "3\tORDINAL: first\n",
      "2\tORDINAL: fourth\n",
      "2\tORDINAL: First\n",
      "1\tORDINAL: fifth\n",
      "1\tORDINAL: Second\n",
      "1\tORDINAL: Third\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "21\tORG: Trump\n",
      "15\tORG: FBI\n",
      "10\tORG: Church\n",
      "10\tORG: Assange\n",
      "9\tORG: Guardian\n",
      "7\tORG: Google\n",
      "5\tORG: Kavanaugh\n",
      "5\tORG: CIA\n",
      "5\tORG: Ford\n",
      "5\tORG: Mueller\n",
      "5\tORG: Acosta\n",
      "4\tORG: CDF\n",
      "4\tORG: Senate\n",
      "3\tORG: Carter Page\n",
      "3\tORG: White House\n",
      "3\tORG: Manafort\n",
      "3\tORG: Congress\n",
      "3\tORG: Darul Uloom\n",
      "3\tORG: Council\n",
      "3\tORG: the Supreme Court\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "1\tPERCENT: almost 90%\n",
      "1\tPERCENT: 100 %\n",
      "1\tPERCENT: 20 percent\n",
      "1\tPERCENT: around 46 percent\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "12\tPERSON: Francis\n",
      "8\tPERSON: Benedict\n",
      "7\tPERSON: Trump\n",
      "6\tPERSON: Peter Strzok\n",
      "6\tPERSON: Pope\n",
      "5\tPERSON: Lisa Page\n",
      "5\tPERSON: Clinton\n",
      "5\tPERSON: Haig\n",
      "5\tPERSON: Donald Trump\n",
      "4\tPERSON: Karadima\n",
      "4\tPERSON: Hillary Clinton\n",
      "4\tPERSON: Ramirez\n",
      "3\tPERSON: Kim\n",
      "3\tPERSON: Zakkout\n",
      "3\tPERSON: Hans Kung\n",
      "3\tPERSON: Kasper\n",
      "3\tPERSON: McCarrick\n",
      "3\tPERSON: Siraj Ibn Wahhaj\n",
      "3\tPERSON: Jamie\n",
      "2\tPERSON: Garcia Zarate\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "4\tPRODUCT: Twitter\n",
      "2\tPRODUCT: Cardinal McCarrick\n",
      "1\tPRODUCT: Cardinal Francisco Javier Errázuriz of Santiago\n",
      "1\tPRODUCT: Corker\n",
      "1\tPRODUCT: Facebook\n",
      "1\tPRODUCT: Avenatti\n",
      "\n",
      "MOST COMMON TIMES\n",
      "2\tTIME: night\n",
      "1\tTIME: hours\n",
      "1\tTIME: 30-minute\n",
      "1\tTIME: 02:00 EDT\n",
      "1\tTIME: earlier this morning\n",
      "1\tTIME: nighty-night\n",
      "1\tTIME: early Tuesday\n",
      "1\tTIME: morning\n",
      "1\tTIME: 11:45 EDT\n",
      "1\tTIME: afternoon\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "1\tWORK_OF_ART: The Realist Report\n",
      "1\tWORK_OF_ART: You’re a Jew\n",
      "1\tWORK_OF_ART: Sofian\n",
      "1\tWORK_OF_ART: Amoris Laetitia\n",
      "1\tWORK_OF_ART: PhD\n",
      "1\tWORK_OF_ART: The Great Left Hope\n",
      "1\tWORK_OF_ART: People of the Book\n",
      "1\tWORK_OF_ART: Principles of Catholic Theology\n",
      "1\tWORK_OF_ART: arch-conservative”\n",
      "1\tWORK_OF_ART: Sankt Gallen\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in calling_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in calling_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in calling_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in calling_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in calling_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LANGUAGES\")        \n",
    "for key, val in calling_language_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in calling_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in calling_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in calling_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in calling_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in calling_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in calling_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in calling_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in calling_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in calling_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")    \n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in calling_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in calling_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c7bc6e1-50e3-4400-9de4-412f6917a7dd",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_calling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5f78267-ace4-4093-ac76-e99daf63a7e2",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_calling['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_calling['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_calling['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_calling['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_calling['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(total_entities_dict_calling['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_calling['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_calling['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict_calling['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_calling['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_calling['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_calling['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_calling['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_calling['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_calling['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_calling['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_calling['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a0b60e4-2ef2-46cf-bdba-e480d0206215",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_calling)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4397fe9-1221-4b81-aa00-e3a1d209e9ab",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_calling['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_calling['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_calling['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_calling['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_calling['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(unique_entities_dict_calling['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_calling['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_calling['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict_calling['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_calling['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_calling['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_calling['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_calling['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_calling['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_calling['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_calling['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_calling['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b787e42-e4e6-4cd6-aef2-773846c8b8cf",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_calling_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9294a3-862d-4a03-a36f-019976d5ac30",
   "metadata": {},
   "source": [
    "### Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ef180-7395-448a-a054-163d4707114e",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Repetition class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7aed3bf1-2350-4918-ad25-a2aceeb0045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  18\n",
      "Total number of entities:  849\n",
      "Total number of unique entities:  551\n",
      "Percentage of unique entities:  64.89988221436984\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_repetition = {key: list(g) for key, g in groupby(sorted(total_repetition_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_repetition.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_repetition))\n",
    "\n",
    "total_entities_value_list_repetition = list()\n",
    "for i in total_entities_dict_repetition.values():\n",
    "    total_entities_value_list_repetition.append(i)\n",
    "    \n",
    "total_entities_repetition= len(sum(total_entities_value_list_repetition, []))\n",
    "print(\"Total number of entities: \", total_entities_repetition)\n",
    "\n",
    "unique_entities_dict_repetition = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_repetition_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_repetition = list()\n",
    "for i in unique_entities_dict_repetition.values():\n",
    "    unique_entities_value_list_repetition.append(i)\n",
    "    \n",
    "unique_entities_repetition= len(sum(unique_entities_value_list_repetition, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_repetition)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_repetition/total_entities_repetition)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "36ba6ec9-54f8-46cc-956a-4b20a00bd5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_repetition = len(total_entities_dict_repetition['CARDINAL'])\n",
    "total_date_repetition = len(total_entities_dict_repetition['DATE'])\n",
    "total_event_repetition = len(total_entities_dict_repetition['EVENT'])\n",
    "total_fac_repetition = len(total_entities_dict_repetition['FAC'])\n",
    "total_gpe_repetition = len(total_entities_dict_repetition['GPE'])\n",
    "total_language_repetition = len(total_entities_dict_repetition['LANGUAGE'])\n",
    "total_law_repetition = len(total_entities_dict_repetition['LAW'])\n",
    "total_loc_repetition = len(total_entities_dict_repetition['LOC'])\n",
    "total_money_repetition = len(total_entities_dict_repetition['MONEY'])\n",
    "total_norp_repetition = len(total_entities_dict_repetition['NORP'])\n",
    "total_ordinal_repetition = len(total_entities_dict_repetition['ORDINAL'])\n",
    "total_org_repetition = len(total_entities_dict_repetition['ORG'])\n",
    "total_percent_repetition = len(total_entities_dict_repetition['PERCENT'])\n",
    "total_person_repetition = len(total_entities_dict_repetition['PERSON'])\n",
    "total_product_repetition = len(total_entities_dict_repetition['PRODUCT'])\n",
    "total_quantity_repetition = len(total_entities_dict_repetition['QUANTITY'])\n",
    "total_time_repetition = len(total_entities_dict_repetition['TIME'])\n",
    "total_woa_repetition = len(total_entities_dict_repetition['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ef3f8ef7-0458-49b0-9c21-2ed3f02efe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_repetition = len(unique_entities_dict_repetition['CARDINAL'])\n",
    "unique_date_repetition = len(unique_entities_dict_repetition['DATE'])\n",
    "unique_event_repetition = len(unique_entities_dict_repetition['EVENT'])\n",
    "unique_fac_repetition = len(unique_entities_dict_repetition['FAC'])\n",
    "unique_gpe_repetition = len(unique_entities_dict_repetition['GPE'])\n",
    "unique_language_repetition = len(unique_entities_dict_repetition['LANGUAGE'])\n",
    "unique_law_repetition = len(unique_entities_dict_repetition['LAW'])\n",
    "unique_loc_repetition = len(unique_entities_dict_repetition['LOC'])\n",
    "unique_money_repetition = len(unique_entities_dict_repetition['MONEY'])\n",
    "unique_norp_repetition = len(unique_entities_dict_repetition['NORP'])\n",
    "unique_ordinal_repetition = len(unique_entities_dict_repetition['ORDINAL'])\n",
    "unique_org_repetition = len(unique_entities_dict_repetition['ORG'])\n",
    "unique_percent_repetition = len(unique_entities_dict_repetition['PERCENT'])\n",
    "unique_person_repetition = len(unique_entities_dict_repetition['PERSON'])\n",
    "unique_product_repetition = len(unique_entities_dict_repetition['PRODUCT'])\n",
    "unique_quantity_repetition = len(unique_entities_dict_repetition['QUANTITY'])\n",
    "unique_time_repetition = len(unique_entities_dict_repetition['TIME'])\n",
    "unique_woa_repetition = len(unique_entities_dict_repetition['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dc756ce7-7f3d-4bcd-adee-5ecf32515b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  62\n",
      "Percentage of extracted cardinal numbers:  7.302709069493522\n",
      "Total of unique cardinal numbers:  35\n",
      "Percentage of unique cardinal numbers:  56.451612903225815\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  94\n",
      "Percentage of extracted dates:  11.071849234393403\n",
      "Total of unique dates:  77\n",
      "Percentage of unique dates:  81.91489361702128\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  1\n",
      "Percentage of extracted events:  0.11778563015312131\n",
      "Total of unique events:  1\n",
      "Percentage of unique events:  100.0\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  12\n",
      "Percentage of extracted facilities:  1.4134275618374559\n",
      "Total of unique facilities:  7\n",
      "Percentage of unique facilities:  58.333333333333336\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  154\n",
      "Percentage of extracted countries or cities:  18.138987043580684\n",
      "Total of unique countries or cities:  63\n",
      "Percentage of unique countries or cities:  40.909090909090914\n",
      "\n",
      "LANGUAGE\n",
      "Total of extracted languages:  1\n",
      "Percentage of extracted languages:  0.11778563015312131\n",
      "Total of unique languages:  1\n",
      "Percentage of unique languages:  100.0\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  1\n",
      "Percentage of extracted laws:  0.11778563015312131\n",
      "Total of unique laws:  1\n",
      "Percentage of unique laws:  100.0\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  13\n",
      "Percentage of extracted generic locations:  1.5312131919905771\n",
      "Total of unique generic locations:  8\n",
      "Percentage of unique generic locations:  61.53846153846154\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  2\n",
      "Percentage of extracted money values:  0.23557126030624262\n",
      "Total of unique money values:  2\n",
      "Percentage of unique money values:  100.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  77\n",
      "Percentage of extracted nationalities, religious or political groups:  9.069493521790342\n",
      "Total of unique nationalities, religious or political groups:  49\n",
      "Percentage of unique nationalities, religious or political groups:  63.63636363636363\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  14\n",
      "Percentage extracted ordinal numbers:  1.6489988221436984\n",
      "Total of unique ordinal numbers:  6\n",
      "Percentage of unique ordinal numbers:  42.857142857142854\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  203\n",
      "Percentage extracted companies or organizations:  23.910482921083627\n",
      "Total of unique companies or organizations:  136\n",
      "Percentage of unique companies or organizations:  66.99507389162561\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  6\n",
      "Percentage extracted percentages:  0.7067137809187279\n",
      "Total of unique percentages:  6\n",
      "Percentage of unique percentages:  100.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  177\n",
      "Percentage extracted people:  20.848056537102476\n",
      "Total of unique people:  131\n",
      "Percentage of unique people:  74.01129943502825\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  9\n",
      "Percentage extracted products:  1.0600706713780919\n",
      "Total of unique products:  7\n",
      "Percentage of unique products:  77.77777777777779\n",
      "\n",
      "QUANTITY\n",
      "Total of extracted measurements:  2\n",
      "Percentage extracted measurements:  0.23557126030624262\n",
      "Total of unique measurements:  2\n",
      "Percentage of unique measurements:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  5\n",
      "Percentage of extracted times:  0.5889281507656066\n",
      "Total of unique times:  4\n",
      "Percentage of unique times:  80.0\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  16\n",
      "Percentage of extracted works of art:  1.884570082449941\n",
      "Total of unique works of art:  15\n",
      "Percentage of unique works of art:  93.75\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_repetition)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_repetition)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_repetition/total_cardinal_repetition)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_repetition)\n",
    "print(\"Percentage of extracted dates: \", (total_date_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique dates: \", unique_date_repetition)\n",
    "print(\"Percentage of unique dates: \", (unique_date_repetition/total_date_repetition)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_repetition)\n",
    "print(\"Percentage of extracted events: \", (total_event_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique events: \", unique_event_repetition)\n",
    "print(\"Percentage of unique events: \", (unique_event_repetition/total_event_repetition)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_repetition)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_repetition)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_repetition/total_fac_repetition)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_repetition)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_repetition)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_repetition/total_gpe_repetition)*100)\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(\"Total of extracted languages: \", total_language_repetition)\n",
    "print(\"Percentage of extracted languages: \", (total_language_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique languages: \", unique_language_repetition)\n",
    "print(\"Percentage of unique languages: \", (unique_language_repetition/total_language_repetition)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_repetition)\n",
    "print(\"Percentage of extracted laws: \", (total_law_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique laws: \", unique_law_repetition)\n",
    "print(\"Percentage of unique laws: \", (unique_law_repetition/total_law_repetition)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_repetition)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_repetition)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_repetition/total_loc_repetition)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money_repetition)\n",
    "print(\"Percentage of extracted money values: \", (total_money_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique money values: \", unique_money_repetition)\n",
    "print(\"Percentage of unique money values: \", (unique_money_repetition/total_money_repetition)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_repetition)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_repetition)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_repetition/total_norp_repetition)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_repetition)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_repetition)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_repetition/total_ordinal_repetition)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_repetition)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_repetition)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_repetition/total_org_repetition)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_repetition)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_repetition)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_repetition/total_percent_repetition)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_repetition)\n",
    "print(\"Percentage extracted people: \", (total_person_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique people: \", unique_person_repetition)\n",
    "print(\"Percentage of unique people: \", (unique_person_repetition/total_person_repetition)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_repetition)\n",
    "print(\"Percentage extracted products: \", (total_product_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique products: \", unique_product_repetition)\n",
    "print(\"Percentage of unique products: \", (unique_product_repetition/total_product_repetition)*100)\n",
    "print(\"\\nQUANTITY\")\n",
    "print(\"Total of extracted measurements: \", total_quantity_repetition)\n",
    "print(\"Percentage extracted measurements: \", (total_quantity_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique measurements: \", unique_quantity_repetition)\n",
    "print(\"Percentage of unique measurements: \", (unique_quantity_repetition/total_quantity_repetition)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_repetition)\n",
    "print(\"Percentage of extracted times: \", (total_time_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique times: \", unique_time_repetition)\n",
    "print(\"Percentage of unique times: \", (unique_time_repetition/total_time_repetition)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_repetition)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_repetition/total_entities_repetition)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_repetition)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_repetition/total_woa_repetition)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9f06eee7-60d0-4052-9cd2-e12ef5bef927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "21\tGPE: US\n",
      "13\tCARDINAL: one\n",
      "11\tGPE: Iran\n",
      "10\tORG: Trump\n",
      "10\tORG: FBI\n",
      "10\tORG: Church\n",
      "9\tGPE: Russia\n",
      "9\tORG: Council\n",
      "8\tNORP: Russian\n",
      "8\tPERSON: Trump\n",
      "7\tORG: Islam\n",
      "7\tCARDINAL: two\n",
      "6\tGPE: U.S.\n",
      "6\tNORP: Muslim\n",
      "6\tGPE: Rome\n",
      "6\tFAC: Vatican\n",
      "5\tORG: the Justice Department\n",
      "5\tGPE: Syria\n",
      "5\tLOC: Europe\n",
      "5\tGPE: the United States\n",
      "5\tORDINAL: first\n",
      "5\tGPE: China\n",
      "5\tGPE: Cuba\n",
      "5\tPERSON: Jean\n",
      "5\tPERSON: Perez\n",
      "4\tDATE: 2016\n",
      "4\tPERSON: Francis\n",
      "4\tPERSON: Saris\n",
      "4\tPERSON: Putin\n",
      "4\tDATE: today\n"
     ]
    }
   ],
   "source": [
    "repetition_ents_count = Counter()\n",
    "\n",
    "for ent in total_repetition_text.ents:\n",
    "    repetition_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in repetition_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "84c55c1c-d898-49ae-85bb-e7f6504dd67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_cardinal_count = Counter()\n",
    "repetition_date_count = Counter()\n",
    "repetition_event_count = Counter()\n",
    "repetition_fac_count = Counter()\n",
    "repetition_gpe_count = Counter()\n",
    "repetition_language_count = Counter()\n",
    "repetition_law_count = Counter()\n",
    "repetition_loc_count = Counter()\n",
    "repetition_money_count = Counter()\n",
    "repetition_norp_count = Counter()\n",
    "repetition_ordinal_count = Counter()\n",
    "repetition_org_count = Counter()\n",
    "repetition_percent_count = Counter()\n",
    "repetition_person_count = Counter()\n",
    "repetition_product_count = Counter()\n",
    "repetition_quantity_count = Counter()\n",
    "repetition_time_count = Counter()\n",
    "repetition_woa_count = Counter()\n",
    "\n",
    "for ent in total_repetition_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        repetition_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        repetition_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        repetition_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        repetition_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        repetition_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LANGUAGE\"):\n",
    "        repetition_language_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        repetition_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        repetition_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        repetition_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        repetition_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        repetition_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        repetition_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        repetition_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        repetition_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        repetition_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"QUANTITY\"):\n",
    "        repetition_quantity_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        repetition_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        repetition_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "471ddbc9-2cc6-4288-9837-cb2c7628e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "13\tCARDINAL: one\n",
      "7\tCARDINAL: two\n",
      "4\tCARDINAL: three\n",
      "3\tCARDINAL: #\n",
      "3\tCARDINAL: One\n",
      "2\tCARDINAL: 911\n",
      "2\tCARDINAL: six\n",
      "1\tCARDINAL: 2011.Kim\n",
      "1\tCARDINAL: more than 1,300\n",
      "1\tCARDINAL: almost 1 million\n",
      "\n",
      "MOST COMMON DATES\n",
      "4\tDATE: 2016\n",
      "4\tDATE: today\n",
      "4\tDATE: 2017\n",
      "3\tDATE: last year\n",
      "3\tDATE: 2009\n",
      "2\tDATE: 2010\n",
      "2\tDATE: the years\n",
      "2\tDATE: 5 years\n",
      "2\tDATE: the coming days\n",
      "1\tDATE: this year\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "1\tEVENT: the US Constitution\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "6\tFAC: Vatican\n",
      "1\tFAC: Alexandria’s\n",
      "1\tFAC: St. Cyr\n",
      "1\tFAC: EOIR\n",
      "1\tFAC: Vatican II\n",
      "1\tFAC: Reva Street\n",
      "1\tFAC: the Otay Mesa Port of Entry\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "21\tGPE: US\n",
      "11\tGPE: Iran\n",
      "9\tGPE: Russia\n",
      "6\tGPE: U.S.\n",
      "6\tGPE: Rome\n",
      "5\tGPE: Syria\n",
      "5\tGPE: the United States\n",
      "5\tGPE: China\n",
      "5\tGPE: Cuba\n",
      "4\tGPE: Paris\n",
      "3\tGPE: Israel\n",
      "3\tGPE: Indonesia\n",
      "3\tGPE: Sara\n",
      "3\tGPE: Las Vegas\n",
      "3\tGPE: San Antonio\n",
      "\n",
      "MOST COMMON LANGUAGES\n",
      "1\tLANGUAGE: English\n",
      "\n",
      "MOST COMMON LAWS\n",
      "1\tLAW: Sharia\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "5\tLOC: Europe\n",
      "2\tLOC: Earth\n",
      "1\tLOC: Saris\n",
      "1\tLOC: Mass\n",
      "1\tLOC: Barros\n",
      "1\tLOC: Baltics\n",
      "1\tLOC: the South Side Flats\n",
      "1\tLOC: the middle east\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "1\tMONEY: less than $10,000\n",
      "1\tMONEY: tens of billions of dollars\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "8\tNORP: Russian\n",
      "6\tNORP: Muslim\n",
      "4\tNORP: Democrats\n",
      "3\tNORP: Russians\n",
      "3\tNORP: Islamic\n",
      "3\tNORP: Muslims\n",
      "3\tNORP: Syrian\n",
      "2\tNORP: Iranian\n",
      "2\tNORP: Catholic\n",
      "2\tNORP: Christians\n",
      "2\tNORP: Jewish\n",
      "2\tNORP: British\n",
      "1\tNORP: Kurdish\n",
      "1\tNORP: Mexican\n",
      "1\tNORP: Greek\n",
      "1\tNORP: Chinese\n",
      "1\tNORP: Indonesian\n",
      "1\tNORP: Diocese\n",
      "1\tNORP: Protestant\n",
      "1\tNORP: Irish\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "5\tORDINAL: first\n",
      "3\tORDINAL: second\n",
      "2\tORDINAL: third\n",
      "2\tORDINAL: fourth\n",
      "1\tORDINAL: 20th\n",
      "1\tORDINAL: 30th\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "10\tORG: Trump\n",
      "10\tORG: FBI\n",
      "10\tORG: Church\n",
      "9\tORG: Council\n",
      "7\tORG: Islam\n",
      "5\tORG: the Justice Department\n",
      "3\tORG: the White House\n",
      "3\tORG: Comey’s\n",
      "3\tORG: Taser\n",
      "2\tORG: UMC Quick Care\n",
      "2\tORG: ISIS\n",
      "2\tORG: CFIUS\n",
      "2\tORG: Congress\n",
      "2\tORG: Eucharist\n",
      "2\tORG: AP\n",
      "2\tORG: Nation of Islam\n",
      "2\tORG: the Holy See\n",
      "2\tORG: @realDonaldTrump\n",
      "2\tORG: Amber Guyger\n",
      "2\tORG: House\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "1\tPERCENT: twenty-two percent\n",
      "1\tPERCENT: fifty percent\n",
      "1\tPERCENT: 12.7%\n",
      "1\tPERCENT: 11%\n",
      "1\tPERCENT: 1.2%\n",
      "1\tPERCENT: 0.8%\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "8\tPERSON: Trump\n",
      "5\tPERSON: Jean\n",
      "5\tPERSON: Perez\n",
      "4\tPERSON: Francis\n",
      "4\tPERSON: Saris\n",
      "4\tPERSON: Putin\n",
      "4\tPERSON: Kritarch Saris\n",
      "4\tPERSON: Clinton\n",
      "3\tPERSON: Lynch\n",
      "2\tPERSON: Julian Assange\n",
      "2\tPERSON: Obama\n",
      "2\tPERSON: Campos\n",
      "2\tPERSON: Muller\n",
      "2\tPERSON: John\n",
      "2\tPERSON: Pope\n",
      "2\tPERSON: Viktor Orban\n",
      "2\tPERSON: Common Core\n",
      "2\tPERSON: Barack Obama\n",
      "2\tPERSON: Ray\n",
      "2\tPERSON: Horowitz\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "2\tPRODUCT: Twitter\n",
      "2\tPRODUCT: Khweis\n",
      "1\tPRODUCT: JVP\n",
      "1\tPRODUCT: the Holy Bible\n",
      "1\tPRODUCT: Guyger\n",
      "1\tPRODUCT: Quaaludes\n",
      "1\tPRODUCT: Snopes\n",
      "\n",
      "MOST COMMON QUANTITIES\n",
      "1\tQUANTITY: about 3 miles\n",
      "1\tQUANTITY: 6.5 million miles\n",
      "\n",
      "MOST COMMON TIMES\n",
      "2\tTIME: afternoon\n",
      "1\tTIME: about eight hours\n",
      "1\tTIME: four minute\n",
      "1\tTIME: 1o o'clock\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "2\tWORK_OF_ART: Allahu Akbar\n",
      "1\tWORK_OF_ART: Fishback's Rubble and Rubble\n",
      "1\tWORK_OF_ART: Outbreaks\n",
      "1\tWORK_OF_ART: 2018The Instructions of the Carbonari\n",
      "1\tWORK_OF_ART: Cardinal O’Malley\n",
      "1\tWORK_OF_ART: Citizens of Newton\n",
      "1\tWORK_OF_ART: Principlism\n",
      "1\tWORK_OF_ART: Hippocratic\n",
      "1\tWORK_OF_ART: Natural Law\n",
      "1\tWORK_OF_ART: A ‘new dawn\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in repetition_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in repetition_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in repetition_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in repetition_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in repetition_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LANGUAGES\")        \n",
    "for key, val in repetition_language_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in repetition_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in repetition_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in repetition_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in repetition_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in repetition_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in repetition_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in repetition_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in repetition_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in repetition_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON QUANTITIES\")        \n",
    "for key, val in repetition_quantity_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in repetition_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in repetition_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57ba60b4-4709-4935-a282-dab678572e9a",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_repetition)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bad20707-5385-448c-a6a0-c6db1e18c5d1",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_repetition['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_repetition['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_repetition['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_repetition['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_repetition['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(total_entities_dict_repetition['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_repetition['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_repetition['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict_repetition['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_repetition['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_repetition['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_repetition['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_repetition['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_repetition['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_repetition['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(total_entities_dict_repetition['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_repetition['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_repetition['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "febe5323-39ae-49d8-ad7a-54ae452daa9f",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_repetition)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70749fc4-8e91-4951-808c-4354f8e02f32",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_repetition['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_repetition['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_repetition['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_repetition['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_repetition['GPE'])\n",
    "print(\"\\nLANGUAGE\")\n",
    "print(unique_entities_dict_repetition['LANGUAGE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_repetition['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_repetition['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict_repetition['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_repetition['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_repetition['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_repetition['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_repetition['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_repetition['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_repetition['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(unique_entities_dict_repetition['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_repetition['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_repetition['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8c647f8-97e9-4e43-b040-21158bfa8ce0",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_repetition_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace87989-d311-4c7b-b531-1d7e1a50872b",
   "metadata": {},
   "source": [
    "### Doubt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fd14a-3c7d-40cb-82a5-68edfc8a2186",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Doubt class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ab4c923c-9558-4f6d-b02d-e52bd023962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LAW', 'LOC', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  15\n",
      "Total number of entities:  820\n",
      "Total number of unique entities:  489\n",
      "Percentage of unique entities:  59.63414634146341\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_doubt = {key: list(g) for key, g in groupby(sorted(total_doubt_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_doubt.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_doubt))\n",
    "\n",
    "total_entities_value_list_doubt = list()\n",
    "for i in total_entities_dict_doubt.values():\n",
    "    total_entities_value_list_doubt.append(i)\n",
    "    \n",
    "total_entities_doubt= len(sum(total_entities_value_list_doubt, []))\n",
    "print(\"Total number of entities: \", total_entities_doubt)\n",
    "\n",
    "unique_entities_dict_doubt = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_doubt_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_doubt = list()\n",
    "for i in unique_entities_dict_doubt.values():\n",
    "    unique_entities_value_list_doubt.append(i)\n",
    "    \n",
    "unique_entities_doubt = len(sum(unique_entities_value_list_doubt, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_doubt)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_doubt/total_entities_doubt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e04fb083-fc21-4e1b-a93c-9bb0ad6b0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_doubt = len(total_entities_dict_doubt['CARDINAL'])\n",
    "total_date_doubt = len(total_entities_dict_doubt['DATE'])\n",
    "total_event_doubt = len(total_entities_dict_doubt['EVENT'])\n",
    "total_fac_doubt = len(total_entities_dict_doubt['FAC'])\n",
    "total_gpe_doubt = len(total_entities_dict_doubt['GPE'])\n",
    "total_law_doubt = len(total_entities_dict_doubt['LAW'])\n",
    "total_loc_doubt = len(total_entities_dict_doubt['LOC'])\n",
    "total_norp_doubt = len(total_entities_dict_doubt['NORP'])\n",
    "total_ordinal_doubt = len(total_entities_dict_doubt['ORDINAL'])\n",
    "total_org_doubt = len(total_entities_dict_doubt['ORG'])\n",
    "total_percent_doubt = len(total_entities_dict_doubt['PERCENT'])\n",
    "total_person_doubt = len(total_entities_dict_doubt['PERSON'])\n",
    "total_product_doubt = len(total_entities_dict_doubt['PRODUCT'])\n",
    "total_time_doubt = len(total_entities_dict_doubt['TIME'])\n",
    "total_woa_doubt = len(total_entities_dict_doubt['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b1e56ab4-712b-4b43-a496-2b802697ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_doubt = len(unique_entities_dict_doubt['CARDINAL'])\n",
    "unique_date_doubt = len(unique_entities_dict_doubt['DATE'])\n",
    "unique_event_doubt = len(unique_entities_dict_doubt['EVENT'])\n",
    "unique_fac_doubt = len(unique_entities_dict_doubt['FAC'])\n",
    "unique_gpe_doubt = len(unique_entities_dict_doubt['GPE'])\n",
    "unique_law_doubt = len(unique_entities_dict_doubt['LAW'])\n",
    "unique_loc_doubt = len(unique_entities_dict_doubt['LOC'])\n",
    "unique_norp_doubt = len(unique_entities_dict_doubt['NORP'])\n",
    "unique_ordinal_doubt = len(unique_entities_dict_doubt['ORDINAL'])\n",
    "unique_org_doubt = len(unique_entities_dict_doubt['ORG'])\n",
    "unique_percent_doubt = len(unique_entities_dict_doubt['PERCENT'])\n",
    "unique_person_doubt = len(unique_entities_dict_doubt['PERSON'])\n",
    "unique_product_doubt = len(unique_entities_dict_doubt['PRODUCT'])\n",
    "unique_time_doubt = len(unique_entities_dict_doubt['TIME'])\n",
    "unique_woa_doubt = len(unique_entities_dict_doubt['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "37c3c6f6-3f91-44b4-86db-986bf6af75be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  51\n",
      "Percentage of extracted cardinal numbers:  6.219512195121951\n",
      "Total of unique cardinal numbers:  33\n",
      "Percentage of unique cardinal numbers:  64.70588235294117\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  99\n",
      "Percentage of extracted dates:  12.073170731707316\n",
      "Total of unique dates:  78\n",
      "Percentage of unique dates:  78.78787878787878\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  4\n",
      "Percentage of extracted events:  0.4878048780487805\n",
      "Total of unique events:  4\n",
      "Percentage of unique events:  100.0\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  8\n",
      "Percentage of extracted facilities:  0.975609756097561\n",
      "Total of unique facilities:  5\n",
      "Percentage of unique facilities:  62.5\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  112\n",
      "Percentage of extracted countries or cities:  13.658536585365855\n",
      "Total of unique countries or cities:  60\n",
      "Percentage of unique countries or cities:  53.57142857142857\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  7\n",
      "Percentage of extracted laws:  0.853658536585366\n",
      "Total of unique laws:  7\n",
      "Percentage of unique laws:  100.0\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  12\n",
      "Percentage of extracted generic locations:  1.4634146341463417\n",
      "Total of unique generic locations:  3\n",
      "Percentage of unique generic locations:  25.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  51\n",
      "Percentage of extracted nationalities, religious or political groups:  6.219512195121951\n",
      "Total of unique nationalities, religious or political groups:  28\n",
      "Percentage of unique nationalities, religious or political groups:  54.90196078431373\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  12\n",
      "Percentage extracted ordinal numbers:  1.4634146341463417\n",
      "Total of unique ordinal numbers:  4\n",
      "Percentage of unique ordinal numbers:  33.33333333333333\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  221\n",
      "Percentage extracted companies or organizations:  26.951219512195124\n",
      "Total of unique companies or organizations:  118\n",
      "Percentage of unique companies or organizations:  53.39366515837104\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  1\n",
      "Percentage extracted percentages:  0.12195121951219512\n",
      "Total of unique percentages:  1\n",
      "Percentage of unique percentages:  100.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  191\n",
      "Percentage extracted people:  23.29268292682927\n",
      "Total of unique people:  108\n",
      "Percentage of unique people:  56.54450261780105\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  2\n",
      "Percentage extracted products:  0.24390243902439024\n",
      "Total of unique products:  2\n",
      "Percentage of unique products:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  37\n",
      "Percentage of extracted times:  4.512195121951219\n",
      "Total of unique times:  29\n",
      "Percentage of unique times:  78.37837837837837\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  12\n",
      "Percentage of extracted works of art:  1.4634146341463417\n",
      "Total of unique works of art:  9\n",
      "Percentage of unique works of art:  75.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_doubt)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_doubt)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_doubt/total_cardinal_doubt)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_doubt)\n",
    "print(\"Percentage of extracted dates: \", (total_date_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique dates: \", unique_date_doubt)\n",
    "print(\"Percentage of unique dates: \", (unique_date_doubt/total_date_doubt)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_doubt)\n",
    "print(\"Percentage of extracted events: \", (total_event_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique events: \", unique_event_doubt)\n",
    "print(\"Percentage of unique events: \", (unique_event_doubt/total_event_doubt)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_doubt)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_doubt)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_doubt/total_fac_doubt)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_doubt)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_doubt)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_doubt/total_gpe_doubt)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_doubt)\n",
    "print(\"Percentage of extracted laws: \", (total_law_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique laws: \", unique_law_doubt)\n",
    "print(\"Percentage of unique laws: \", (unique_law_doubt/total_law_doubt)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_doubt)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_doubt)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_doubt/total_loc_doubt)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_doubt)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_doubt)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_doubt/total_norp_doubt)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_doubt)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_doubt)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_doubt/total_ordinal_doubt)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_doubt)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_doubt)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_doubt/total_org_doubt)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_doubt)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_doubt)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_doubt/total_percent_doubt)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_doubt)\n",
    "print(\"Percentage extracted people: \", (total_person_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique people: \", unique_person_doubt)\n",
    "print(\"Percentage of unique people: \", (unique_person_doubt/total_person_doubt)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_doubt)\n",
    "print(\"Percentage extracted products: \", (total_product_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique products: \", unique_product_doubt)\n",
    "print(\"Percentage of unique products: \", (unique_product_doubt/total_product_doubt)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_doubt)\n",
    "print(\"Percentage of extracted times: \", (total_time_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique times: \", unique_time_doubt)\n",
    "print(\"Percentage of unique times: \", (unique_time_doubt/total_time_doubt)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_doubt)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_doubt/total_entities_doubt)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_doubt)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_doubt/total_woa_doubt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "15e9f8e4-5b10-4fbd-8265-cbc4f04ea7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "17\tPERSON: Campos\n",
      "12\tGPE: Las Vegas\n",
      "12\tORG: FBI\n",
      "11\tPERSON: Paddock\n",
      "10\tORG: Trump\n",
      "10\tLOC: Mandalay Bay\n",
      "9\tPERSON: Francis\n",
      "9\tCARDINAL: one\n",
      "9\tORG: Assange\n",
      "9\tORG: Guardian\n",
      "8\tGPE: Iran\n",
      "8\tGPE: Syria\n",
      "8\tORDINAL: first\n",
      "8\tPERSON: Ford\n",
      "7\tCARDINAL: two\n",
      "7\tORG: Lambert\n",
      "6\tORG: ISIS\n",
      "6\tPERSON: Lombardo\n",
      "6\tDATE: Friday\n",
      "6\tGPE: U.S.\n",
      "6\tORG: UN\n",
      "6\tORG: Ford\n",
      "6\tPERSON: Gillum\n",
      "5\tORG: Kavanaugh\n",
      "5\tDATE: Thursday\n",
      "5\tPERSON: Stephen Paddock\n",
      "5\tORG: TENEX\n",
      "5\tGPE: Russia\n",
      "4\tORG: White House\n",
      "4\tTIME: 9:59 p.m.\n"
     ]
    }
   ],
   "source": [
    "doubt_ents_count = Counter()\n",
    "\n",
    "for ent in total_doubt_text.ents:\n",
    "    doubt_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in doubt_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ea5afb19-d6cf-40c2-8307-d775ec638380",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubt_cardinal_count = Counter()\n",
    "doubt_date_count = Counter()\n",
    "doubt_event_count = Counter()\n",
    "doubt_fac_count = Counter()\n",
    "doubt_gpe_count = Counter()\n",
    "doubt_law_count = Counter()\n",
    "doubt_loc_count = Counter()\n",
    "doubt_norp_count = Counter()\n",
    "doubt_ordinal_count = Counter()\n",
    "doubt_org_count = Counter()\n",
    "doubt_percent_count = Counter()\n",
    "doubt_person_count = Counter()\n",
    "doubt_product_count = Counter()\n",
    "doubt_time_count = Counter()\n",
    "doubt_woa_count = Counter()\n",
    "\n",
    "for ent in total_doubt_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        doubt_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        doubt_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        doubt_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        doubt_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        doubt_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        doubt_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        doubt_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        doubt_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        doubt_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        doubt_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        doubt_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        doubt_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        doubt_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        doubt_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        doubt_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "63d72dff-1fd0-4735-8738-1416d6d5c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "9\tCARDINAL: one\n",
      "7\tCARDINAL: two\n",
      "3\tCARDINAL: four\n",
      "2\tCARDINAL: dozens\n",
      "2\tCARDINAL: 11\n",
      "1\tCARDINAL: 59\n",
      "1\tCARDINAL: over 500\n",
      "1\tCARDINAL: hundreds\n",
      "1\tCARDINAL: 32\n",
      "1\tCARDINAL: 911\n",
      "\n",
      "MOST COMMON DATES\n",
      "6\tDATE: Friday\n",
      "5\tDATE: Thursday\n",
      "4\tDATE: Monday\n",
      "4\tDATE: 2016\n",
      "3\tDATE: today\n",
      "2\tDATE: Tuesday\n",
      "2\tDATE: Oct. 1\n",
      "2\tDATE: October\n",
      "2\tDATE: daily\n",
      "1\tDATE: Wednesday\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "1\tEVENT: Geneva -\n",
      "1\tEVENT: the Great Western Schism\n",
      "1\tEVENT: the Third Secret\n",
      "1\tEVENT: the Second Amendment\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "3\tFAC: Metro\n",
      "2\tFAC: Route 91 Harvest\n",
      "1\tFAC: Noah Lew\n",
      "1\tFAC: Travis Air Force\n",
      "1\tFAC: Vatican\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "12\tGPE: Las Vegas\n",
      "8\tGPE: Iran\n",
      "8\tGPE: Syria\n",
      "6\tGPE: U.S.\n",
      "5\tGPE: Russia\n",
      "4\tGPE: Australia\n",
      "3\tGPE: Baghdad\n",
      "3\tGPE: Damascus\n",
      "3\tGPE: Obama\n",
      "2\tGPE: Israel\n",
      "2\tGPE: Msgr\n",
      "2\tGPE: Afghanistan\n",
      "2\tGPE: Vadim Mikerin\n",
      "2\tGPE: Rome\n",
      "2\tGPE: US\n",
      "\n",
      "MOST COMMON LAWS\n",
      "1\tLAW: the Real Presence in the Mass - in the Sacrifice of the Mass\n",
      "1\tLAW: the Foreign Corrupt Practices Act\n",
      "1\tLAW: Article 19 of the Universal Declaration of Human Rights\n",
      "1\tLAW: Romans 13\n",
      "1\tLAW: Article 675 of the Catechism of the Catholic Church\n",
      "1\tLAW: Fr.\n",
      "1\tLAW: Constitution\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "10\tLOC: Mandalay Bay\n",
      "1\tLOC: Beltway\n",
      "1\tLOC: Middle Eastern Christians\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "4\tNORP: American\n",
      "4\tNORP: Syrian\n",
      "4\tNORP: Democratic\n",
      "3\tNORP: Muslim\n",
      "3\tNORP: Russian\n",
      "3\tNORP: Romans\n",
      "2\tNORP: Shiite\n",
      "2\tNORP: Catholics\n",
      "2\tNORP: Iranian\n",
      "2\tNORP: Kurds\n",
      "2\tNORP: Jewish\n",
      "2\tNORP: anti-Semitic\n",
      "2\tNORP: Republicans\n",
      "2\tNORP: French\n",
      "1\tNORP: Iraqi\n",
      "1\tNORP: neo-Catholic\n",
      "1\tNORP: Modernist\n",
      "1\tNORP: Turks\n",
      "1\tNORP: Americans\n",
      "1\tNORP: Awans\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "8\tORDINAL: first\n",
      "2\tORDINAL: First\n",
      "1\tORDINAL: second\n",
      "1\tORDINAL: Fourth\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "12\tORG: FBI\n",
      "10\tORG: Trump\n",
      "9\tORG: Assange\n",
      "9\tORG: Guardian\n",
      "7\tORG: Lambert\n",
      "6\tORG: ISIS\n",
      "6\tORG: UN\n",
      "6\tORG: Ford\n",
      "5\tORG: Kavanaugh\n",
      "5\tORG: TENEX\n",
      "4\tORG: White House\n",
      "4\tORG: Lombardo\n",
      "4\tORG: Church\n",
      "4\tORG: Congress\n",
      "4\tORG: CIA\n",
      "4\tORG: Qur’an\n",
      "3\tORG: MGM\n",
      "3\tORG: CNN\n",
      "3\tORG: Transportation Corporation\n",
      "3\tORG: AP\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "1\tPERCENT: one hundred percent\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "17\tPERSON: Campos\n",
      "11\tPERSON: Paddock\n",
      "9\tPERSON: Francis\n",
      "8\tPERSON: Ford\n",
      "6\tPERSON: Lombardo\n",
      "6\tPERSON: Gillum\n",
      "5\tPERSON: Stephen Paddock\n",
      "4\tPERSON: Pope\n",
      "4\tPERSON: Kavanaugh\n",
      "3\tPERSON: Jesus Campos\n",
      "3\tPERSON: Haley\n",
      "3\tPERSON: Carlson\n",
      "3\tPERSON: Tillerson\n",
      "3\tPERSON: Abrams\n",
      "3\tPERSON: Smith\n",
      "2\tPERSON: Christine Blasey Ford\n",
      "2\tPERSON: Trump\n",
      "2\tPERSON: Stephen Paddock’s\n",
      "2\tPERSON: Saint Francis’\n",
      "2\tPERSON: Hillary Clinton\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "1\tPRODUCT: Pius XII\n",
      "1\tPRODUCT: Twitter\n",
      "\n",
      "MOST COMMON TIMES\n",
      "4\tTIME: 9:59 p.m.\n",
      "3\tTIME: 10:05 p.m.\n",
      "3\tTIME: 6 minutes\n",
      "2\tTIME: six minutes\n",
      "1\tTIME: 10 minutes\n",
      "1\tTIME: hours\n",
      "1\tTIME: six-minute\n",
      "1\tTIME: 10:17 p.m.\n",
      "1\tTIME: two minutes\n",
      "1\tTIME: the 9:59 p.m.\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "2\tWORK_OF_ART: FCPA\n",
      "2\tWORK_OF_ART: Sharia\n",
      "2\tWORK_OF_ART: sources”\n",
      "1\tWORK_OF_ART: The Ellen DeGeneres Show\n",
      "1\tWORK_OF_ART: PhD\n",
      "1\tWORK_OF_ART: islamofauxbic”?Capitol Police\n",
      "1\tWORK_OF_ART: Bible\n",
      "1\tWORK_OF_ART: The Secret Still Hidden\n",
      "1\tWORK_OF_ART: Idiot\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in doubt_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in doubt_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in doubt_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in doubt_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in doubt_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in doubt_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in doubt_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\") \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in doubt_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in doubt_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in doubt_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in doubt_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in doubt_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in doubt_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "        \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in doubt_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in doubt_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7d672b5-b04d-49a5-9cf5-f7986cdba7fd",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_doubt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17de3790-14ca-484b-86d2-912e970009af",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_doubt['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_doubt['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_doubt['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_doubt['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_doubt['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_doubt['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_doubt['LOC'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_doubt['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_doubt['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_doubt['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_doubt['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_doubt['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_doubt['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_doubt['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_doubt['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9df7f41d-c189-462e-92ce-24b2691d4013",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_doubt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b2942a6-4ba5-46f3-a17b-683aa312fb2f",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_doubt['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_doubt['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_doubt['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_doubt['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_doubt['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_doubt['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_doubt['LOC'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_doubt['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_doubt['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_doubt['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_doubt['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_doubt['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_doubt['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_doubt['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_doubt['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aea6f9a-1e15-4d03-8ff7-445a5d5718f9",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_doubt_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9571f-3d80-4bad-adad-647165b4c582",
   "metadata": {},
   "source": [
    "### Appeal_to_Fear-Prejudice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c28fb4b-e574-4832-9340-e6dd0a9de429",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Appeal_to_Fear-Prejudice class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d0ef03e0-5fa0-4f8a-8ba5-fb8e3d1ce7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  16\n",
      "Total number of entities:  491\n",
      "Total number of unique entities:  302\n",
      "Percentage of unique entities:  61.5071283095723\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_prejudice = {key: list(g) for key, g in groupby(sorted(total_prejudice_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_prejudice.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_prejudice))\n",
    "\n",
    "total_entities_value_list_prejudice = list()\n",
    "for i in total_entities_dict_prejudice.values():\n",
    "    total_entities_value_list_prejudice.append(i)\n",
    "    \n",
    "total_entities_prejudice = len(sum(total_entities_value_list_prejudice, []))\n",
    "print(\"Total number of entities: \", total_entities_prejudice)\n",
    "\n",
    "unique_entities_dict_prejudice = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_prejudice_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_prejudice = list()\n",
    "for i in unique_entities_dict_prejudice.values():\n",
    "    unique_entities_value_list_prejudice.append(i)\n",
    "    \n",
    "unique_entities_prejudice = len(sum(unique_entities_value_list_prejudice, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_prejudice)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_prejudice/total_entities_prejudice)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a643009c-60de-4cc3-b00f-b33cfa7b9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_prejudice = len(total_entities_dict_prejudice['CARDINAL'])\n",
    "total_date_prejudice = len(total_entities_dict_prejudice['DATE'])\n",
    "total_event_prejudice = len(total_entities_dict_prejudice['EVENT'])\n",
    "total_fac_prejudice = len(total_entities_dict_prejudice['FAC'])\n",
    "total_gpe_prejudice = len(total_entities_dict_prejudice['GPE'])\n",
    "total_law_prejudice = len(total_entities_dict_prejudice['LAW'])\n",
    "total_loc_prejudice = len(total_entities_dict_prejudice['LOC'])\n",
    "total_money_prejudice = len(total_entities_dict_prejudice['MONEY'])\n",
    "total_norp_prejudice = len(total_entities_dict_prejudice['NORP'])\n",
    "total_ordinal_prejudice = len(total_entities_dict_prejudice['ORDINAL'])\n",
    "total_org_prejudice = len(total_entities_dict_prejudice['ORG'])\n",
    "total_percent_prejudice = len(total_entities_dict_prejudice['PERCENT'])\n",
    "total_person_prejudice = len(total_entities_dict_prejudice['PERSON'])\n",
    "total_product_prejudice = len(total_entities_dict_prejudice['PRODUCT'])\n",
    "total_time_prejudice = len(total_entities_dict_prejudice['TIME'])\n",
    "total_woa_prejudice = len(total_entities_dict_prejudice['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "95710bc8-54b8-4879-8a4b-fdd1f4d8c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_prejudice = len(unique_entities_dict_prejudice['CARDINAL'])\n",
    "unique_date_prejudice = len(unique_entities_dict_prejudice['DATE'])\n",
    "unique_event_prejudice = len(unique_entities_dict_prejudice['EVENT'])\n",
    "unique_fac_prejudice = len(unique_entities_dict_prejudice['FAC'])\n",
    "unique_gpe_prejudice = len(unique_entities_dict_prejudice['GPE'])\n",
    "unique_law_prejudice = len(unique_entities_dict_prejudice['LAW'])\n",
    "unique_loc_prejudice = len(unique_entities_dict_prejudice['LOC'])\n",
    "unique_money_prejudice = len(unique_entities_dict_prejudice['MONEY'])\n",
    "unique_norp_prejudice = len(unique_entities_dict_prejudice['NORP'])\n",
    "unique_ordinal_prejudice = len(unique_entities_dict_prejudice['ORDINAL'])\n",
    "unique_org_prejudice = len(unique_entities_dict_prejudice['ORG'])\n",
    "unique_percent_prejudice = len(unique_entities_dict_prejudice['PERCENT'])\n",
    "unique_person_prejudice = len(unique_entities_dict_prejudice['PERSON'])\n",
    "unique_product_prejudice = len(unique_entities_dict_prejudice['PRODUCT'])\n",
    "unique_time_prejudice = len(unique_entities_dict_prejudice['TIME'])\n",
    "unique_woa_prejudice = len(unique_entities_dict_prejudice['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ca559868-097c-4411-b3ad-e653171f267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  28\n",
      "Percentage of extracted cardinal numbers:  5.7026476578411405\n",
      "Total of unique cardinal numbers:  18\n",
      "Percentage of unique cardinal numbers:  64.28571428571429\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  43\n",
      "Percentage of extracted dates:  8.757637474541752\n",
      "Total of unique dates:  30\n",
      "Percentage of unique dates:  69.76744186046511\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  3\n",
      "Percentage of extracted events:  0.6109979633401221\n",
      "Total of unique events:  3\n",
      "Percentage of unique events:  100.0\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  1\n",
      "Percentage of extracted facilities:  0.20366598778004072\n",
      "Total of unique facilities:  1\n",
      "Percentage of unique facilities:  100.0\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  135\n",
      "Percentage of extracted countries or cities:  27.494908350305497\n",
      "Total of unique countries or cities:  55\n",
      "Percentage of unique countries or cities:  40.74074074074074\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  1\n",
      "Percentage of extracted laws:  0.20366598778004072\n",
      "Total of unique laws:  1\n",
      "Percentage of unique laws:  100.0\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  14\n",
      "Percentage of extracted generic locations:  2.8513238289205702\n",
      "Total of unique generic locations:  7\n",
      "Percentage of unique generic locations:  50.0\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  1\n",
      "Percentage of extracted money values:  0.20366598778004072\n",
      "Total of unique money values:  1\n",
      "Percentage of unique money values:  100.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  72\n",
      "Percentage of extracted nationalities, religious or political groups:  14.663951120162933\n",
      "Total of unique nationalities, religious or political groups:  42\n",
      "Percentage of unique nationalities, religious or political groups:  58.333333333333336\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  4\n",
      "Percentage extracted ordinal numbers:  8.961303462321792\n",
      "Total of unique ordinal numbers:  2\n",
      "Percentage of unique ordinal numbers:  50.0\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  80\n",
      "Percentage extracted companies or organizations:  16.293279022403258\n",
      "Total of unique companies or organizations:  57\n",
      "Percentage of unique companies or organizations:  71.25\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  4\n",
      "Percentage extracted percentages:  0.8146639511201629\n",
      "Total of unique percentages:  3\n",
      "Percentage of unique percentages:  75.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  96\n",
      "Percentage extracted people:  19.551934826883908\n",
      "Total of unique people:  74\n",
      "Percentage of unique people:  77.08333333333334\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  2\n",
      "Percentage extracted products:  0.40733197556008144\n",
      "Total of unique products:  1\n",
      "Percentage of unique products:  50.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  2\n",
      "Percentage of extracted times:  0.40733197556008144\n",
      "Total of unique times:  2\n",
      "Percentage of unique times:  100.0\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  5\n",
      "Percentage of extracted works of art:  1.0183299389002036\n",
      "Total of unique works of art:  5\n",
      "Percentage of unique works of art:  100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_prejudice)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_prejudice)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_prejudice/total_cardinal_prejudice)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_prejudice)\n",
    "print(\"Percentage of extracted dates: \", (total_date_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique dates: \", unique_date_prejudice)\n",
    "print(\"Percentage of unique dates: \", (unique_date_prejudice/total_date_prejudice)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_prejudice)\n",
    "print(\"Percentage of extracted events: \", (total_event_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique events: \", unique_event_prejudice)\n",
    "print(\"Percentage of unique events: \", (unique_event_prejudice/total_event_prejudice)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_prejudice)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_prejudice)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_prejudice/total_fac_prejudice)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_prejudice)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_prejudice)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_prejudice/total_gpe_prejudice)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_prejudice)\n",
    "print(\"Percentage of extracted laws: \", (total_law_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique laws: \", unique_law_prejudice)\n",
    "print(\"Percentage of unique laws: \", (unique_law_prejudice/total_law_prejudice)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_prejudice)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_prejudice)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_prejudice/total_loc_prejudice)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money_prejudice)\n",
    "print(\"Percentage of extracted money values: \", (total_money_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique money values: \", unique_money_prejudice)\n",
    "print(\"Percentage of unique money values: \", (unique_money_prejudice/total_money_prejudice)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_prejudice)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_prejudice)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_prejudice/total_norp_prejudice)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_prejudice)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_loaded/total_entities_prejudice)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_prejudice)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_prejudice/total_ordinal_prejudice)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_prejudice)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_prejudice)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_prejudice/total_org_prejudice)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_prejudice)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_prejudice)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_prejudice/total_percent_prejudice)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_prejudice)\n",
    "print(\"Percentage extracted people: \", (total_person_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique people: \", unique_person_prejudice)\n",
    "print(\"Percentage of unique people: \", (unique_person_prejudice/total_person_prejudice)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_prejudice)\n",
    "print(\"Percentage extracted products: \", (total_product_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique products: \", unique_product_prejudice)\n",
    "print(\"Percentage of unique products: \", (unique_product_prejudice/total_product_prejudice)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_prejudice)\n",
    "print(\"Percentage of extracted times: \", (total_time_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique times: \", unique_time_prejudice)\n",
    "print(\"Percentage of unique times: \", (unique_time_prejudice/total_time_prejudice)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_prejudice)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_prejudice/total_entities_prejudice)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_prejudice)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_prejudice/total_woa_prejudice)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "661a23f4-00ba-4a03-be3f-8ad6625dc07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "22\tGPE: Iran\n",
      "13\tGPE: U.S.\n",
      "10\tGPE: Syria\n",
      "8\tORG: Church\n",
      "8\tGPE: the United States\n",
      "7\tPERSON: Trump\n",
      "7\tCARDINAL: one\n",
      "6\tGPE: Iraq\n",
      "6\tPERSON: Donald Trump\n",
      "6\tGPE: UK\n",
      "5\tNORP: Muslim\n",
      "5\tGPE: US\n",
      "5\tORG: Trump\n",
      "4\tORG: ISIS\n",
      "4\tDATE: Tuesday\n",
      "4\tNORP: Syrian\n",
      "4\tORG: Hezbollah\n",
      "4\tLOC: Africa\n",
      "4\tDATE: May\n",
      "4\tLOC: Europe\n",
      "4\tNORP: Islamic\n",
      "4\tNORP: Muslims\n",
      "4\tGPE: Khashoggi\n",
      "3\tGPE: Madagascar\n",
      "3\tNORP: Iranian\n",
      "3\tNORP: British\n",
      "3\tNORP: German\n",
      "3\tORDINAL: first\n",
      "3\tPERSON: Bagheri\n",
      "3\tNORP: African\n"
     ]
    }
   ],
   "source": [
    "prejudice_ents_count = Counter()\n",
    "\n",
    "for ent in total_prejudice_text.ents:\n",
    "    prejudice_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in prejudice_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6d101090-1025-4e93-8c3e-0ca79bb98634",
   "metadata": {},
   "outputs": [],
   "source": [
    "prejudice_cardinal_count = Counter()\n",
    "prejudice_date_count = Counter()\n",
    "prejudice_event_count = Counter()\n",
    "prejudice_fac_count = Counter()\n",
    "prejudice_gpe_count = Counter()\n",
    "prejudice_law_count = Counter()\n",
    "prejudice_loc_count = Counter()\n",
    "prejudice_money_count = Counter()\n",
    "prejudice_norp_count = Counter()\n",
    "prejudice_ordinal_count = Counter()\n",
    "prejudice_org_count = Counter()\n",
    "prejudice_percent_count = Counter()\n",
    "prejudice_person_count = Counter()\n",
    "prejudice_product_count = Counter()\n",
    "prejudice_time_count = Counter()\n",
    "prejudice_woa_count = Counter()\n",
    "\n",
    "for ent in total_prejudice_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        prejudice_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        prejudice_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        prejudice_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        prejudice_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        prejudice_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1  \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        prejudice_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        prejudice_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        prejudice_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        prejudice_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        prejudice_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        prejudice_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        prejudice_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        prejudice_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        prejudice_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        prejudice_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        prejudice_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "62598ed7-f64c-4873-9b51-ac2367be35c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "7\tCARDINAL: one\n",
      "2\tCARDINAL: five\n",
      "2\tCARDINAL: more than 1,700\n",
      "2\tCARDINAL: 240,255\n",
      "2\tCARDINAL: two\n",
      "1\tCARDINAL: Ten\n",
      "1\tCARDINAL: half\n",
      "1\tCARDINAL: roughly 50\n",
      "1\tCARDINAL: 3\n",
      "1\tCARDINAL: 6\n",
      "\n",
      "MOST COMMON DATES\n",
      "4\tDATE: Tuesday\n",
      "4\tDATE: May\n",
      "3\tDATE: 2013\n",
      "3\tDATE: Days later\n",
      "2\tDATE: Oct. 1, 2009\n",
      "2\tDATE: fiscal year 2016\n",
      "2\tDATE: Friday\n",
      "1\tDATE: last Friday\n",
      "1\tDATE: 13 years\n",
      "1\tDATE: this past week\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "1\tEVENT: Occupation\n",
      "1\tEVENT: the Declaration of Religious Freedom\n",
      "1\tEVENT: the World Economic Forum\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "1\tFAC: Vatican II\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "22\tGPE: Iran\n",
      "13\tGPE: U.S.\n",
      "10\tGPE: Syria\n",
      "8\tGPE: the United States\n",
      "6\tGPE: Iraq\n",
      "6\tGPE: UK\n",
      "5\tGPE: US\n",
      "4\tGPE: Khashoggi\n",
      "3\tGPE: Madagascar\n",
      "3\tGPE: Switzerland\n",
      "2\tGPE: America\n",
      "2\tGPE: IRGC\n",
      "2\tGPE: Damascus\n",
      "2\tGPE: Kirkuk\n",
      "2\tGPE: North Korea\n",
      "\n",
      "MOST COMMON LAWS\n",
      "1\tLAW: Constitution\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "4\tLOC: Africa\n",
      "4\tLOC: Europe\n",
      "2\tLOC: Western Europe\n",
      "1\tLOC: Straits\n",
      "1\tLOC: the Middle East\n",
      "1\tLOC: Central Europe\n",
      "1\tLOC: Middle East\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "1\tMONEY: billions of dollars\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "5\tNORP: Muslim\n",
      "4\tNORP: Syrian\n",
      "4\tNORP: Islamic\n",
      "4\tNORP: Muslims\n",
      "3\tNORP: Iranian\n",
      "3\tNORP: British\n",
      "3\tNORP: German\n",
      "3\tNORP: African\n",
      "2\tNORP: European\n",
      "2\tNORP: Kurds\n",
      "2\tNORP: Iraqi\n",
      "2\tNORP: Islam\n",
      "2\tNORP: Islamists\n",
      "2\tNORP: Turkish\n",
      "2\tNORP: Saudi\n",
      "2\tNORP: Republicans\n",
      "2\tNORP: Nazis\n",
      "1\tNORP: Zionism\n",
      "1\tNORP: French\n",
      "1\tNORP: Americans\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "3\tORDINAL: first\n",
      "1\tORDINAL: fourth\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "8\tORG: Church\n",
      "5\tORG: Trump\n",
      "4\tORG: ISIS\n",
      "4\tORG: Hezbollah\n",
      "2\tORG: ERO\n",
      "2\tORG: ICE\n",
      "2\tORG: Labour MP\n",
      "2\tORG: the Islamic State\n",
      "2\tORG: al-Qaeda\n",
      "2\tORG: the World Health Organization\n",
      "1\tORG: Holy Matrimony, Confession and Holy Communion\n",
      "1\tORG: the Third Council of Constantinople\n",
      "1\tORG: Assad’s\n",
      "1\tORG: AL\n",
      "1\tORG: the US Administration\n",
      "1\tORG: Congress\n",
      "1\tORG: al-Qaida\n",
      "1\tORG: Reuters\n",
      "1\tORG: Obama’s\n",
      "1\tORG: Secretaries of State\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "2\tPERCENT: Ninety-two percent\n",
      "1\tPERCENT: 45 percent\n",
      "1\tPERCENT: up to 90%\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "7\tPERSON: Trump\n",
      "6\tPERSON: Donald Trump\n",
      "3\tPERSON: Bagheri\n",
      "3\tPERSON: Chris Bryant\n",
      "2\tPERSON: Theresa May\n",
      "2\tPERSON: Benedict\n",
      "2\tPERSON: Clinton\n",
      "2\tPERSON: Freemason\n",
      "2\tPERSON: Kazi\n",
      "2\tPERSON: Rick Scott\n",
      "2\tPERSON: Ron DeSantis\n",
      "1\tPERSON: Madagascar\n",
      "1\tPERSON: Bergoglio\n",
      "1\tPERSON: Leo II\n",
      "1\tPERSON: Honorius\n",
      "1\tPERSON: Pope\n",
      "1\tPERSON: H.R. McMaster\n",
      "1\tPERSON: Fishback\n",
      "1\tPERSON: Emmanuel Macron\n",
      "1\tPERSON: Angela Merkel\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "2\tPRODUCT: Twitter\n",
      "\n",
      "MOST COMMON TIMES\n",
      "1\tTIME: 24-48 hours\n",
      "1\tTIME: the same hour\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "1\tWORK_OF_ART: Honorius\n",
      "1\tWORK_OF_ART: Naiveté\n",
      "1\tWORK_OF_ART: Please Holy Father\n",
      "1\tWORK_OF_ART: The History of Jihad From Muhammad\n",
      "1\tWORK_OF_ART: Speaker Pelosi\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in prejudice_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in prejudice_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in prejudice_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in prejudice_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in prejudice_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\") \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in prejudice_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in prejudice_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in prejudice_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in prejudice_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in prejudice_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in prejudice_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in prejudice_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in prejudice_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in prejudice_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in prejudice_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in prejudice_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2de713b9-1daa-41dd-973c-022fd3434d86",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_prejudice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f5f1cdf-7646-4ca7-92c2-268bb2738efa",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_prejudice['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_prejudice['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_prejudice['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_prejudice['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_prejudice['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_prejudice['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_prejudice['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict_prejudice['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_prejudice['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_prejudice['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_prejudice['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_prejudice['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_prejudice['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_prejudice['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_prejudice['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_prejudice['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a38c7f1-b608-4e87-a8a6-71502f6521ad",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_prejudice)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "410b8b26-38c5-490a-8be0-818643b15b0c",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_prejudice['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_prejudice['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_prejudice['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_prejudice['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_prejudice['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_prejudice['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_prejudice['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict_prejudice['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_prejudice['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_prejudice['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_prejudice['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_prejudice['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_prejudice['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_prejudice['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_prejudice['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_prejudice['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51dca8b-15ed-4747-8eb7-1f402c907be4",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_prejudice_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca66dbb-b515-416e-9f13-84bdab129ae7",
   "metadata": {},
   "source": [
    "### Exaggeration-Minimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d69941-d43a-4c31-aaad-6ced453c63b5",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Exaggeration-Minimisation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "65e09a12-acf9-40bd-9306-6330bd6e20f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LAW', 'LOC', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  16\n",
      "Total number of entities:  429\n",
      "Total number of unique entities:  299\n",
      "Percentage of unique entities:  69.6969696969697\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_ex_min = {key: list(g) for key, g in groupby(sorted(total_ex_min_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_ex_min.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_ex_min))\n",
    "\n",
    "total_entities_value_list_ex_min = list()\n",
    "for i in total_entities_dict_ex_min.values():\n",
    "    total_entities_value_list_ex_min.append(i)\n",
    "    \n",
    "total_entities_ex_min= len(sum(total_entities_value_list_ex_min, []))\n",
    "print(\"Total number of entities: \", total_entities_ex_min)\n",
    "\n",
    "unique_entities_dict_ex_min = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_ex_min_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_ex_min = list()\n",
    "for i in unique_entities_dict_ex_min.values():\n",
    "    unique_entities_value_list_ex_min.append(i)\n",
    "    \n",
    "unique_entities_ex_min= len(sum(unique_entities_value_list_ex_min, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_ex_min)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_ex_min/total_entities_ex_min)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c855f32c-f61a-4c3b-8fd1-87c8c21eb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_ex_min = len(total_entities_dict_ex_min['CARDINAL'])\n",
    "total_date_ex_min = len(total_entities_dict_ex_min['DATE'])\n",
    "total_event_ex_min = len(total_entities_dict_ex_min['EVENT'])\n",
    "total_fac_ex_min = len(total_entities_dict_ex_min['FAC'])\n",
    "total_gpe_ex_min = len(total_entities_dict_ex_min['GPE'])\n",
    "total_law_ex_min = len(total_entities_dict_ex_min['LAW'])\n",
    "total_loc_ex_min = len(total_entities_dict_ex_min['LOC'])\n",
    "total_norp_ex_min = len(total_entities_dict_ex_min['NORP'])\n",
    "total_ordinal_ex_min = len(total_entities_dict_ex_min['ORDINAL'])\n",
    "total_org_ex_min = len(total_entities_dict_ex_min['ORG'])\n",
    "total_percent_ex_min = len(total_entities_dict_ex_min['PERCENT'])\n",
    "total_person_ex_min = len(total_entities_dict_ex_min['PERSON'])\n",
    "total_product_ex_min = len(total_entities_dict_ex_min['PRODUCT'])\n",
    "total_quantity_ex_min = len(total_entities_dict_ex_min['QUANTITY'])\n",
    "total_time_ex_min = len(total_entities_dict_ex_min['TIME'])\n",
    "total_woa_ex_min = len(total_entities_dict_ex_min['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "85a0b188-b2d7-4a8a-91b5-25ef99efc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_ex_min = len(unique_entities_dict_ex_min['CARDINAL'])\n",
    "unique_date_ex_min = len(unique_entities_dict_ex_min['DATE'])\n",
    "unique_event_ex_min = len(unique_entities_dict_ex_min['EVENT'])\n",
    "unique_fac_ex_min = len(unique_entities_dict_ex_min['FAC'])\n",
    "unique_gpe_ex_min = len(unique_entities_dict_ex_min['GPE'])\n",
    "unique_law_ex_min = len(unique_entities_dict_ex_min['LAW'])\n",
    "unique_loc_ex_min = len(unique_entities_dict_ex_min['LOC'])\n",
    "unique_norp_ex_min = len(unique_entities_dict_ex_min['NORP'])\n",
    "unique_ordinal_ex_min = len(unique_entities_dict_ex_min['ORDINAL'])\n",
    "unique_org_ex_min = len(unique_entities_dict_ex_min['ORG'])\n",
    "unique_percent_ex_min = len(unique_entities_dict_ex_min['PERCENT'])\n",
    "unique_person_ex_min = len(unique_entities_dict_ex_min['PERSON'])\n",
    "unique_product_ex_min = len(unique_entities_dict_ex_min['PRODUCT'])\n",
    "unique_quantity_ex_min = len(unique_entities_dict_ex_min['QUANTITY'])\n",
    "unique_time_ex_min = len(unique_entities_dict_ex_min['TIME'])\n",
    "unique_woa_ex_min = len(unique_entities_dict_ex_min['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7488ca10-87d0-41a6-9c4b-155c9acc20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  22\n",
      "Percentage of extracted cardinal numbers:  5.128205128205128\n",
      "Total of unique cardinal numbers:  13\n",
      "Percentage of unique cardinal numbers:  59.09090909090909\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  50\n",
      "Percentage of extracted dates:  11.655011655011654\n",
      "Total of unique dates:  43\n",
      "Percentage of unique dates:  86.0\n",
      "\n",
      "EVENT\n",
      "Total of extracted events:  4\n",
      "Percentage of extracted events:  0.9324009324009324\n",
      "Total of unique events:  4\n",
      "Percentage of unique events:  100.0\n",
      "\n",
      "FAC\n",
      "Total of extracted facilities:  3\n",
      "Percentage of extracted facilities:  0.6993006993006993\n",
      "Total of unique facilities:  3\n",
      "Percentage of unique facilities:  100.0\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  83\n",
      "Percentage of extracted countries or cities:  19.34731934731935\n",
      "Total of unique countries or cities:  45\n",
      "Percentage of unique countries or cities:  54.21686746987952\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  2\n",
      "Percentage of extracted laws:  0.4662004662004662\n",
      "Total of unique laws:  2\n",
      "Percentage of unique laws:  100.0\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  10\n",
      "Percentage of extracted generic locations:  2.331002331002331\n",
      "Total of unique generic locations:  7\n",
      "Percentage of unique generic locations:  70.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  47\n",
      "Percentage of extracted nationalities, religious or political groups:  10.955710955710956\n",
      "Total of unique nationalities, religious or political groups:  33\n",
      "Percentage of unique nationalities, religious or political groups:  70.2127659574468\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  6\n",
      "Percentage extracted ordinal numbers:  10.256410256410255\n",
      "Total of unique ordinal numbers:  3\n",
      "Percentage of unique ordinal numbers:  50.0\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  100\n",
      "Percentage extracted companies or organizations:  23.310023310023308\n",
      "Total of unique companies or organizations:  69\n",
      "Percentage of unique companies or organizations:  69.0\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  5\n",
      "Percentage extracted percentages:  1.1655011655011656\n",
      "Total of unique percentages:  3\n",
      "Percentage of unique percentages:  60.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  85\n",
      "Percentage extracted people:  19.813519813519815\n",
      "Total of unique people:  62\n",
      "Percentage of unique people:  72.94117647058823\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  3\n",
      "Percentage extracted products:  0.6993006993006993\n",
      "Total of unique products:  3\n",
      "Percentage of unique products:  100.0\n",
      "\n",
      "QUANTITY\n",
      "Total of extracted measurements:  1\n",
      "Percentage extracted measurements:  0.2331002331002331\n",
      "Total of unique measurements:  1\n",
      "Percentage of unique measurements:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  4\n",
      "Percentage of extracted times:  0.9324009324009324\n",
      "Total of unique times:  4\n",
      "Percentage of unique times:  100.0\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  4\n",
      "Percentage of extracted works of art:  0.9324009324009324\n",
      "Total of unique works of art:  4\n",
      "Percentage of unique works of art:  100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_ex_min)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_ex_min)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_ex_min/total_cardinal_ex_min)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_ex_min)\n",
    "print(\"Percentage of extracted dates: \", (total_date_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique dates: \", unique_date_ex_min)\n",
    "print(\"Percentage of unique dates: \", (unique_date_ex_min/total_date_ex_min)*100)\n",
    "print(\"\\nEVENT\")\n",
    "print(\"Total of extracted events: \", total_event_ex_min)\n",
    "print(\"Percentage of extracted events: \", (total_event_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique events: \", unique_event_ex_min)\n",
    "print(\"Percentage of unique events: \", (unique_event_ex_min/total_event_ex_min)*100)\n",
    "print(\"\\nFAC\")\n",
    "print(\"Total of extracted facilities: \", total_fac_ex_min)\n",
    "print(\"Percentage of extracted facilities: \", (total_fac_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique facilities: \", unique_fac_ex_min)\n",
    "print(\"Percentage of unique facilities: \", (unique_fac_ex_min/total_fac_ex_min)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_ex_min)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_ex_min)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_ex_min/total_gpe_ex_min)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_ex_min)\n",
    "print(\"Percentage of extracted laws: \", (total_law_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique laws: \", unique_law_ex_min)\n",
    "print(\"Percentage of unique laws: \", (unique_law_ex_min/total_law_ex_min)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_ex_min)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_ex_min)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_ex_min/total_loc_ex_min)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_ex_min)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_ex_min)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_ex_min/total_norp_ex_min)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_ex_min)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_loaded/total_entities_ex_min)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_ex_min)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_ex_min/total_ordinal_ex_min)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_ex_min)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_ex_min)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_ex_min/total_org_ex_min)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_ex_min)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_ex_min)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_ex_min/total_percent_ex_min)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_ex_min)\n",
    "print(\"Percentage extracted people: \", (total_person_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique people: \", unique_person_ex_min)\n",
    "print(\"Percentage of unique people: \", (unique_person_ex_min/total_person_ex_min)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_ex_min)\n",
    "print(\"Percentage extracted products: \", (total_product_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique products: \", unique_product_ex_min)\n",
    "print(\"Percentage of unique products: \", (unique_product_ex_min/total_product_ex_min)*100)\n",
    "print(\"\\nQUANTITY\")\n",
    "print(\"Total of extracted measurements: \", total_quantity_ex_min)\n",
    "print(\"Percentage extracted measurements: \", (total_quantity_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique measurements: \", unique_quantity_ex_min)\n",
    "print(\"Percentage of unique measurements: \", (unique_quantity_ex_min/total_quantity_ex_min)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_ex_min)\n",
    "print(\"Percentage of extracted times: \", (total_time_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique times: \", unique_time_ex_min)\n",
    "print(\"Percentage of unique times: \", (unique_time_ex_min/total_time_ex_min)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_ex_min)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_ex_min/total_entities_ex_min)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_ex_min)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_ex_min/total_woa_ex_min)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "99a0eabf-e840-4f83-b31c-94de7b2fe9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "15\tGPE: U.S.\n",
      "9\tCARDINAL: one\n",
      "7\tORG: Guardian\n",
      "7\tPERSON: Trump\n",
      "7\tGPE: Iran\n",
      "6\tORG: Trump\n",
      "6\tORG: Assange\n",
      "6\tPERSON: Patel\n",
      "5\tGPE: the United States\n",
      "5\tNORP: American\n",
      "4\tORDINAL: first\n",
      "4\tGPE: US\n",
      "4\tORG: CIA\n",
      "3\tGPE: Vietnam\n",
      "3\tORG: Congress\n",
      "3\tPERSON: Awan\n",
      "3\tGPE: Spain\n",
      "3\tPERSON: Obama\n",
      "3\tORG: Julian Assange\n",
      "3\tLOC: the Gulf of Tonkin\n",
      "3\tGPE: Russia\n",
      "3\tPERCENT: 100%\n",
      "3\tORG: Patel\n",
      "2\tORG: Manafort\n",
      "2\tORG: The Daily Caller\n",
      "2\tPERSON: Farrakhan\n",
      "2\tGPE: Obama\n",
      "2\tPERSON: Oswald\n",
      "2\tNORP: Marines\n",
      "2\tCARDINAL: millions\n"
     ]
    }
   ],
   "source": [
    "ex_min_ents_count = Counter()\n",
    "\n",
    "for ent in total_ex_min_text.ents:\n",
    "    ex_min_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in ex_min_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "74380184-db31-4673-93b8-848d19181095",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_min_cardinal_count = Counter()\n",
    "ex_min_date_count = Counter()\n",
    "ex_min_event_count = Counter()\n",
    "ex_min_fac_count = Counter()\n",
    "ex_min_gpe_count = Counter()\n",
    "ex_min_law_count = Counter()\n",
    "ex_min_loc_count = Counter()\n",
    "ex_min_norp_count = Counter()\n",
    "ex_min_ordinal_count = Counter()\n",
    "ex_min_org_count = Counter()\n",
    "ex_min_percent_count = Counter()\n",
    "ex_min_person_count = Counter()\n",
    "ex_min_product_count = Counter()\n",
    "ex_min_quantity_count = Counter()\n",
    "ex_min_time_count = Counter()\n",
    "ex_min_woa_count = Counter()\n",
    "\n",
    "for ent in total_ex_min_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        ex_min_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        ex_min_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"EVENT\"):\n",
    "        ex_min_event_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"FAC\"):\n",
    "        ex_min_fac_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        ex_min_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        ex_min_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        ex_min_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        ex_min_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        ex_min_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        ex_min_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        ex_min_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        ex_min_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        ex_min_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"QUANTITY\"):\n",
    "        ex_min_quantity_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        ex_min_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        ex_min_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4e4ca78b-ef14-4f74-b004-859e598025e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "9\tCARDINAL: one\n",
      "2\tCARDINAL: millions\n",
      "1\tCARDINAL: 2006.Needless\n",
      "1\tCARDINAL: five\n",
      "1\tCARDINAL: seven\n",
      "1\tCARDINAL: two\n",
      "1\tCARDINAL: two-million-plus\n",
      "1\tCARDINAL: three\n",
      "1\tCARDINAL: 3\n",
      "1\tCARDINAL: tens of thousands\n",
      "\n",
      "MOST COMMON DATES\n",
      "2\tDATE: Friday\n",
      "2\tDATE: Wednesday\n",
      "2\tDATE: July 2015\n",
      "2\tDATE: 2010\n",
      "2\tDATE: 2015\n",
      "2\tDATE: Saturday\n",
      "2\tDATE: 69\n",
      "1\tDATE: days\n",
      "1\tDATE: weeks\n",
      "1\tDATE: 50-year-old\n",
      "\n",
      "MOST COMMON EVENTS\n",
      "1\tEVENT: the Korean War\n",
      "1\tEVENT: New Year's\n",
      "1\tEVENT: the Kuiper Belt\n",
      "1\tEVENT: the Cold War\n",
      "\n",
      "MOST COMMON FACILITIES\n",
      "1\tFAC: Tower Hamlets\n",
      "1\tFAC: Vatican II\n",
      "1\tFAC: Epstein\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "15\tGPE: U.S.\n",
      "7\tGPE: Iran\n",
      "5\tGPE: the United States\n",
      "4\tGPE: US\n",
      "3\tGPE: Vietnam\n",
      "3\tGPE: Spain\n",
      "3\tGPE: Russia\n",
      "2\tGPE: Obama\n",
      "2\tGPE: Arizona\n",
      "2\tGPE: Brazil\n",
      "2\tGPE: Germany\n",
      "2\tGPE: New York City\n",
      "1\tGPE: Florida\n",
      "1\tGPE: Kirkuk\n",
      "1\tGPE: Korea\n",
      "\n",
      "MOST COMMON LAWS\n",
      "1\tLAW: First Amendment\n",
      "1\tLAW: the First Amendment\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "3\tLOC: the Gulf of Tonkin\n",
      "2\tLOC: Europe\n",
      "1\tLOC: Barros\n",
      "1\tLOC: Earth\n",
      "1\tLOC: Latin America\n",
      "1\tLOC: Pelosi\n",
      "1\tLOC: the South China Sea\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "5\tNORP: American\n",
      "2\tNORP: Marines\n",
      "2\tNORP: Muslims\n",
      "2\tNORP: Awans\n",
      "2\tNORP: Catholic\n",
      "2\tNORP: Muslim\n",
      "2\tNORP: Pakistani\n",
      "2\tNORP: Ukrainians\n",
      "2\tNORP: Russian\n",
      "2\tNORP: Christians\n",
      "2\tNORP: Ecuadorian\n",
      "1\tNORP: Republican\n",
      "1\tNORP: Iraqi\n",
      "1\tNORP: Kurds\n",
      "1\tNORP: Jews\n",
      "1\tNORP: Dems\n",
      "1\tNORP: Patristic\n",
      "1\tNORP: anti-Catholic\n",
      "1\tNORP: Franciscans\n",
      "1\tNORP: Teresian\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "4\tORDINAL: first\n",
      "1\tORDINAL: second\n",
      "1\tORDINAL: Second\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "7\tORG: Guardian\n",
      "6\tORG: Trump\n",
      "6\tORG: Assange\n",
      "4\tORG: CIA\n",
      "3\tORG: Congress\n",
      "3\tORG: Julian Assange\n",
      "3\tORG: Patel\n",
      "2\tORG: Manafort\n",
      "2\tORG: The Daily Caller\n",
      "2\tORG: McGill University\n",
      "2\tORG: FBI\n",
      "2\tORG: Wilson\n",
      "2\tORG: AAA\n",
      "1\tORG: Kavanaugh\n",
      "1\tORG: the Justice Department\n",
      "1\tORG: Guatemalan\n",
      "1\tORG: the Distinguished Intelligence Medal\n",
      "1\tORG: USO\n",
      "1\tORG: Franken\n",
      "1\tORG: Kate SteinleSan Francisco\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "3\tPERCENT: 100%\n",
      "1\tPERCENT: 3.24%\n",
      "1\tPERCENT: 0.63%\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "7\tPERSON: Trump\n",
      "6\tPERSON: Patel\n",
      "3\tPERSON: Awan\n",
      "3\tPERSON: Obama\n",
      "2\tPERSON: Farrakhan\n",
      "2\tPERSON: Oswald\n",
      "2\tPERSON: Hitler\n",
      "2\tPERSON: Bush\n",
      "2\tPERSON: Donald J. Trump\n",
      "2\tPERSON: Will Brett\n",
      "2\tPERSON: Putin\n",
      "2\tPERSON: Donald Trump\n",
      "1\tPERSON: Davis\n",
      "1\tPERSON: Arbenz\n",
      "1\tPERSON: Tracy Barnes\n",
      "1\tPERSON: JFK\n",
      "1\tPERSON: LeeAnn Tweeden\n",
      "1\tPERSON: Al Franken\n",
      "1\tPERSON: Garcia Zarate\n",
      "1\tPERSON: Steinle\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "1\tPRODUCT: Twitter\n",
      "1\tPRODUCT: Pluto\n",
      "1\tPRODUCT: MS-13\n",
      "\n",
      "MOST COMMON QUANTITIES\n",
      "1\tQUANTITY: one billion miles\n",
      "\n",
      "MOST COMMON TIMES\n",
      "1\tTIME: desperate hour\n",
      "1\tTIME: an hour\n",
      "1\tTIME: less than a minute\n",
      "1\tTIME: night\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "1\tWORK_OF_ART: The Jewish Question\n",
      "1\tWORK_OF_ART: Media Leak Strategy\n",
      "1\tWORK_OF_ART: an Emmy Award\n",
      "1\tWORK_OF_ART: Late Night with Seth Meyers\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in ex_min_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in ex_min_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON EVENTS\")        \n",
    "for key, val in ex_min_event_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON FACILITIES\")        \n",
    "for key, val in ex_min_fac_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in ex_min_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\")    \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in ex_min_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in ex_min_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in ex_min_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in ex_min_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in ex_min_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in ex_min_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in ex_min_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in ex_min_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON QUANTITIES\")        \n",
    "for key, val in ex_min_quantity_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in ex_min_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in ex_min_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc50e38e-62c1-4424-9004-50b5d90d2d30",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_ex_min)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee19cc9b-3a20-4dd3-a37e-d4e4a0de2338",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_ex_min['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_ex_min['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(total_entities_dict_ex_min['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(total_entities_dict_ex_min['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_ex_min['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_ex_min['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_ex_min['LOC'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_ex_min['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_ex_min['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_ex_min['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_ex_min['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_ex_min['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_ex_min['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(total_entities_dict_ex_min['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_ex_min['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_ex_min['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1424aba-0c6b-460f-b8e4-a3c2462ae748",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_ex_min)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ac7cc58-5aa5-4ba5-a06c-aaa21273acdf",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_ex_min['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_ex_min['DATE'])\n",
    "print(\"\\nEVENT\")\n",
    "print(unique_entities_dict_ex_min['EVENT'])\n",
    "print(\"\\nFAC\")\n",
    "print(unique_entities_dict_ex_min['FAC'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_ex_min['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_ex_min['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_ex_min['LOC'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_ex_min['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_ex_min['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_ex_min['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_ex_min['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_ex_min['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_ex_min['PRODUCT'])\n",
    "print(\"\\nQUANTITY\")\n",
    "print(unique_entities_dict_ex_min['QUANTITY'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_ex_min['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_ex_min['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4b8e467-168e-499b-afba-56bfc6643afd",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_ex_min_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169e15c-18b9-4b26-b13c-c5b84f2ac51f",
   "metadata": {},
   "source": [
    "### Flag_Waving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c1952-a666-4e76-b2e2-8522d41d90f1",
   "metadata": {},
   "source": [
    "This first section will focus on the extraction of the information described above focusing on the Flag_Waving class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a162b2c5-e184-4ab7-8e94-39cc6a2a59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL ENTITIES\n",
      "All categories extracted:  dict_keys(['CARDINAL', 'DATE', 'GPE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'TIME', 'WORK_OF_ART'])\n",
      "Number of categories extracted:  14\n",
      "Total number of entities:  529\n",
      "Total number of unique entities:  300\n",
      "Percentage of unique entities:  56.71077504725898\n"
     ]
    }
   ],
   "source": [
    "total_entities_dict_waving = {key: list(g) for key, g in groupby(sorted(total_waving_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "print(\"ALL ENTITIES\")\n",
    "print(\"All categories extracted: \", total_entities_dict_waving.keys())\n",
    "print(\"Number of categories extracted: \", len(total_entities_dict_waving))\n",
    "\n",
    "total_entities_value_list_waving = list()\n",
    "for i in total_entities_dict_waving.values():\n",
    "    total_entities_value_list_waving.append(i)\n",
    "    \n",
    "total_entities_waving= len(sum(total_entities_value_list_waving, []))\n",
    "print(\"Total number of entities: \", total_entities_waving)\n",
    "\n",
    "unique_entities_dict_waving = {key: list(set(map(lambda x: str(x), g))) for key, g in groupby(sorted(total_waving_text.ents, key=lambda x: x.label_), lambda x: x.label_)}\n",
    "\n",
    "unique_entities_value_list_waving = list()\n",
    "for i in unique_entities_dict_waving.values():\n",
    "    unique_entities_value_list_waving.append(i)\n",
    "    \n",
    "unique_entities_waving= len(sum(unique_entities_value_list_waving, []))\n",
    "print(\"Total number of unique entities: \", unique_entities_waving)\n",
    "print(\"Percentage of unique entities: \", (unique_entities_waving/total_entities_waving)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "de6cce9e-3f7d-4f9d-8d95-154e91f6a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the total occurrences for each label\n",
    "total_cardinal_waving = len(total_entities_dict_waving['CARDINAL'])\n",
    "total_date_waving = len(total_entities_dict_waving['DATE'])\n",
    "total_gpe_waving = len(total_entities_dict_waving['GPE'])\n",
    "total_law_waving = len(total_entities_dict_waving['LAW'])\n",
    "total_loc_waving = len(total_entities_dict_waving['LOC'])\n",
    "total_money_waving = len(total_entities_dict_waving['MONEY'])\n",
    "total_norp_waving = len(total_entities_dict_waving['NORP'])\n",
    "total_ordinal_waving = len(total_entities_dict_waving['ORDINAL'])\n",
    "total_org_waving = len(total_entities_dict_waving['ORG'])\n",
    "total_percent_waving = len(total_entities_dict_waving['PERCENT'])\n",
    "total_person_waving = len(total_entities_dict_waving['PERSON'])\n",
    "total_product_waving = len(total_entities_dict_waving['PRODUCT'])\n",
    "total_time_waving = len(total_entities_dict_waving['TIME'])\n",
    "total_woa_waving = len(total_entities_dict_waving['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bb0068e1-60e3-40de-9657-5e26be382747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the unique occurrences for each label\n",
    "unique_cardinal_waving = len(unique_entities_dict_waving['CARDINAL'])\n",
    "unique_date_waving = len(unique_entities_dict_waving['DATE'])\n",
    "unique_gpe_waving = len(unique_entities_dict_waving['GPE'])\n",
    "unique_law_waving = len(unique_entities_dict_waving['LAW'])\n",
    "unique_loc_waving = len(unique_entities_dict_waving['LOC'])\n",
    "unique_money_waving = len(unique_entities_dict_waving['MONEY'])\n",
    "unique_norp_waving = len(unique_entities_dict_waving['NORP'])\n",
    "unique_ordinal_waving = len(unique_entities_dict_waving['ORDINAL'])\n",
    "unique_org_waving = len(unique_entities_dict_waving['ORG'])\n",
    "unique_percent_waving = len(unique_entities_dict_waving['PERCENT'])\n",
    "unique_person_waving = len(unique_entities_dict_waving['PERSON'])\n",
    "unique_product_waving = len(unique_entities_dict_waving['PRODUCT'])\n",
    "unique_time_waving = len(unique_entities_dict_waving['TIME'])\n",
    "unique_woa_waving = len(unique_entities_dict_waving['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bc6ee68a-4ebc-466c-8a5c-f04d0d5ebc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARDINAL\n",
      "Total of extracted cardinal numbers:  23\n",
      "Percentage of extracted cardinal numbers:  4.3478260869565215\n",
      "Total of unique cardinal numbers:  15\n",
      "Percentage of unique cardinal numbers:  65.21739130434783\n",
      "\n",
      "DATE\n",
      "Total of extracted dates:  58\n",
      "Percentage of extracted dates:  10.964083175803403\n",
      "Total of unique dates:  47\n",
      "Percentage of unique dates:  81.03448275862068\n",
      "\n",
      "GPE\n",
      "Total of extracted countries or cities:  105\n",
      "Percentage of extracted countries or cities:  19.848771266540645\n",
      "Total of unique countries or cities:  51\n",
      "Percentage of unique countries or cities:  48.57142857142857\n",
      "\n",
      "LAW\n",
      "Total of extracted laws:  6\n",
      "Percentage of extracted laws:  1.1342155009451798\n",
      "Total of unique laws:  4\n",
      "Percentage of unique laws:  66.66666666666666\n",
      "\n",
      "LOC\n",
      "Total of extracted generic locations:  18\n",
      "Percentage of extracted generic locations:  3.402646502835539\n",
      "Total of unique generic locations:  8\n",
      "Percentage of unique generic locations:  44.44444444444444\n",
      "\n",
      "MONEY\n",
      "Total of extracted money values:  4\n",
      "Percentage of extracted money values:  0.7561436672967864\n",
      "Total of unique money values:  4\n",
      "Percentage of unique money values:  100.0\n",
      "\n",
      "NORP\n",
      "Total of extracted nationalities, religious or political groups:  101\n",
      "Percentage of extracted nationalities, religious or political groups:  19.092627599243855\n",
      "Total of unique nationalities, religious or political groups:  27\n",
      "Percentage of unique nationalities, religious or political groups:  26.732673267326735\n",
      "\n",
      "ORDINAL\n",
      "Total of extracted ordinal numbers:  5\n",
      "Percentage extracted ordinal numbers:  8.31758034026465\n",
      "Total of unique ordinal numbers:  2\n",
      "Percentage of unique ordinal numbers:  40.0\n",
      "\n",
      "ORG\n",
      "Total of extracted companies or organizations:  105\n",
      "Percentage extracted companies or organizations:  19.848771266540645\n",
      "Total of unique companies or organizations:  68\n",
      "Percentage of unique companies or organizations:  64.76190476190476\n",
      "\n",
      "PERCENT\n",
      "Total of extracted percentages:  2\n",
      "Percentage extracted percentages:  0.3780718336483932\n",
      "Total of unique percentages:  2\n",
      "Percentage of unique percentages:  100.0\n",
      "\n",
      "PERSON\n",
      "Total of extracted people:  91\n",
      "Percentage extracted people:  17.20226843100189\n",
      "Total of unique people:  61\n",
      "Percentage of unique people:  67.03296703296702\n",
      "\n",
      "PRODUCT\n",
      "Total of extracted products:  1\n",
      "Percentage extracted products:  0.1890359168241966\n",
      "Total of unique products:  1\n",
      "Percentage of unique products:  100.0\n",
      "\n",
      "TIME\n",
      "Total of extracted times:  7\n",
      "Percentage of extracted times:  1.3232514177693762\n",
      "Total of unique times:  7\n",
      "Percentage of unique times:  100.0\n",
      "\n",
      "WORK OF ART\n",
      "Total of extracted works of art:  3\n",
      "Percentage of extracted works of art:  0.5671077504725899\n",
      "Total of unique works of art:  3\n",
      "Percentage of unique works of art:  100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"CARDINAL\")\n",
    "print(\"Total of extracted cardinal numbers: \", total_cardinal_waving)\n",
    "print(\"Percentage of extracted cardinal numbers: \", (total_cardinal_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique cardinal numbers: \", unique_cardinal_waving)\n",
    "print(\"Percentage of unique cardinal numbers: \", (unique_cardinal_waving/total_cardinal_waving)*100)\n",
    "print(\"\\nDATE\")\n",
    "print(\"Total of extracted dates: \", total_date_waving)\n",
    "print(\"Percentage of extracted dates: \", (total_date_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique dates: \", unique_date_waving)\n",
    "print(\"Percentage of unique dates: \", (unique_date_waving/total_date_waving)*100)\n",
    "print(\"\\nGPE\")\n",
    "print(\"Total of extracted countries or cities: \", total_gpe_waving)\n",
    "print(\"Percentage of extracted countries or cities: \", (total_gpe_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique countries or cities: \", unique_gpe_waving)\n",
    "print(\"Percentage of unique countries or cities: \", (unique_gpe_waving/total_gpe_waving)*100)\n",
    "print(\"\\nLAW\")\n",
    "print(\"Total of extracted laws: \", total_law_waving)\n",
    "print(\"Percentage of extracted laws: \", (total_law_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique laws: \", unique_law_waving)\n",
    "print(\"Percentage of unique laws: \", (unique_law_waving/total_law_waving)*100)\n",
    "print(\"\\nLOC\")\n",
    "print(\"Total of extracted generic locations: \", total_loc_waving)\n",
    "print(\"Percentage of extracted generic locations: \", (total_loc_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique generic locations: \", unique_loc_waving)\n",
    "print(\"Percentage of unique generic locations: \", (unique_loc_waving/total_loc_waving)*100)\n",
    "print(\"\\nMONEY\")\n",
    "print(\"Total of extracted money values: \", total_money_waving)\n",
    "print(\"Percentage of extracted money values: \", (total_money_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique money values: \", unique_money_waving)\n",
    "print(\"Percentage of unique money values: \", (unique_money_waving/total_money_waving)*100)\n",
    "print(\"\\nNORP\")\n",
    "print(\"Total of extracted nationalities, religious or political groups: \", total_norp_waving)\n",
    "print(\"Percentage of extracted nationalities, religious or political groups: \", (total_norp_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique nationalities, religious or political groups: \", unique_norp_waving)\n",
    "print(\"Percentage of unique nationalities, religious or political groups: \", (unique_norp_waving/total_norp_waving)*100)\n",
    "print(\"\\nORDINAL\")\n",
    "print(\"Total of extracted ordinal numbers: \", total_ordinal_waving)\n",
    "print(\"Percentage extracted ordinal numbers: \", (total_ordinal_loaded/total_entities_waving)*100)\n",
    "print(\"Total of unique ordinal numbers: \", unique_ordinal_waving)\n",
    "print(\"Percentage of unique ordinal numbers: \", (unique_ordinal_waving/total_ordinal_waving)*100)\n",
    "print(\"\\nORG\")\n",
    "print(\"Total of extracted companies or organizations: \", total_org_waving)\n",
    "print(\"Percentage extracted companies or organizations: \", (total_org_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique companies or organizations: \", unique_org_waving)\n",
    "print(\"Percentage of unique companies or organizations: \", (unique_org_waving/total_org_waving)*100)\n",
    "print(\"\\nPERCENT\")\n",
    "print(\"Total of extracted percentages: \", total_percent_waving)\n",
    "print(\"Percentage extracted percentages: \", (total_percent_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique percentages: \", unique_percent_waving)\n",
    "print(\"Percentage of unique percentages: \", (unique_percent_waving/total_percent_waving)*100)\n",
    "print(\"\\nPERSON\")\n",
    "print(\"Total of extracted people: \", total_person_waving)\n",
    "print(\"Percentage extracted people: \", (total_person_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique people: \", unique_person_waving)\n",
    "print(\"Percentage of unique people: \", (unique_person_waving/total_person_waving)*100)\n",
    "print(\"\\nPRODUCT\")\n",
    "print(\"Total of extracted products: \", total_product_waving)\n",
    "print(\"Percentage extracted products: \", (total_product_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique products: \", unique_product_waving)\n",
    "print(\"Percentage of unique products: \", (unique_product_waving/total_product_waving)*100)\n",
    "print(\"\\nTIME\")\n",
    "print(\"Total of extracted times: \", total_time_waving)\n",
    "print(\"Percentage of extracted times: \", (total_time_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique times: \", unique_time_waving)\n",
    "print(\"Percentage of unique times: \", (unique_time_waving/total_time_waving)*100)\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(\"Total of extracted works of art: \", total_woa_waving)\n",
    "print(\"Percentage of extracted works of art: \", (total_woa_waving/total_entities_waving)*100)\n",
    "print(\"Total of unique works of art: \", unique_woa_waving)\n",
    "print(\"Percentage of unique works of art: \", (unique_woa_waving/total_woa_waving)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2ef81954-ff5f-45f6-9b3e-0348d1a24a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON ENTITIES\n",
      "42\tNORP: American\n",
      "13\tGPE: Iran\n",
      "10\tGPE: America\n",
      "9\tORG: CIA\n",
      "9\tNORP: Americans\n",
      "8\tLOC: Europe\n",
      "7\tORG: Congress\n",
      "7\tCARDINAL: two\n",
      "7\tPERSON: Habib Powell\n",
      "6\tGPE: US\n",
      "5\tORG: Hezbollah\n",
      "5\tGPE: Syria\n",
      "5\tPERSON: Trump\n",
      "5\tGPE: U.S.\n",
      "5\tNORP: Christian\n",
      "5\tNORP: Democrats\n",
      "4\tGPE: the United States\n",
      "4\tORG: Trump\n",
      "4\tNORP: Islamic\n",
      "4\tNORP: Russian\n",
      "4\tDATE: Sunday\n",
      "4\tORDINAL: first\n",
      "4\tORG: Orban\n",
      "4\tDATE: today\n",
      "4\tGPE: Russia\n",
      "4\tPERSON: Barr\n",
      "4\tORG: CNN\n",
      "3\tGPE: Lebanon\n",
      "3\tDATE: 1953\n",
      "3\tNORP: Muslim\n"
     ]
    }
   ],
   "source": [
    "waving_ents_count = Counter()\n",
    "\n",
    "for ent in total_waving_text.ents:\n",
    "    waving_ents_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "\n",
    "print(\"MOST COMMON ENTITIES\")\n",
    "for key, val in waving_ents_count.most_common(30):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ef52f3cd-0c2d-4589-a3bf-6a091ddba90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "waving_cardinal_count = Counter()\n",
    "waving_date_count = Counter()\n",
    "waving_gpe_count = Counter()\n",
    "waving_law_count = Counter()\n",
    "waving_loc_count = Counter()\n",
    "waving_money_count = Counter()\n",
    "waving_norp_count = Counter()\n",
    "waving_ordinal_count = Counter()\n",
    "waving_org_count = Counter()\n",
    "waving_percent_count = Counter()\n",
    "waving_person_count = Counter()\n",
    "waving_product_count = Counter()\n",
    "waving_time_count = Counter()\n",
    "waving_woa_count = Counter()\n",
    "\n",
    "for ent in total_waving_text.ents:\n",
    "    if (ent.label_ == \"CARDINAL\"):\n",
    "        waving_cardinal_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"DATE\"):\n",
    "        waving_date_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"GPE\"):\n",
    "        waving_gpe_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LAW\"):\n",
    "        waving_law_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"LOC\"):\n",
    "        waving_loc_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"MONEY\"):\n",
    "        waving_money_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"NORP\"):\n",
    "        waving_norp_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORDINAL\"):\n",
    "        waving_ordinal_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"ORG\"):\n",
    "        waving_org_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PERCENT\"):\n",
    "        waving_percent_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"PERSON\"):\n",
    "        waving_person_count[f\"{ent.label_}: {ent.text}\"] += 1\n",
    "    if (ent.label_ == \"PRODUCT\"):\n",
    "        waving_product_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"TIME\"):\n",
    "        waving_time_count[f\"{ent.label_}: {ent.text}\"] += 1 \n",
    "    if (ent.label_ == \"WORK_OF_ART\"):\n",
    "        waving_woa_count[f\"{ent.label_}: {ent.text}\"] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ea212632-21d0-4c36-850a-56df9c1099db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST COMMON CARDINALS\n",
      "7\tCARDINAL: two\n",
      "2\tCARDINAL: One\n",
      "2\tCARDINAL: three\n",
      "1\tCARDINAL: only one\n",
      "1\tCARDINAL: 5x\n",
      "1\tCARDINAL: 2017For\n",
      "1\tCARDINAL: well as thousands\n",
      "1\tCARDINAL: Two-thirds\n",
      "1\tCARDINAL: 0.7\n",
      "1\tCARDINAL: 0.1\n",
      "\n",
      "MOST COMMON DATES\n",
      "4\tDATE: Sunday\n",
      "4\tDATE: today\n",
      "3\tDATE: 1953\n",
      "2\tDATE: February 11, 2018\n",
      "2\tDATE: 2015\n",
      "2\tDATE: the coming days\n",
      "1\tDATE: so many years\n",
      "1\tDATE: more than 50 years\n",
      "1\tDATE: November 1963\n",
      "1\tDATE: 1954\n",
      "\n",
      "MOST COMMON COUNTRIES OR CITIES\n",
      "13\tGPE: Iran\n",
      "10\tGPE: America\n",
      "6\tGPE: US\n",
      "5\tGPE: Syria\n",
      "5\tGPE: U.S.\n",
      "4\tGPE: the United States\n",
      "4\tGPE: Russia\n",
      "3\tGPE: Lebanon\n",
      "3\tGPE: Israel\n",
      "3\tGPE: Florida\n",
      "3\tGPE: Broward County\n",
      "2\tGPE: UK\n",
      "2\tGPE: Brussels\n",
      "2\tGPE: Hungary\n",
      "2\tGPE: West Virginia\n",
      "\n",
      "MOST COMMON LAWS\n",
      "3\tLAW: Constitution\n",
      "1\tLAW: Second Amendment\n",
      "1\tLAW: the US Constitution\n",
      "1\tLAW: First Amendment rights\n",
      "\n",
      "MOST COMMON LOCATIONS\n",
      "8\tLOC: Europe\n",
      "2\tLOC: the Middle East\n",
      "2\tLOC: Africa\n",
      "2\tLOC: West\n",
      "1\tLOC: East\n",
      "1\tLOC: the Middle East Media Research Institute\n",
      "1\tLOC: Sunna\n",
      "1\tLOC: Central America\n",
      "\n",
      "MOST COMMON MONEY VALUES\n",
      "1\tMONEY: #KateSteinle #KatesLaw\n",
      "1\tMONEY: tens of millions\n",
      "1\tMONEY: 5.64\n",
      "1\tMONEY: 5.00\n",
      "\n",
      "MOST COMMON NATIONALITIES OR GROUPS\n",
      "42\tNORP: American\n",
      "9\tNORP: Americans\n",
      "5\tNORP: Christian\n",
      "5\tNORP: Democrats\n",
      "4\tNORP: Islamic\n",
      "4\tNORP: Russian\n",
      "3\tNORP: Muslim\n",
      "3\tNORP: Russians\n",
      "3\tNORP: Republican\n",
      "3\tNORP: Muslims\n",
      "2\tNORP: Zionism\n",
      "2\tNORP: Democratic\n",
      "2\tNORP: Republicans\n",
      "1\tNORP: Israeli\n",
      "1\tNORP: Palestinians\n",
      "1\tNORP: Jewish\n",
      "1\tNORP: British\n",
      "1\tNORP: Iranian\n",
      "1\tNORP: Iranians\n",
      "1\tNORP: European\n",
      "\n",
      "MOST COMMON ORDINALS\n",
      "4\tORDINAL: first\n",
      "1\tORDINAL: third\n",
      "\n",
      "MOST COMMON ORGANIZATIONS\n",
      "9\tORG: CIA\n",
      "7\tORG: Congress\n",
      "5\tORG: Hezbollah\n",
      "4\tORG: Trump\n",
      "4\tORG: Orban\n",
      "4\tORG: CNN\n",
      "3\tORG: Westerville Police\n",
      "3\tORG: Islam\n",
      "2\tORG: JFK\n",
      "2\tORG: Cabinet\n",
      "2\tORG: PLO\n",
      "2\tORG: UN\n",
      "2\tORG: Mueller\n",
      "2\tORG: Acosta\n",
      "1\tORG: the Home Affairs Select Committee\n",
      "1\tORG: Efrat\n",
      "1\tORG: Freedom of Information\n",
      "1\tORG: the Assassination Records Review Board\n",
      "1\tORG: HANNITY\n",
      "1\tORG: Ginger (@SpicyMustang\n",
      "\n",
      "MOST COMMON PERCENTAGES\n",
      "1\tPERCENT: 0.63%\n",
      "1\tPERCENT: 0.30%\n",
      "\n",
      "MOST COMMON PEOPLE\n",
      "7\tPERSON: Habib Powell\n",
      "5\tPERSON: Trump\n",
      "4\tPERSON: Barr\n",
      "3\tPERSON: Obama\n",
      "3\tPERSON: Candace Smith\n",
      "3\tPERSON: Bush\n",
      "3\tPERSON: Mueller\n",
      "2\tPERSON: Quentin Lamar Smith\n",
      "2\tPERSON: Joe Morbitzer\n",
      "2\tPERSON: Morbitzer\n",
      "2\tPERSON: Monica Lewinsky\n",
      "2\tPERSON: Putin\n",
      "2\tPERSON: Donald Trump\n",
      "2\tPERSON: Paul Craig Roberts\n",
      "2\tPERSON: George W. Bush\n",
      "2\tPERSON: Huma Abedin\n",
      "1\tPERSON: Keith Vaz\n",
      "1\tPERSON: Pamela Geller\n",
      "1\tPERSON: Robert Spencer\n",
      "1\tPERSON: Assad\n",
      "\n",
      "MOST COMMON PRODUCTS\n",
      "1\tPRODUCT: Facebook’s\n",
      "\n",
      "MOST COMMON TIMES\n",
      "1\tTIME: some 16 hours\n",
      "1\tTIME: 4:45 pm\n",
      "1\tTIME: 6:02 pm\n",
      "1\tTIME: later that night\n",
      "1\tTIME: night\n",
      "1\tTIME: 🇸\n",
      "1\tTIME: 10:35 EDT\n",
      "\n",
      "MOST COMMON WORK OF ARTS\n",
      "1\tWORK_OF_ART: Fight Those Who Want to Change the Christian Identity of Europe”Police\n",
      "1\tWORK_OF_ART: Face The Nation\n",
      "1\tWORK_OF_ART: Latino Voters Show Trump What It Means\n"
     ]
    }
   ],
   "source": [
    "print(\"MOST COMMON CARDINALS\")        \n",
    "for key, val in waving_cardinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON DATES\")        \n",
    "for key, val in waving_date_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\") \n",
    "\n",
    "print(\"\\nMOST COMMON COUNTRIES OR CITIES\")        \n",
    "for key, val in waving_gpe_count.most_common(15):\n",
    "    print(val, key, sep=\"\\t\") \n",
    "\n",
    "print(\"\\nMOST COMMON LAWS\")        \n",
    "for key, val in waving_law_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON LOCATIONS\")        \n",
    "for key, val in waving_loc_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON MONEY VALUES\")        \n",
    "for key, val in waving_money_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON NATIONALITIES OR GROUPS\")        \n",
    "for key, val in waving_norp_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON ORDINALS\")        \n",
    "for key, val in waving_ordinal_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON ORGANIZATIONS\")        \n",
    "for key, val in waving_org_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PERCENTAGES\")        \n",
    "for key, val in waving_percent_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "\n",
    "print(\"\\nMOST COMMON PEOPLE\")        \n",
    "for key, val in waving_person_count.most_common(20):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "    \n",
    "print(\"\\nMOST COMMON PRODUCTS\")        \n",
    "for key, val in waving_product_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")\n",
    "\n",
    "print(\"\\nMOST COMMON TIMES\")        \n",
    "for key, val in waving_time_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")  \n",
    "    \n",
    "print(\"\\nMOST COMMON WORK OF ARTS\")        \n",
    "for key, val in waving_woa_count.most_common(10):\n",
    "    print(val, key, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e687f1d-e147-42f0-b53b-283eda7e8b17",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL THE ENTITIES EXTRACTED FOR EACH CATEGORY\n",
    "print(\"TOTAL ENTITIES\")\n",
    "print(total_entities_dict_waving)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccd4237c-f000-444f-b58f-7e3be99c44a8",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(total_entities_dict_waving['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(total_entities_dict_waving['DATE'])\n",
    "print(\"\\nGPE\")\n",
    "print(total_entities_dict_waving['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(total_entities_dict_waving['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(total_entities_dict_waving['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(total_entities_dict_waving['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(total_entities_dict_waving['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(total_entities_dict_waving['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(total_entities_dict_waving['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(total_entities_dict_waving['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(total_entities_dict_waving['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(total_entities_dict_waving['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(total_entities_dict_waving['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(total_entities_dict_waving['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "690b4dea-0119-4881-8daa-35600c291cb4",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO SEE ALL UNIQUE ENTITIES\n",
    "print(\"UNIQUE ENTITIES\")\n",
    "print(unique_entities_dict_waving)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c140ae36-3b5b-452a-91c4-37da4fb76459",
   "metadata": {},
   "source": [
    "print(\"CARDINAL\")\n",
    "print(unique_entities_dict_waving['CARDINAL'])\n",
    "print(\"\\nDATE\")\n",
    "print(unique_entities_dict_waving['DATE'])\n",
    "print(\"\\nGPE\")\n",
    "print(unique_entities_dict_waving['GPE'])\n",
    "print(\"\\nLAW\")\n",
    "print(unique_entities_dict_waving['LAW'])\n",
    "print(\"\\nLOC\")\n",
    "print(unique_entities_dict_waving['LOC'])\n",
    "print(\"\\nMONEY\")\n",
    "print(unique_entities_dict_waving['MONEY'])\n",
    "print(\"\\nNORP\")\n",
    "print(unique_entities_dict_waving['NORP'])\n",
    "print(\"\\nORDINAL\")\n",
    "print(unique_entities_dict_waving['ORDINAL'])\n",
    "print(\"\\nORG\")\n",
    "print(unique_entities_dict_waving['ORG'])\n",
    "print(\"\\nPERCENT\")\n",
    "print(unique_entities_dict_waving['PERCENT'])\n",
    "print(\"\\nPERSON\")\n",
    "print(unique_entities_dict_waving['PERSON'])\n",
    "print(\"\\nPRODUCT\")\n",
    "print(unique_entities_dict_waving['PRODUCT'])\n",
    "print(\"\\nTIME\")\n",
    "print(unique_entities_dict_waving['TIME'])\n",
    "print(\"\\nWORK OF ART\")\n",
    "print(unique_entities_dict_waving['WORK_OF_ART'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6540b50-e4fd-4945-a080-2b0711a98d60",
   "metadata": {},
   "source": [
    "#RUN AS CODE TO DISPLAY THE TEXT WITH ALL OF THE RECOGNIZED ENTITIES\n",
    "displacy.render(total_waving_text, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f595b-6873-4349-a044-13c9bf415951",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd108d57-79a1-4b5d-b8bd-04c8203637c6",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad5a26-d141-408e-a896-5cf4448b2b25",
   "metadata": {},
   "source": [
    "For each paragraph belonging to a particular persuasion technique, it was decided to calculate the mean of the positive and negative sentiment for each paragraph in order to provide a general overview of the sentiment associated with that particular persuasion technique. \n",
    "\n",
    "This first process will involve all the persuasion techiniques combined and label-specific analysis will follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a155ed15-dc22-495b-8784-730c064b7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_total_lista = list()\n",
    "for i in X_total_lista:\n",
    "    doc_total_lista.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "33aea5eb-c620-44ab-8c3e-a70767317b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1878\n",
      "Positive sentiment: 0.6621691549101224\n",
      "Negative sentiment: 0.3378308451552449\n"
     ]
    }
   ],
   "source": [
    "#Load spacy sentiment analysis\n",
    "nlp_sa = eng_spacysentiment.load()\n",
    "\n",
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_total_sentiment = list()\n",
    "for i in doc_total_lista:\n",
    "    doc_total_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_total_sentiment_cats = list()    \n",
    "for i in doc_total_sentiment:\n",
    "    doc_total_sentiment_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset  \n",
    "total_positive = (sum(d['positive'] for d in doc_total_sentiment_cats)/len(doc_total_sentiment_cats))\n",
    "total_negative = (sum(d['negative'] for d in doc_total_sentiment_cats)/len(doc_total_sentiment_cats))\n",
    "\n",
    "print(len(doc_total_sentiment_cats))\n",
    "print(\"Positive sentiment: \" + str(total_positive))\n",
    "print(\"Negative sentiment: \" + str(total_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91dc2f-d106-4314-96de-f990a1553bff",
   "metadata": {},
   "source": [
    "### Loaded_Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fca06-7b17-4449-b418-ab1bf0ccc223",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Loaded_Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "834dc1f8-9e07-47b4-8750-8aa5a380ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_loaded_language = list()\n",
    "for i in X_loaded_language:\n",
    "    doc_loaded_language.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "083aa0a7-030f-4c84-b39a-2d2e642bd40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806\n",
      "Positive sentiment: 0.6547903497961741\n",
      "Negative sentiment: 0.3452096506258558\n"
     ]
    }
   ],
   "source": [
    "# perform spacy sentiment analysis for each paragraph\n",
    "doc_loaded_language_sentiment = list()\n",
    "for i in doc_loaded_language:\n",
    "    doc_loaded_language_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_loaded_language_cats = list()    \n",
    "for i in doc_loaded_language_sentiment:\n",
    "    doc_loaded_language_cats.append(i.cats)\n",
    "\n",
    "# create and print the average of the positive and negative evaluations for all the sentences of the dataset \n",
    "loaded_language_positive = (sum(d['positive'] for d in doc_loaded_language_cats)/len(doc_loaded_language_cats))\n",
    "loaded_language_negative = (sum(d['negative'] for d in doc_loaded_language_cats)/len(doc_loaded_language_cats))\n",
    "\n",
    "print(len(doc_loaded_language_cats))\n",
    "print(\"Positive sentiment: \" + str(loaded_language_positive))\n",
    "print(\"Negative sentiment: \" + str(loaded_language_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e8443-026e-4983-a076-8629ace66ecd",
   "metadata": {},
   "source": [
    "### Name_Calling-Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039a2ca-77a2-4632-8f72-eaae1b215b84",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Name_Calling-Labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "760f8595-6463-49e2-8762-806bb1d9d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_name_calling = list()\n",
    "for i in X_name_calling:\n",
    "    doc_name_calling.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "efd1bc2b-3f87-4720-b962-88c0d7b238a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "Positive sentiment: 0.7093578578388825\n",
      "Negative sentiment: 0.29064214305991704\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_name_calling_sentiment = list()\n",
    "for i in doc_name_calling:\n",
    "    doc_name_calling_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_name_calling_cats = list()    \n",
    "for i in doc_name_calling_sentiment:\n",
    "    doc_name_calling_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset \n",
    "name_calling_positive = (sum(d['positive'] for d in doc_name_calling_cats)/len(doc_name_calling_cats))\n",
    "name_calling_negative = (sum(d['negative'] for d in doc_name_calling_cats)/len(doc_name_calling_cats))\n",
    "\n",
    "print(len(doc_name_calling_cats))\n",
    "print(\"Positive sentiment: \" + str(name_calling_positive))\n",
    "print(\"Negative sentiment: \" + str(name_calling_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1971e85-57ef-4623-8c39-b67cc0e8c4a0",
   "metadata": {},
   "source": [
    "### Repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd1033d-6c99-4553-bb06-08d8bd13f08e",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "37d0a790-c417-4e21-bff9-edc3797add17",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_repetition = list()\n",
    "for i in X_repetition:\n",
    "    doc_repetition.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "022b4d3c-f365-43d6-a81f-6619941b32eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "Positive sentiment: 0.6673896217112268\n",
      "Negative sentiment: 0.33261037515658576\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_repetition_sentiment = list()\n",
    "for i in doc_repetition:\n",
    "    doc_repetition_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_repetition_cats = list()    \n",
    "for i in doc_repetition_sentiment:\n",
    "    doc_repetition_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset  \n",
    "repetition_positive = (sum(d['positive'] for d in doc_repetition_cats)/len(doc_repetition_cats))\n",
    "repetition_negative = (sum(d['negative'] for d in doc_repetition_cats)/len(doc_repetition_cats))\n",
    "\n",
    "print(len(doc_repetition_cats))\n",
    "print(\"Positive sentiment: \" + str(repetition_positive))\n",
    "print(\"Negative sentiment: \" + str(repetition_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21056048-bcee-4bce-8194-84e448c48a27",
   "metadata": {},
   "source": [
    "### Doubt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51521c91-0831-4969-877e-1eeefe3caf76",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Doubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d3ea6173-029b-4c9b-81d8-4ecaac6daefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_doubt = list()\n",
    "for i in X_doubt:\n",
    "    doc_doubt.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ecee15ba-383f-4949-b759-80cab1f6ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "Positive sentiment: 0.6209130356875026\n",
      "Negative sentiment: 0.37908696565167926\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_doubt_sentiment = list()\n",
    "for i in doc_doubt:\n",
    "    doc_doubt_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_doubt_cats = list()    \n",
    "for i in doc_doubt_sentiment:\n",
    "    doc_doubt_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset  \n",
    "doubt_positive = (sum(d['positive'] for d in doc_doubt_cats)/len(doc_doubt_cats))\n",
    "doubt_negative = (sum(d['negative'] for d in doc_doubt_cats)/len(doc_doubt_cats))\n",
    "\n",
    "print(len(doc_doubt_cats))\n",
    "print(\"Positive sentiment: \" + str(doubt_positive))\n",
    "print(\"Negative sentiment: \" + str(doubt_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669cf2f-6e87-483b-a475-93ee6525d532",
   "metadata": {},
   "source": [
    "### Appeal_to_Fear-Prejudice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d8258-ee2a-4c52-8e4a-03ebd060a1ad",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Appeal_to_Fear-Prejudice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f82a3b85-d821-4156-baa4-88b07fdd4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_prejudice = list()\n",
    "for i in X_prejudice:\n",
    "    doc_prejudice.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "1ad62f9b-3461-4662-bcbf-db0a261043c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "Positive sentiment: 0.6366185784187831\n",
      "Negative sentiment: 0.3633814182179653\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_prejudice_sentiment = list()\n",
    "for i in doc_prejudice:\n",
    "    doc_prejudice_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_prejudice_cats = list()    \n",
    "for i in doc_prejudice_sentiment:\n",
    "    doc_prejudice_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset\n",
    "prejudice_positive = (sum(d['positive'] for d in doc_prejudice_cats)/len(doc_prejudice_cats))\n",
    "prejudice_negative = (sum(d['negative'] for d in doc_prejudice_cats)/len(doc_prejudice_cats))\n",
    "\n",
    "print(len(doc_prejudice_cats))\n",
    "print(\"Positive sentiment: \" + str(prejudice_positive))\n",
    "print(\"Negative sentiment: \" + str(prejudice_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae98b1-17ed-4734-ace6-d78a7c0efd6f",
   "metadata": {},
   "source": [
    "### Exaggeration-Minimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e8774-435a-4a98-82e6-8e9b583c3a54",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Exaggeration-Minimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "dadba770-3f65-495b-bf8b-751438177c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ex_min = list()\n",
    "for i in X_ex_min:\n",
    "    doc_ex_min.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "29200610-8a07-4300-9cab-672b00406f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "Positive sentiment: 0.6661935986263292\n",
      "Negative sentiment: 0.3338064034628161\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph.\n",
    "doc_ex_min_sentiment = list()\n",
    "for i in doc_ex_min:\n",
    "    doc_ex_min_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_ex_min_cats = list()    \n",
    "for i in doc_ex_min_sentiment:\n",
    "    doc_ex_min_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset \n",
    "ex_min_positive = (sum(d['positive'] for d in doc_ex_min_cats)/len(doc_ex_min_cats))\n",
    "ex_min_negative = (sum(d['negative'] for d in doc_ex_min_cats)/len(doc_ex_min_cats))\n",
    "\n",
    "print(len(doc_ex_min_cats))\n",
    "print(\"Positive sentiment: \" + str(ex_min_positive))\n",
    "print(\"Negative sentiment: \" + str(ex_min_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07f646-a1d7-4403-9660-ca15af9cd211",
   "metadata": {},
   "source": [
    "### Flag_Waving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa0131-591a-4b78-9cf9-e047e8f31871",
   "metadata": {},
   "source": [
    "This section will focus on calculate the mean of the positive and negative sentiment for each paragraph labled as Flag_Waving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1e6e5a8b-9114-4f69-bce3-f87e5928c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_flag_waving = list()\n",
    "for i in X_flag_waving:\n",
    "    doc_flag_waving.append(nlp(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a03dc910-e605-46e0-b55a-2d96ac50460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "Positive sentiment: 0.6736761131208646\n",
      "Negative sentiment: 0.326323887816365\n"
     ]
    }
   ],
   "source": [
    "# Perform spacy sentiment analysis for each paragraph\n",
    "doc_flag_waving_sentiment = list()\n",
    "for i in doc_flag_waving:\n",
    "    doc_flag_waving_sentiment.append(nlp_sa(i))\n",
    "    \n",
    "# Create an empty list to which I append, for each paragraph, a dictionary containing the positive and negative percentage relative to the paragraph\n",
    "doc_flag_waving_cats = list()    \n",
    "for i in doc_flag_waving_sentiment:\n",
    "    doc_flag_waving_cats.append(i.cats)\n",
    "\n",
    "# Create and print the average of the positive and negative evaluations for all the sentences of the dataset   \n",
    "flag_waving_positive = (sum(d['positive'] for d in doc_flag_waving_cats)/len(doc_flag_waving_cats))\n",
    "flag_waving_negative = (sum(d['negative'] for d in doc_flag_waving_cats)/len(doc_flag_waving_cats))\n",
    "\n",
    "print(len(doc_flag_waving_cats))\n",
    "print(\"Positive sentiment: \" + str(flag_waving_positive))\n",
    "print(\"Negative sentiment: \" + str(flag_waving_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582b830-e494-4d4f-a768-14b01224dc3b",
   "metadata": {},
   "source": [
    "## Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "c5de0be7-5366-486e-9ab0-8163d46db060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL\n",
      "Positive sentiment: 0.6621691549101224\n",
      "Negative sentiment: 0.3378308451552449\n",
      "\n",
      "LOADED LANGUAGE\n",
      "Positive sentiment: 0.6547903497961741\n",
      "Negative sentiment: 0.3452096506258558\n",
      "\n",
      "NAME CALLING - LABELING\n",
      "Positive sentiment: 0.7093578578388825\n",
      "Negative sentiment: 0.29064214305991704\n",
      "\n",
      "REPETITION\n",
      "Positive sentiment: 0.6673896217112268\n",
      "Negative sentiment: 0.33261037515658576\n",
      "\n",
      "DOUBT\n",
      "Positive sentiment: 0.6209130356875026\n",
      "Negative sentiment: 0.37908696565167926\n",
      "\n",
      "PREJUDICE\n",
      "Positive sentiment: 0.6366185784187831\n",
      "Negative sentiment: 0.3633814182179653\n",
      "\n",
      "EXAGGERATION - MINIMISATION\n",
      "Positive sentiment: 0.6661935986263292\n",
      "Negative sentiment: 0.3338064034628161\n",
      "\n",
      "FLAG WAVING\n",
      "Positive sentiment: 0.6736761131208646\n",
      "Negative sentiment: 0.326323887816365\n"
     ]
    }
   ],
   "source": [
    "print(\"TOTAL\")\n",
    "print(\"Positive sentiment: \" + str(total_positive))\n",
    "print(\"Negative sentiment: \" + str(total_negative))\n",
    "print(\"\\nLOADED LANGUAGE\")\n",
    "print(\"Positive sentiment: \" + str(loaded_language_positive))\n",
    "print(\"Negative sentiment: \" + str(loaded_language_negative))\n",
    "print(\"\\nNAME CALLING - LABELING\")\n",
    "print(\"Positive sentiment: \" + str(name_calling_positive))\n",
    "print(\"Negative sentiment: \" + str(name_calling_negative))\n",
    "print(\"\\nREPETITION\")\n",
    "print(\"Positive sentiment: \" + str(repetition_positive))\n",
    "print(\"Negative sentiment: \" + str(repetition_negative))\n",
    "print(\"\\nDOUBT\")\n",
    "print(\"Positive sentiment: \" + str(doubt_positive))\n",
    "print(\"Negative sentiment: \" + str(doubt_negative))\n",
    "print(\"\\nPREJUDICE\")\n",
    "print(\"Positive sentiment: \" + str(prejudice_positive))\n",
    "print(\"Negative sentiment: \" + str(prejudice_negative))\n",
    "print(\"\\nEXAGGERATION - MINIMISATION\")\n",
    "print(\"Positive sentiment: \" + str(ex_min_positive))\n",
    "print(\"Negative sentiment: \" + str(ex_min_negative))\n",
    "print(\"\\nFLAG WAVING\")\n",
    "print(\"Positive sentiment: \" + str(flag_waving_positive))\n",
    "print(\"Negative sentiment: \" + str(flag_waving_negative))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
